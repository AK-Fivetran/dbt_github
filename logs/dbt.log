2020-05-05 21:35:38.321029 (MainThread): Running with dbt=0.16.1
2020-05-05 21:35:38.512539 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 21:35:38.514101 (MainThread): Tracking: tracking
2020-05-05 21:35:38.525436 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f182390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f17b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9928d0>]}
2020-05-05 21:35:38.554173 (MainThread): Partial parsing not enabled
2020-05-05 21:35:38.557408 (MainThread): Parsing macros/core.sql
2020-05-05 21:35:38.563894 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 21:35:38.574884 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 21:35:38.577468 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 21:35:38.599735 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 21:35:38.640473 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 21:35:38.667544 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 21:35:38.669952 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 21:35:38.677567 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 21:35:38.694360 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 21:35:38.702734 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 21:35:38.710436 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 21:35:38.716890 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 21:35:38.719498 (MainThread): Parsing macros/etc/query.sql
2020-05-05 21:35:38.721326 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 21:35:38.723624 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 21:35:38.726425 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 21:35:38.737323 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 21:35:38.739906 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 21:35:38.741400 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 21:35:38.794636 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 21:35:38.796216 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 21:35:38.797516 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 21:35:38.799088 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 21:35:38.802110 (MainThread): Parsing macros/etc.sql
2020-05-05 21:35:38.803160 (MainThread): Parsing macros/catalog.sql
2020-05-05 21:35:38.811365 (MainThread): Parsing macros/adapters.sql
2020-05-05 21:35:38.837143 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 21:35:38.839859 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 21:35:38.841652 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 21:35:38.855741 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 21:35:38.871879 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 21:35:38.896450 (MainThread): Partial parsing not enabled
2020-05-05 21:35:38.937874 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 21:35:38.938035 (MainThread): Opening a new connection, currently in state init
2020-05-05 21:35:38.968826 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 21:35:38.968995 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:38.977094 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 21:35:38.977227 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:38.995326 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 21:35:38.995464 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.003078 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 21:35:39.003205 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.010875 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 21:35:39.011005 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.020348 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 21:35:39.020684 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.028284 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 21:35:39.028425 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.037172 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 21:35:39.037311 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.044376 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 21:35:39.044518 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.052784 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 21:35:39.052921 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.060309 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 21:35:39.060433 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.067720 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 21:35:39.067853 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.080002 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 21:35:39.080166 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.089136 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 21:35:39.089283 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.096181 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 21:35:39.096339 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.103082 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 21:35:39.103233 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.110764 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 21:35:39.110892 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.118227 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 21:35:39.118472 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.125760 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 21:35:39.125913 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.132704 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 21:35:39.132830 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.139280 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 21:35:39.139426 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.146191 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 21:35:39.146339 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.157826 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 21:35:39.157973 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.164952 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 21:35:39.165081 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.171581 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 21:35:39.171710 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.179173 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 21:35:39.179299 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.188636 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 21:35:39.188824 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:35:39.198282 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f707250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f85ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f97ed10>]}
2020-05-05 21:35:39.198515 (MainThread): Flushing usage events
2020-05-05 21:35:39.718244 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 21:35:39.719010 (MainThread): Encountered an error:
2020-05-05 21:35:39.719377 (MainThread): Compilation Error
  The schema file at transform/github.yml is invalid because version 1 is not supported. Please consult the documentation for more information on schema.yml syntax:
  
  https://docs.getdbt.com/docs/schemayml-files
2020-05-05 21:35:39.724461 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 336, in load_all
    loader.load(internal_manifest=internal_manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 208, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 182, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 138, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/schemas.py", line 289, in parse_file
    self._parse_format_version(yaml_block)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/schemas.py", line 153, in _parse_format_version
    path, 'version {} is not supported'.format(version)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 764, in raise_invalid_schema_yml_version
    .format(path, issue)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  The schema file at transform/github.yml is invalid because version 1 is not supported. Please consult the documentation for more information on schema.yml syntax:
  
  https://docs.getdbt.com/docs/schemayml-files

2020-05-05 21:36:13.730473 (MainThread): Running with dbt=0.16.1
2020-05-05 21:36:13.893129 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 21:36:13.894252 (MainThread): Tracking: tracking
2020-05-05 21:36:13.901312 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c21750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c30c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e2f90>]}
2020-05-05 21:36:13.930484 (MainThread): Partial parsing not enabled
2020-05-05 21:36:13.932597 (MainThread): Parsing macros/core.sql
2020-05-05 21:36:13.937343 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 21:36:13.947840 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 21:36:13.950948 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 21:36:13.971377 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 21:36:14.010283 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 21:36:14.035334 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 21:36:14.037531 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 21:36:14.045004 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 21:36:14.062535 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 21:36:14.070376 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 21:36:14.077514 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 21:36:14.085223 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 21:36:14.086371 (MainThread): Parsing macros/etc/query.sql
2020-05-05 21:36:14.087564 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 21:36:14.089669 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 21:36:14.092239 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 21:36:14.103188 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 21:36:14.105802 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 21:36:14.107252 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 21:36:14.158002 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 21:36:14.159533 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 21:36:14.160648 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 21:36:14.162016 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 21:36:14.164898 (MainThread): Parsing macros/etc.sql
2020-05-05 21:36:14.165941 (MainThread): Parsing macros/catalog.sql
2020-05-05 21:36:14.175080 (MainThread): Parsing macros/adapters.sql
2020-05-05 21:36:14.199821 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 21:36:14.202089 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 21:36:14.204617 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 21:36:14.220895 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 21:36:14.236652 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 21:36:14.260457 (MainThread): Partial parsing not enabled
2020-05-05 21:36:14.304035 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 21:36:14.304201 (MainThread): Opening a new connection, currently in state init
2020-05-05 21:36:14.330904 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 21:36:14.331057 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.338349 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 21:36:14.338476 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.355995 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 21:36:14.356129 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.363155 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 21:36:14.363322 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.370768 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 21:36:14.370900 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.378364 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 21:36:14.378497 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.386726 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 21:36:14.386868 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.394298 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 21:36:14.394434 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.400543 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 21:36:14.400672 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.406796 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 21:36:14.406916 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.417282 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 21:36:14.417418 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.423757 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 21:36:14.423891 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.435684 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 21:36:14.435812 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.441998 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 21:36:14.442142 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.450401 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 21:36:14.450558 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.457110 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 21:36:14.457242 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.464418 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 21:36:14.464559 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.470683 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 21:36:14.470811 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.476978 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 21:36:14.477108 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.485081 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 21:36:14.485213 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.491417 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 21:36:14.491545 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.497773 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 21:36:14.497902 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.505156 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 21:36:14.505347 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.512787 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 21:36:14.513005 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.520658 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 21:36:14.520794 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.527607 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 21:36:14.527731 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.534533 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 21:36:14.534663 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:36:14.637631 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 21:36:14.637942 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c30c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ead090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c92cd0>]}
2020-05-05 21:36:14.638144 (MainThread): Flushing usage events
2020-05-05 21:36:14.981651 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 21:36:14.982099 (MainThread): Encountered an error:
2020-05-05 21:36:14.982418 (MainThread): Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found
2020-05-05 21:36:14.985816 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found

2020-05-05 21:38:56.744090 (MainThread): Running with dbt=0.16.1
2020-05-05 21:38:56.925681 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 21:38:56.927062 (MainThread): Tracking: tracking
2020-05-05 21:38:56.939243 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c98150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111d0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c9b350>]}
2020-05-05 21:38:56.963765 (MainThread): Partial parsing not enabled
2020-05-05 21:38:56.966417 (MainThread): Parsing macros/core.sql
2020-05-05 21:38:56.971885 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 21:38:56.983553 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 21:38:56.986057 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 21:38:57.006829 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 21:38:57.046997 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 21:38:57.074241 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 21:38:57.076793 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 21:38:57.085778 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 21:38:57.104116 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 21:38:57.112303 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 21:38:57.120253 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 21:38:57.126861 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 21:38:57.128271 (MainThread): Parsing macros/etc/query.sql
2020-05-05 21:38:57.130827 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 21:38:57.133250 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 21:38:57.135822 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 21:38:57.146415 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 21:38:57.149405 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 21:38:57.151012 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 21:38:57.204323 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 21:38:57.206053 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 21:38:57.207293 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 21:38:57.208795 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 21:38:57.211682 (MainThread): Parsing macros/etc.sql
2020-05-05 21:38:57.212591 (MainThread): Parsing macros/catalog.sql
2020-05-05 21:38:57.221521 (MainThread): Parsing macros/adapters.sql
2020-05-05 21:38:57.247821 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 21:38:57.250546 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 21:38:57.252592 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 21:38:57.265856 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 21:38:57.281289 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 21:38:57.305713 (MainThread): Partial parsing not enabled
2020-05-05 21:38:57.344032 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 21:38:57.344172 (MainThread): Opening a new connection, currently in state init
2020-05-05 21:38:57.374060 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 21:38:57.374202 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.382003 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 21:38:57.382132 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.399875 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 21:38:57.400013 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.407475 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 21:38:57.407598 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.415033 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 21:38:57.415157 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.422156 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 21:38:57.422285 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.429218 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 21:38:57.429466 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.438114 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 21:38:57.438251 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.444822 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 21:38:57.444950 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.451820 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 21:38:57.451963 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.460038 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 21:38:57.460185 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.469013 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 21:38:57.469145 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.480994 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 21:38:57.481155 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.488659 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 21:38:57.488813 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.497920 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 21:38:57.498300 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.505057 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 21:38:57.505183 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.512493 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 21:38:57.512622 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.519298 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 21:38:57.519441 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.525982 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 21:38:57.526120 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.534022 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 21:38:57.534151 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.540643 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 21:38:57.540774 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.547324 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 21:38:57.547448 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.553852 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 21:38:57.554002 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.561001 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 21:38:57.561142 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.568942 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 21:38:57.569077 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.575764 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 21:38:57.575903 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.582827 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 21:38:57.582960 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:38:57.701092 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 21:38:57.701474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111e76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112f5750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112f5410>]}
2020-05-05 21:38:57.701684 (MainThread): Flushing usage events
2020-05-05 21:38:58.116013 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 21:38:58.116262 (MainThread): Encountered an error:
2020-05-05 21:38:58.116434 (MainThread): Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found
2020-05-05 21:38:58.121454 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found

2020-05-05 21:40:58.486862 (MainThread): Running with dbt=0.16.1
2020-05-05 21:40:58.642545 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 21:40:58.643470 (MainThread): Tracking: tracking
2020-05-05 21:40:58.650066 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe4150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbf4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6afe50>]}
2020-05-05 21:40:58.675916 (MainThread): Partial parsing not enabled
2020-05-05 21:40:58.678454 (MainThread): Parsing macros/core.sql
2020-05-05 21:40:58.684251 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 21:40:58.694051 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 21:40:58.696156 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 21:40:58.717436 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 21:40:58.758501 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 21:40:58.782973 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 21:40:58.786809 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 21:40:58.794259 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 21:40:58.808756 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 21:40:58.817010 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 21:40:58.824964 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 21:40:58.830493 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 21:40:58.831582 (MainThread): Parsing macros/etc/query.sql
2020-05-05 21:40:58.832824 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 21:40:58.835048 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 21:40:58.837736 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 21:40:58.848375 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 21:40:58.852064 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 21:40:58.853615 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 21:40:58.901680 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 21:40:58.903081 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 21:40:58.904171 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 21:40:58.905462 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 21:40:58.908254 (MainThread): Parsing macros/etc.sql
2020-05-05 21:40:58.909059 (MainThread): Parsing macros/catalog.sql
2020-05-05 21:40:58.918213 (MainThread): Parsing macros/adapters.sql
2020-05-05 21:40:58.943472 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 21:40:58.945825 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 21:40:58.947687 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 21:40:58.960675 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 21:40:58.976530 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 21:40:58.999405 (MainThread): Partial parsing not enabled
2020-05-05 21:40:59.038146 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 21:40:59.038291 (MainThread): Opening a new connection, currently in state init
2020-05-05 21:40:59.065699 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 21:40:59.065878 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.073734 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 21:40:59.073868 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.091602 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 21:40:59.091740 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.099647 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 21:40:59.099782 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.107127 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 21:40:59.107279 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.114386 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 21:40:59.114522 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.121980 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 21:40:59.122107 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.129890 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 21:40:59.130054 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.137593 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 21:40:59.137728 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.145149 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 21:40:59.145276 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.154170 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 21:40:59.154307 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.160969 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 21:40:59.161097 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.173573 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 21:40:59.173706 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.181154 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 21:40:59.181305 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.190448 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 21:40:59.190592 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.197230 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 21:40:59.197366 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.204956 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 21:40:59.205089 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.211643 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 21:40:59.211813 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.220200 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 21:40:59.220396 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.227531 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 21:40:59.227663 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.234417 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 21:40:59.234548 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.241413 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 21:40:59.241542 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.248981 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 21:40:59.249173 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.257491 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 21:40:59.257634 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.266204 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 21:40:59.266418 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.275611 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 21:40:59.275810 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.282838 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 21:40:59.283291 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:40:59.403337 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 21:40:59.403727 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdb17d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccd5250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccd56d0>]}
2020-05-05 21:40:59.403935 (MainThread): Flushing usage events
2020-05-05 21:40:59.811779 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 21:40:59.811969 (MainThread): Encountered an error:
2020-05-05 21:40:59.812099 (MainThread): Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found
2020-05-05 21:40:59.813551 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found

2020-05-05 21:42:43.743297 (MainThread): Running with dbt=0.16.1
2020-05-05 21:42:43.920999 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 21:42:43.922448 (MainThread): Tracking: tracking
2020-05-05 21:42:43.930424 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b50a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba73d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b532610>]}
2020-05-05 21:42:43.953941 (MainThread): Partial parsing not enabled
2020-05-05 21:42:43.956355 (MainThread): Parsing macros/core.sql
2020-05-05 21:42:43.961757 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 21:42:43.971710 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 21:42:43.975315 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 21:42:43.995213 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 21:42:44.034797 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 21:42:44.060871 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 21:42:44.063464 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 21:42:44.070754 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 21:42:44.086235 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 21:42:44.095181 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 21:42:44.102558 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 21:42:44.109777 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 21:42:44.111108 (MainThread): Parsing macros/etc/query.sql
2020-05-05 21:42:44.112480 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 21:42:44.114654 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 21:42:44.117188 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 21:42:44.127672 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 21:42:44.130213 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 21:42:44.131733 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 21:42:44.184737 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 21:42:44.186352 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 21:42:44.187649 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 21:42:44.189217 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 21:42:44.192249 (MainThread): Parsing macros/etc.sql
2020-05-05 21:42:44.193298 (MainThread): Parsing macros/catalog.sql
2020-05-05 21:42:44.202177 (MainThread): Parsing macros/adapters.sql
2020-05-05 21:42:44.227945 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 21:42:44.231016 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 21:42:44.233252 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 21:42:44.247018 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 21:42:44.262495 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 21:42:44.286149 (MainThread): Partial parsing not enabled
2020-05-05 21:42:44.327667 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 21:42:44.327814 (MainThread): Opening a new connection, currently in state init
2020-05-05 21:42:44.355463 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 21:42:44.355601 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.363687 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 21:42:44.363827 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.380742 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 21:42:44.380875 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.388657 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 21:42:44.388801 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.396798 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 21:42:44.396943 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.404292 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 21:42:44.404483 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.412073 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 21:42:44.412245 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.419716 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 21:42:44.419845 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.426327 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 21:42:44.426455 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.433234 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 21:42:44.433371 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.442301 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 21:42:44.442435 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.448898 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 21:42:44.449026 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.461444 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 21:42:44.461616 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.469393 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 21:42:44.469528 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.478065 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 21:42:44.478198 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.485336 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 21:42:44.485498 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.495063 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 21:42:44.495210 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.501783 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 21:42:44.501910 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.509939 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 21:42:44.510080 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.517218 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 21:42:44.517348 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.524217 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 21:42:44.524420 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.531461 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 21:42:44.531591 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.538317 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 21:42:44.538533 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.546149 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 21:42:44.546286 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.552704 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 21:42:44.552853 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.559873 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 21:42:44.560005 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.566652 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 21:42:44.566774 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:44.690876 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 21:42:44.691197 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc28e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc28150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb5e810>]}
2020-05-05 21:42:44.691396 (MainThread): Flushing usage events
2020-05-05 21:42:45.108063 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 21:42:45.108266 (MainThread): Encountered an error:
2020-05-05 21:42:45.108489 (MainThread): Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found
2020-05-05 21:42:45.113014 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_pull_request (models/base/stg_github_pull_request.sql)
  Model 'model.github.stg_github_pull_request' (models/base/stg_github_pull_request.sql) depends on source 'github.pull_request' which was not found

2020-05-05 21:42:52.690574 (MainThread): Running with dbt=0.16.1
2020-05-05 21:42:52.851364 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 21:42:52.852317 (MainThread): Tracking: tracking
2020-05-05 21:42:52.858644 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df68ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4a6750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4b7610>]}
2020-05-05 21:42:52.882828 (MainThread): Partial parsing not enabled
2020-05-05 21:42:52.885116 (MainThread): Parsing macros/core.sql
2020-05-05 21:42:52.890448 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 21:42:52.901230 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 21:42:52.903485 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 21:42:52.923971 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 21:42:52.962886 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 21:42:52.988115 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 21:42:52.990423 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 21:42:52.997537 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 21:42:53.014034 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 21:42:53.021729 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 21:42:53.029082 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 21:42:53.035356 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 21:42:53.036902 (MainThread): Parsing macros/etc/query.sql
2020-05-05 21:42:53.039352 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 21:42:53.042594 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 21:42:53.045048 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 21:42:53.055671 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 21:42:53.057960 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 21:42:53.059274 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 21:42:53.107422 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 21:42:53.109015 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 21:42:53.110195 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 21:42:53.111521 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 21:42:53.114539 (MainThread): Parsing macros/etc.sql
2020-05-05 21:42:53.115319 (MainThread): Parsing macros/catalog.sql
2020-05-05 21:42:53.123668 (MainThread): Parsing macros/adapters.sql
2020-05-05 21:42:53.149212 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 21:42:53.151559 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 21:42:53.153286 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 21:42:53.164826 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 21:42:53.181294 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 21:42:53.203470 (MainThread): Partial parsing not enabled
2020-05-05 21:42:53.244859 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 21:42:53.245141 (MainThread): Opening a new connection, currently in state init
2020-05-05 21:42:53.270530 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 21:42:53.270665 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.279498 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 21:42:53.279632 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.295304 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 21:42:53.295435 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.302584 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 21:42:53.302716 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.311547 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 21:42:53.311683 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.318175 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 21:42:53.318298 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.324332 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 21:42:53.324451 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.332278 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 21:42:53.332409 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.342445 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 21:42:53.342623 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.349598 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 21:42:53.349758 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.357316 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 21:42:53.357440 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.364126 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 21:42:53.364255 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.376862 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 21:42:53.376994 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.383156 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 21:42:53.383290 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.389429 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 21:42:53.389591 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.396416 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 21:42:53.396541 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.403878 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 21:42:53.404001 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.411873 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 21:42:53.412000 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.418308 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 21:42:53.418437 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.425150 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 21:42:53.425297 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.432420 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 21:42:53.432566 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.441057 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 21:42:53.441212 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.447282 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 21:42:53.447412 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.453528 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 21:42:53.453654 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.459992 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 21:42:53.460122 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.466643 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 21:42:53.466771 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.474436 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 21:42:53.474679 (MainThread): Opening a new connection, currently in state closed
2020-05-05 21:42:53.592821 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 21:42:53.593181 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4cc050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5cc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5cc690>]}
2020-05-05 21:42:53.593376 (MainThread): Flushing usage events
2020-05-05 21:42:53.948748 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 21:42:53.948976 (MainThread): Encountered an error:
2020-05-05 21:42:53.949150 (MainThread): Compilation Error in model stg_github_requested_reviewer_history (models/base/stg_github_requested_reviewer_history.sql)
  Model 'model.github.stg_github_requested_reviewer_history' (models/base/stg_github_requested_reviewer_history.sql) depends on source 'github.requested_reviewer_history' which was not found
2020-05-05 21:42:53.950523 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_requested_reviewer_history (models/base/stg_github_requested_reviewer_history.sql)
  Model 'model.github.stg_github_requested_reviewer_history' (models/base/stg_github_requested_reviewer_history.sql) depends on source 'github.requested_reviewer_history' which was not found

2020-05-05 22:35:12.463770 (MainThread): Running with dbt=0.16.1
2020-05-05 22:35:12.664143 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 22:35:12.665494 (MainThread): Tracking: tracking
2020-05-05 22:35:12.683491 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a5fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105511ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10551af10>]}
2020-05-05 22:35:12.706008 (MainThread): Partial parsing not enabled
2020-05-05 22:35:12.709074 (MainThread): Parsing macros/core.sql
2020-05-05 22:35:12.714376 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 22:35:12.724395 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 22:35:12.726771 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 22:35:12.746026 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 22:35:12.783224 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 22:35:12.806880 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 22:35:12.809318 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 22:35:12.816695 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 22:35:12.831066 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 22:35:12.838973 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 22:35:12.847394 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 22:35:12.853413 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 22:35:12.855528 (MainThread): Parsing macros/etc/query.sql
2020-05-05 22:35:12.857173 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 22:35:12.859185 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 22:35:12.861578 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 22:35:12.871651 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 22:35:12.874025 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 22:35:12.875460 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 22:35:12.920383 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 22:35:12.921919 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 22:35:12.923345 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 22:35:12.924761 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 22:35:12.927610 (MainThread): Parsing macros/etc.sql
2020-05-05 22:35:12.928662 (MainThread): Parsing macros/catalog.sql
2020-05-05 22:35:12.937243 (MainThread): Parsing macros/adapters.sql
2020-05-05 22:35:12.960853 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 22:35:12.965077 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 22:35:12.967558 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 22:35:12.979290 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 22:35:12.993405 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 22:35:13.014907 (MainThread): Partial parsing not enabled
2020-05-05 22:35:13.050821 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 22:35:13.050960 (MainThread): Opening a new connection, currently in state init
2020-05-05 22:35:13.075026 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 22:35:13.075170 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.083375 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 22:35:13.083511 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.100653 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 22:35:13.100795 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.109489 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 22:35:13.109630 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.117535 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 22:35:13.117675 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.125030 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 22:35:13.125170 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.132529 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 22:35:13.132671 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.140260 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 22:35:13.140399 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.147303 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 22:35:13.147444 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.154445 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 22:35:13.154586 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.162514 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 22:35:13.162646 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.170433 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 22:35:13.170575 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.182342 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 22:35:13.182484 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.190053 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 22:35:13.190207 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.197674 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 22:35:13.197811 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.206216 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 22:35:13.206499 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.217342 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 22:35:13.217529 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.226028 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 22:35:13.226194 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.234306 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 22:35:13.234456 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.241625 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 22:35:13.241764 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.248359 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 22:35:13.248497 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.254792 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 22:35:13.255018 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.261433 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 22:35:13.261604 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.268939 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 22:35:13.269105 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.276567 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 22:35:13.276716 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.283779 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 22:35:13.283918 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.291073 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 22:35:13.291211 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:13.424436 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 22:35:13.424794 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c54a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c07b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d1490>]}
2020-05-05 22:35:13.425005 (MainThread): Flushing usage events
2020-05-05 22:35:13.859530 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 22:35:13.859878 (MainThread): Encountered an error:
2020-05-05 22:35:13.860157 (MainThread): Compilation Error in model stg_github_issue_label (models/base/stg_github_issue_label.sql)
  Model 'model.github.stg_github_issue_label' (models/base/stg_github_issue_label.sql) depends on source 'github.issue_label' which was not found
2020-05-05 22:35:13.868014 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_issue_label (models/base/stg_github_issue_label.sql)
  Model 'model.github.stg_github_issue_label' (models/base/stg_github_issue_label.sql) depends on source 'github.issue_label' which was not found

2020-05-05 22:35:34.804039 (MainThread): Running with dbt=0.16.1
2020-05-05 22:35:34.947280 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 22:35:34.948285 (MainThread): Tracking: tracking
2020-05-05 22:35:34.955124 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b6e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b7be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111610490>]}
2020-05-05 22:35:34.977083 (MainThread): Partial parsing not enabled
2020-05-05 22:35:34.979266 (MainThread): Parsing macros/core.sql
2020-05-05 22:35:34.984137 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 22:35:34.992987 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 22:35:34.995318 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 22:35:35.014268 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 22:35:35.050118 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 22:35:35.074353 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 22:35:35.076414 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 22:35:35.083099 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 22:35:35.097783 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 22:35:35.105115 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 22:35:35.112028 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 22:35:35.117550 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 22:35:35.118578 (MainThread): Parsing macros/etc/query.sql
2020-05-05 22:35:35.119699 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 22:35:35.121576 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 22:35:35.123721 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 22:35:35.134494 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 22:35:35.137008 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 22:35:35.138358 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 22:35:35.183431 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 22:35:35.184716 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 22:35:35.185708 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 22:35:35.186868 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 22:35:35.189480 (MainThread): Parsing macros/etc.sql
2020-05-05 22:35:35.190249 (MainThread): Parsing macros/catalog.sql
2020-05-05 22:35:35.198251 (MainThread): Parsing macros/adapters.sql
2020-05-05 22:35:35.221624 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 22:35:35.224258 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 22:35:35.225856 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 22:35:35.237502 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 22:35:35.252031 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 22:35:35.273110 (MainThread): Partial parsing not enabled
2020-05-05 22:35:35.307779 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 22:35:35.308022 (MainThread): Opening a new connection, currently in state init
2020-05-05 22:35:35.331511 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 22:35:35.331641 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.338618 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 22:35:35.338733 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.353428 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 22:35:35.353558 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.359990 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 22:35:35.360093 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.367401 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 22:35:35.367583 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.373903 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 22:35:35.374023 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.379638 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 22:35:35.379742 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.386547 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 22:35:35.386679 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.392152 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 22:35:35.392258 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.398499 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 22:35:35.398627 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.405369 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 22:35:35.405480 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.410826 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 22:35:35.410925 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.421677 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 22:35:35.421800 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.428211 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 22:35:35.428344 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.433934 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 22:35:35.434035 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.440040 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 22:35:35.440157 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.446485 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 22:35:35.446678 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.452351 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 22:35:35.452462 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.458303 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 22:35:35.458427 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.464735 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 22:35:35.464863 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.470686 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 22:35:35.470798 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.476436 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 22:35:35.476539 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.482655 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 22:35:35.482792 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.488460 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 22:35:35.488579 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.495357 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 22:35:35.495485 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.501577 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 22:35:35.501699 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.507318 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 22:35:35.507416 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:35.638612 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 22:35:35.639067 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d58f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c05d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111de9fd0>]}
2020-05-05 22:35:35.639261 (MainThread): Flushing usage events
2020-05-05 22:35:36.031770 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 22:35:36.032057 (MainThread): Encountered an error:
2020-05-05 22:35:36.032313 (MainThread): Compilation Error in model stg_github_pull_request_review (models/base/stg_github_pull_request_review.sql)
  Model 'model.github.stg_github_pull_request_review' (models/base/stg_github_pull_request_review.sql) depends on source 'github.pull_request_review' which was not found
2020-05-05 22:35:36.034652 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_pull_request_review (models/base/stg_github_pull_request_review.sql)
  Model 'model.github.stg_github_pull_request_review' (models/base/stg_github_pull_request_review.sql) depends on source 'github.pull_request_review' which was not found

2020-05-05 22:35:58.675417 (MainThread): Running with dbt=0.16.1
2020-05-05 22:35:58.816605 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 22:35:58.817631 (MainThread): Tracking: tracking
2020-05-05 22:35:58.824574 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106015750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106025d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106025590>]}
2020-05-05 22:35:58.845907 (MainThread): Partial parsing not enabled
2020-05-05 22:35:58.847926 (MainThread): Parsing macros/core.sql
2020-05-05 22:35:58.852596 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 22:35:58.861999 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 22:35:58.863988 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 22:35:58.882620 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 22:35:58.919021 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 22:35:58.942669 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 22:35:58.944751 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 22:35:58.951780 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 22:35:58.966238 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 22:35:58.973712 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 22:35:58.980640 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 22:35:58.985856 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 22:35:58.986835 (MainThread): Parsing macros/etc/query.sql
2020-05-05 22:35:58.987978 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 22:35:58.989778 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 22:35:58.992949 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 22:35:59.002639 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 22:35:59.004980 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 22:35:59.006119 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 22:35:59.051029 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 22:35:59.052300 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 22:35:59.053265 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 22:35:59.054604 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 22:35:59.057169 (MainThread): Parsing macros/etc.sql
2020-05-05 22:35:59.058054 (MainThread): Parsing macros/catalog.sql
2020-05-05 22:35:59.066177 (MainThread): Parsing macros/adapters.sql
2020-05-05 22:35:59.088899 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 22:35:59.091517 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 22:35:59.093704 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 22:35:59.104836 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 22:35:59.118870 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 22:35:59.139232 (MainThread): Partial parsing not enabled
2020-05-05 22:35:59.173538 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 22:35:59.173727 (MainThread): Opening a new connection, currently in state init
2020-05-05 22:35:59.196730 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 22:35:59.196870 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.204079 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 22:35:59.204200 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.219001 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 22:35:59.219127 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.226315 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 22:35:59.226564 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.233306 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 22:35:59.233413 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.239732 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 22:35:59.239852 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.245311 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 22:35:59.245416 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.252088 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 22:35:59.252200 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.257929 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 22:35:59.258043 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.264475 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 22:35:59.264596 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.271321 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 22:35:59.271437 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.277038 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 22:35:59.277139 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.287789 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 22:35:59.287905 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.294818 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 22:35:59.294951 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.300780 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 22:35:59.300894 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.306424 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 22:35:59.306519 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.313191 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 22:35:59.313315 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.318815 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 22:35:59.318925 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.324877 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 22:35:59.324994 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.331902 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 22:35:59.332033 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.337790 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 22:35:59.337902 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.343686 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 22:35:59.343808 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.349422 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 22:35:59.349525 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.355266 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 22:35:59.355382 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.361996 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 22:35:59.362122 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.368228 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 22:35:59.368347 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.374227 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 22:35:59.374404 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:35:59.506984 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 22:35:59.507418 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061cc910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b80ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106086ed0>]}
2020-05-05 22:35:59.507655 (MainThread): Flushing usage events
2020-05-05 22:35:59.881190 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 22:35:59.881524 (MainThread): Encountered an error:
2020-05-05 22:35:59.881775 (MainThread): Compilation Error in model stg_github_issue_comment (models/base/stg_github_issue_comment.sql)
  Model 'model.github.stg_github_issue_comment' (models/base/stg_github_issue_comment.sql) depends on source 'github.issue_comment' which was not found
2020-05-05 22:35:59.883894 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 301, in process_manifest
    process_sources(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 587, in process_sources
    _process_sources_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 575, in _process_sources_for_node
    table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 348, in invalid_source_fail_unless_test
    target_table_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 502, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_github_issue_comment (models/base/stg_github_issue_comment.sql)
  Model 'model.github.stg_github_issue_comment' (models/base/stg_github_issue_comment.sql) depends on source 'github.issue_comment' which was not found

2020-05-05 22:36:13.132612 (MainThread): Running with dbt=0.16.1
2020-05-05 22:36:13.276457 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 22:36:13.277386 (MainThread): Tracking: tracking
2020-05-05 22:36:13.284837 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e49ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e28d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e57690>]}
2020-05-05 22:36:13.306425 (MainThread): Partial parsing not enabled
2020-05-05 22:36:13.308355 (MainThread): Parsing macros/core.sql
2020-05-05 22:36:13.312802 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 22:36:13.321687 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 22:36:13.323798 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 22:36:13.342673 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 22:36:13.378600 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 22:36:13.402762 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 22:36:13.404800 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 22:36:13.411867 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 22:36:13.426423 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 22:36:13.433978 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 22:36:13.440981 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 22:36:13.446507 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 22:36:13.447662 (MainThread): Parsing macros/etc/query.sql
2020-05-05 22:36:13.448801 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 22:36:13.450601 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 22:36:13.452777 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 22:36:13.463147 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 22:36:13.465492 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 22:36:13.466634 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 22:36:13.512022 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 22:36:13.513288 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 22:36:13.514332 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 22:36:13.515467 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 22:36:13.518074 (MainThread): Parsing macros/etc.sql
2020-05-05 22:36:13.518955 (MainThread): Parsing macros/catalog.sql
2020-05-05 22:36:13.527432 (MainThread): Parsing macros/adapters.sql
2020-05-05 22:36:13.550697 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 22:36:13.552842 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 22:36:13.554378 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 22:36:13.566152 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 22:36:13.579830 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 22:36:13.602637 (MainThread): Partial parsing not enabled
2020-05-05 22:36:13.636961 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 22:36:13.637104 (MainThread): Opening a new connection, currently in state init
2020-05-05 22:36:13.660090 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 22:36:13.660222 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.666989 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 22:36:13.667101 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.681875 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 22:36:13.682006 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.688570 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 22:36:13.688813 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.696905 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 22:36:13.697032 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.703397 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 22:36:13.703519 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.708948 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 22:36:13.709044 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.715656 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 22:36:13.715772 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.721376 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 22:36:13.721492 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.728175 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 22:36:13.728308 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.735194 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 22:36:13.735309 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.740754 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 22:36:13.740855 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.751145 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 22:36:13.751317 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.758098 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 22:36:13.758230 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.763960 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 22:36:13.764076 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.769902 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 22:36:13.770011 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.776602 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 22:36:13.776720 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.782311 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 22:36:13.782417 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.787970 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 22:36:13.788071 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.794318 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 22:36:13.794437 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.800279 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 22:36:13.800392 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.805873 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 22:36:13.805976 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.811708 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 22:36:13.811814 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.818038 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 22:36:13.818163 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.825008 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 22:36:13.825200 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.831301 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 22:36:13.831417 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.836880 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 22:36:13.836975 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:36:13.968058 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 22:36:13.968679 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ef2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081af850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081af510>]}
2020-05-05 22:36:13.968881 (MainThread): Flushing usage events
2020-05-05 22:36:14.403889 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 22:36:14.404233 (MainThread): Encountered an error:
2020-05-05 22:36:14.404540 (MainThread): Compilation Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  Model 'model.github.issues_and_prs_per_month' depends on a node named 'pull_requests' which was not found or is disabled
2020-05-05 22:36:14.406933 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 302, in process_manifest
    process_refs(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 553, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 534, in _process_refs_for_node
    disabled=(isinstance(target_model, Disabled))
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 338, in invalid_ref_fail_unless_test
    target_model_package)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 488, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  Model 'model.github.issues_and_prs_per_month' depends on a node named 'pull_requests' which was not found or is disabled

2020-05-05 22:45:01.982954 (MainThread): Running with dbt=0.16.1
2020-05-05 22:45:02.172001 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 22:45:02.173340 (MainThread): Tracking: tracking
2020-05-05 22:45:02.181870 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11090ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e54d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e54e10>]}
2020-05-05 22:45:02.204482 (MainThread): Partial parsing not enabled
2020-05-05 22:45:02.206733 (MainThread): Parsing macros/core.sql
2020-05-05 22:45:02.211587 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 22:45:02.221002 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 22:45:02.223721 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 22:45:02.243655 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 22:45:02.281183 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 22:45:02.305105 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 22:45:02.307580 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 22:45:02.314605 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 22:45:02.328840 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 22:45:02.337906 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 22:45:02.345939 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 22:45:02.351386 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 22:45:02.352622 (MainThread): Parsing macros/etc/query.sql
2020-05-05 22:45:02.354024 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 22:45:02.356019 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 22:45:02.358424 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 22:45:02.369674 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 22:45:02.372126 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 22:45:02.373552 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 22:45:02.420136 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 22:45:02.421762 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 22:45:02.423174 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 22:45:02.424689 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 22:45:02.427711 (MainThread): Parsing macros/etc.sql
2020-05-05 22:45:02.428653 (MainThread): Parsing macros/catalog.sql
2020-05-05 22:45:02.437478 (MainThread): Parsing macros/adapters.sql
2020-05-05 22:45:02.462290 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 22:45:02.465348 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 22:45:02.467574 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 22:45:02.479240 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 22:45:02.493806 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 22:45:02.515214 (MainThread): Partial parsing not enabled
2020-05-05 22:45:02.551858 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 22:45:02.552006 (MainThread): Opening a new connection, currently in state init
2020-05-05 22:45:02.575471 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 22:45:02.575608 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.583376 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 22:45:02.583617 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.599216 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 22:45:02.599368 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.607164 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 22:45:02.607303 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.615204 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 22:45:02.615507 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.626679 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 22:45:02.626894 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.635223 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 22:45:02.635382 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.643098 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 22:45:02.643261 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.649937 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 22:45:02.650084 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.656810 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 22:45:02.656950 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.664660 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 22:45:02.664800 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.672480 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 22:45:02.672613 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.684730 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 22:45:02.684869 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.691492 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 22:45:02.691631 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.698631 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 22:45:02.698795 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.706308 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 22:45:02.706468 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.715213 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 22:45:02.715360 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.721901 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 22:45:02.722054 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.728755 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 22:45:02.728896 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.735726 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 22:45:02.735866 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.742554 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 22:45:02.742699 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.750216 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 22:45:02.750379 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.757625 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 22:45:02.757776 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.764421 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 22:45:02.764571 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.771163 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 22:45:02.771300 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.777794 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 22:45:02.777944 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.785174 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 22:45:02.785408 (MainThread): Opening a new connection, currently in state closed
2020-05-05 22:45:02.920091 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 22:45:02.920782 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110bf110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11101b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111119950>]}
2020-05-05 22:45:02.920976 (MainThread): Flushing usage events
2020-05-05 22:45:03.355089 (MainThread): Connection 'model.github.stg_github_milestone' was properly closed.
2020-05-05 22:45:03.355422 (MainThread): Encountered an error:
2020-05-05 22:45:03.355651 (MainThread): Compilation Error in model github_issues (models/github_issues.sql)
  Model 'model.github.github_issues' depends on a node named 'issue_bloked_time' which was not found or is disabled
2020-05-05 22:45:03.365221 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/main.py", line 212, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 351, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/task/runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 302, in process_manifest
    process_refs(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 553, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/parser/manifest.py", line 534, in _process_refs_for_node
    disabled=(isinstance(target_model, Disabled))
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/utils.py", line 338, in invalid_ref_fail_unless_test
    target_model_package)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 488, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model github_issues (models/github_issues.sql)
  Model 'model.github.github_issues' depends on a node named 'issue_bloked_time' which was not found or is disabled

2020-05-05 23:38:59.333079 (MainThread): Running with dbt=0.16.1
2020-05-05 23:38:59.527594 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:38:59.529352 (MainThread): Tracking: tracking
2020-05-05 23:38:59.537088 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fe07d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fefcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110aac190>]}
2020-05-05 23:38:59.559075 (MainThread): Partial parsing not enabled
2020-05-05 23:38:59.561484 (MainThread): Parsing macros/core.sql
2020-05-05 23:38:59.566747 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:38:59.577735 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:38:59.580329 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:38:59.600314 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:38:59.643793 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:38:59.667461 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:38:59.669807 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:38:59.677072 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:38:59.692104 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:38:59.700504 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:38:59.708442 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:38:59.714520 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:38:59.717109 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:38:59.719022 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:38:59.721112 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:38:59.723683 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:38:59.733730 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:38:59.736133 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:38:59.737468 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:38:59.785615 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:38:59.787205 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:38:59.788504 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:38:59.789929 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:38:59.792713 (MainThread): Parsing macros/etc.sql
2020-05-05 23:38:59.793674 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:38:59.801857 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:38:59.826036 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:38:59.829011 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:38:59.831704 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:38:59.844071 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:38:59.858809 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:38:59.879375 (MainThread): Partial parsing not enabled
2020-05-05 23:38:59.915115 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:38:59.915290 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:38:59.937692 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:38:59.937822 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:38:59.947343 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:38:59.947627 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:38:59.968589 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:38:59.968733 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:38:59.976244 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:38:59.976382 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:38:59.983990 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:38:59.984110 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:38:59.991359 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:38:59.991486 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:38:59.997698 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:38:59.997836 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.005310 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:39:00.005440 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.012232 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:39:00.012370 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.019445 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:39:00.019581 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.026660 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:39:00.026765 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.033684 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:39:00.033903 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.045937 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:39:00.046099 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.054329 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:39:00.054477 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.061628 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:39:00.061788 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.069355 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:39:00.069530 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.077980 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:39:00.078125 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.085432 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:39:00.085585 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.092033 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:39:00.092168 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.098912 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:39:00.099047 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.105689 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:39:00.105823 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.112796 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:39:00.113010 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.120877 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:39:00.121024 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.128122 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:39:00.128268 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.134542 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:39:00.134656 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.141420 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:39:00.141557 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.148882 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:39:00.149014 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.289806 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:39:00.538449 (MainThread): Found 28 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 15 sources
2020-05-05 23:39:00.557042 (MainThread): 
2020-05-05 23:39:00.557393 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:39:00.557489 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:39:00.612243 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:39:00.612402 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:39:02.128498 (ThreadPoolExecutor-0_1): Acquiring new bigquery connection "create_digital-arbor-400_dbt_erik".
2020-05-05 23:39:02.128903 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2020-05-05 23:39:02.129131 (ThreadPoolExecutor-0_1): Creating schema "digital-arbor-400.dbt_erik".
2020-05-05 23:39:02.129905 (ThreadPoolExecutor-0_1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:39:03.170253 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:39:03.170656 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:39:03.170946 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:39:03.345210 (MainThread): 16:39:03 | Concurrency: 4 threads (target='dev')
2020-05-05 23:39:03.345565 (MainThread): 16:39:03 | 
2020-05-05 23:39:03.356841 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:39:03.357090 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:39:03.357262 (Thread-1): 16:39:03 | 1 of 28 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:39:03.357363 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:39:03.357531 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:39:03.357672 (Thread-2): 16:39:03 | 2 of 28 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:39:03.358104 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:39:03.358265 (Thread-3): 16:39:03 | 3 of 28 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:39:03.358426 (Thread-4): 16:39:03 | 4 of 28 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:39:03.358725 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:39:03.358843 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:39:03.359119 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:39:03.359442 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:39:03.359597 (Thread-2): Re-using an available connection from the pool (formerly create_digital-arbor-400_dbt_erik).
2020-05-05 23:39:03.359746 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:39:03.359854 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:39:03.359965 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:39:03.360082 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:39:03.368642 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:39:03.375568 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:39:03.375719 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:39:03.383046 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:39:03.389326 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:39:03.395745 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:39:03.396848 (Thread-3): finished collecting timing info
2020-05-05 23:39:03.403346 (Thread-1): finished collecting timing info
2020-05-05 23:39:03.409724 (Thread-2): finished collecting timing info
2020-05-05 23:39:03.428332 (Thread-4): finished collecting timing info
2020-05-05 23:39:03.843678 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:39:03.844236 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:39:03.855616 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:39:03.856463 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:39:03.857962 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      upated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:39:03.858984 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:39:03.859773 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:39:03.860936 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:39:04.573779 (Thread-2): finished collecting timing info
2020-05-05 23:39:04.574990 (Thread-2): Database Error in model stg_github_card (models/base/stg_github_card.sql)
  Unrecognized name: upated_at; Did you mean updated_at? at [17:7]
  compiled SQL at target/run/github/base/stg_github_card.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/6e79afd9-282d-4948-ab5e-6f11793acf67?maxResults=0&location=US: Unrecognized name: upated_at; Did you mean updated_at? at [17:7]

(job ID: 6e79afd9-282d-4948-ab5e-6f11793acf67)

                                                        -----Query Job SQL Follows-----                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
   5:  OPTIONS()
   6:  as (
   7:    with card as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`github`.`card`
  11:
  12:), fields as (
  13:
  14:    select 
  15:      id,
  16:      archived,
  17:      upated_at,
  18:      is_deleted
  19:    from card
  20:)
  21:
  22:select *
  23:from fields
  24:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_github_card (models/base/stg_github_card.sql)
  Unrecognized name: upated_at; Did you mean updated_at? at [17:7]
  compiled SQL at target/run/github/base/stg_github_card.sql
2020-05-05 23:39:04.591965 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11282d5d0>]}
2020-05-05 23:39:04.592978 (Thread-2): 16:39:04 | 2 of 28 ERROR creating view model dbt_erik.stg_github_card........... [ERROR in 1.23s]
2020-05-05 23:39:04.593142 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:39:04.593639 (Thread-2): Began running node model.github.stg_github_user
2020-05-05 23:39:04.594546 (Thread-2): 16:39:04 | 5 of 28 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:39:04.594980 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:39:04.595348 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:39:04.595741 (Thread-2): Compiling model.github.stg_github_user
2020-05-05 23:39:04.603550 (Thread-2): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:39:04.604900 (Thread-2): finished collecting timing info
2020-05-05 23:39:04.609260 (Thread-2): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:39:04.610532 (Thread-2): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:39:04.722803 (Thread-4): finished collecting timing info
2020-05-05 23:39:04.723529 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116eca50>]}
2020-05-05 23:39:04.723773 (Thread-4): 16:39:04 | 4 of 28 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.36s]
2020-05-05 23:39:04.723911 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:39:04.724103 (Thread-4): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:39:04.724446 (Thread-4): 16:39:04 | 6 of 28 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:39:04.724993 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:39:04.725084 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:39:04.725169 (Thread-4): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:39:04.732916 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:39:04.737127 (Thread-1): finished collecting timing info
2020-05-05 23:39:04.739650 (Thread-3): finished collecting timing info
2020-05-05 23:39:04.740310 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111371190>]}
2020-05-05 23:39:04.740855 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112a2450>]}
2020-05-05 23:39:04.741011 (Thread-4): finished collecting timing info
2020-05-05 23:39:04.741290 (Thread-1): 16:39:04 | 1 of 28 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.38s]
2020-05-05 23:39:04.741482 (Thread-3): 16:39:04 | 3 of 28 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.38s]
2020-05-05 23:39:04.747990 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:39:04.748448 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:39:04.748894 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:39:04.749488 (Thread-1): Began running node model.github.stg_github_issue_label
2020-05-05 23:39:04.749880 (Thread-3): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:39:04.750252 (Thread-1): 16:39:04 | 7 of 28 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:39:04.750571 (Thread-3): 16:39:04 | 8 of 28 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:39:04.750722 (Thread-4): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:39:04.751778 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:39:04.752535 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:39:04.753172 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:39:04.754045 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:39:04.754229 (Thread-1): Compiling model.github.stg_github_issue_label
2020-05-05 23:39:04.754513 (Thread-3): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:39:04.761902 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:39:04.769045 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:39:04.770408 (Thread-3): finished collecting timing info
2020-05-05 23:39:04.774529 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:39:04.774744 (Thread-1): finished collecting timing info
2020-05-05 23:39:04.778888 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:39:04.779235 (Thread-1): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:39:04.780133 (Thread-3): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:39:05.195455 (Thread-2): finished collecting timing info
2020-05-05 23:39:05.197392 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111792a10>]}
2020-05-05 23:39:05.197845 (Thread-2): 16:39:05 | 5 of 28 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.60s]
2020-05-05 23:39:05.198029 (Thread-2): Finished running node model.github.stg_github_user
2020-05-05 23:39:05.198686 (Thread-2): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:39:05.199561 (Thread-2): 16:39:05 | 9 of 28 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:39:05.200116 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:39:05.200378 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:39:05.200537 (Thread-2): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:39:05.209137 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:39:05.210158 (Thread-2): finished collecting timing info
2020-05-05 23:39:05.214614 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:39:05.215057 (Thread-2): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:39:05.337404 (Thread-1): finished collecting timing info
2020-05-05 23:39:05.338495 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11128b650>]}
2020-05-05 23:39:05.338877 (Thread-1): 16:39:05 | 7 of 28 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.59s]
2020-05-05 23:39:05.339091 (Thread-1): Finished running node model.github.stg_github_issue_label
2020-05-05 23:39:05.339308 (Thread-1): Began running node model.github.stg_github_issue_merged
2020-05-05 23:39:05.339505 (Thread-1): 16:39:05 | 10 of 28 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:39:05.339836 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:39:05.339959 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:39:05.340083 (Thread-1): Compiling model.github.stg_github_issue_merged
2020-05-05 23:39:05.349771 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:39:05.352303 (Thread-3): finished collecting timing info
2020-05-05 23:39:05.353025 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128aa350>]}
2020-05-05 23:39:05.353264 (Thread-3): 16:39:05 | 8 of 28 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.60s]
2020-05-05 23:39:05.353473 (Thread-3): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:39:05.353632 (Thread-3): Began running node model.github.stg_github_pull_request
2020-05-05 23:39:05.353768 (Thread-3): 16:39:05 | 11 of 28 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:39:05.354032 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:39:05.354127 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:39:05.354219 (Thread-3): Compiling model.github.stg_github_pull_request
2020-05-05 23:39:05.360668 (Thread-1): finished collecting timing info
2020-05-05 23:39:05.365907 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:39:05.366480 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:39:05.367254 (Thread-3): finished collecting timing info
2020-05-05 23:39:05.371258 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:39:05.371492 (Thread-1): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:39:05.372628 (Thread-3): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id as pull_request_id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:39:05.451947 (Thread-4): finished collecting timing info
2020-05-05 23:39:05.452996 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111725510>]}
2020-05-05 23:39:05.453392 (Thread-4): 16:39:05 | 6 of 28 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.73s]
2020-05-05 23:39:05.453564 (Thread-4): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:39:05.453737 (Thread-4): Began running node model.github.stg_github_repository
2020-05-05 23:39:05.453911 (Thread-4): 16:39:05 | 12 of 28 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:39:05.454396 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:39:05.454538 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:39:05.454667 (Thread-4): Compiling model.github.stg_github_repository
2020-05-05 23:39:05.463130 (Thread-4): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:39:05.463517 (Thread-4): finished collecting timing info
2020-05-05 23:39:05.467753 (Thread-4): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:39:05.468108 (Thread-4): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:39:05.817013 (Thread-2): finished collecting timing info
2020-05-05 23:39:05.817893 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112943250>]}
2020-05-05 23:39:05.819410 (Thread-2): 16:39:05 | 9 of 28 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.62s]
2020-05-05 23:39:05.819722 (Thread-2): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:39:05.820465 (Thread-2): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:39:05.821313 (Thread-2): 16:39:05 | 13 of 28 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:39:05.822023 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:39:05.822366 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:39:05.822736 (Thread-2): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:39:05.829863 (Thread-2): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:39:05.830701 (Thread-2): finished collecting timing info
2020-05-05 23:39:05.835397 (Thread-2): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:39:05.835827 (Thread-2): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:39:05.958526 (Thread-3): finished collecting timing info
2020-05-05 23:39:05.959551 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111371910>]}
2020-05-05 23:39:05.959917 (Thread-3): 16:39:05 | 11 of 28 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.61s]
2020-05-05 23:39:05.960138 (Thread-3): Finished running node model.github.stg_github_pull_request
2020-05-05 23:39:05.960370 (Thread-3): Began running node model.github.stg_github_milestone
2020-05-05 23:39:05.960773 (Thread-3): 16:39:05 | 14 of 28 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:39:05.961168 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:39:05.961296 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:39:05.961420 (Thread-3): Compiling model.github.stg_github_milestone
2020-05-05 23:39:05.971890 (Thread-3): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:39:05.972924 (Thread-3): finished collecting timing info
2020-05-05 23:39:05.977963 (Thread-3): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:39:05.978908 (Thread-3): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:39:06.116126 (Thread-4): finished collecting timing info
2020-05-05 23:39:06.117024 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111725510>]}
2020-05-05 23:39:06.117341 (Thread-4): 16:39:06 | 12 of 28 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.66s]
2020-05-05 23:39:06.117522 (Thread-4): Finished running node model.github.stg_github_repository
2020-05-05 23:39:06.117935 (Thread-4): Began running node model.github.stg_github_issue_comment
2020-05-05 23:39:06.118352 (Thread-4): 16:39:06 | 15 of 28 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:39:06.118835 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:39:06.118978 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:39:06.119200 (Thread-4): Compiling model.github.stg_github_issue_comment
2020-05-05 23:39:06.126868 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:39:06.127270 (Thread-4): finished collecting timing info
2020-05-05 23:39:06.131774 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:39:06.132166 (Thread-4): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:39:06.176406 (Thread-1): finished collecting timing info
2020-05-05 23:39:06.177249 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112980b50>]}
2020-05-05 23:39:06.177545 (Thread-1): 16:39:06 | 10 of 28 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.84s]
2020-05-05 23:39:06.177714 (Thread-1): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:39:06.177881 (Thread-1): Began running node model.github.issue_status_windows
2020-05-05 23:39:06.178044 (Thread-1): 16:39:06 | 16 of 28 SKIP relation dbt_erik.issue_status_windows................. [SKIP]
2020-05-05 23:39:06.178198 (Thread-1): Finished running node model.github.issue_status_windows
2020-05-05 23:39:06.178556 (Thread-1): Began running node model.github.issue_close_stack
2020-05-05 23:39:06.178745 (Thread-1): 16:39:06 | 17 of 28 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:39:06.179223 (Thread-1): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:39:06.179360 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:39:06.179495 (Thread-1): Compiling model.github.issue_close_stack
2020-05-05 23:39:06.188334 (Thread-1): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:39:06.188883 (Thread-1): finished collecting timing info
2020-05-05 23:39:06.193077 (Thread-1): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:39:06.193513 (Thread-1): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from github.issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from github.issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:39:06.452575 (Thread-2): finished collecting timing info
2020-05-05 23:39:06.453508 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112803a10>]}
2020-05-05 23:39:06.453817 (Thread-2): 16:39:06 | 13 of 28 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.63s]
2020-05-05 23:39:06.453986 (Thread-2): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:39:06.454153 (Thread-2): Began running node model.github.issue_labels
2020-05-05 23:39:06.454319 (Thread-2): 16:39:06 | 18 of 28 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:39:06.454638 (Thread-2): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:39:06.454753 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:39:06.454869 (Thread-2): Compiling model.github.issue_labels
2020-05-05 23:39:06.462643 (Thread-2): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:39:06.463058 (Thread-2): finished collecting timing info
2020-05-05 23:39:06.467625 (Thread-2): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:39:06.468048 (Thread-2): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:39:06.710275 (Thread-3): finished collecting timing info
2020-05-05 23:39:06.712020 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111229b50>]}
2020-05-05 23:39:06.712343 (Thread-3): 16:39:06 | 14 of 28 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.75s]
2020-05-05 23:39:06.712520 (Thread-3): Finished running node model.github.stg_github_milestone
2020-05-05 23:39:06.712692 (Thread-3): Began running node model.github.pull_request_reviewers
2020-05-05 23:39:06.712861 (Thread-3): 16:39:06 | 19 of 28 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:39:06.713348 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:39:06.713484 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:39:06.716597 (Thread-4): finished collecting timing info
2020-05-05 23:39:06.716845 (Thread-3): Compiling model.github.pull_request_reviewers
2020-05-05 23:39:06.717420 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111229fd0>]}
2020-05-05 23:39:06.726034 (Thread-3): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:39:06.726263 (Thread-4): 16:39:06 | 15 of 28 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.60s]
2020-05-05 23:39:06.726566 (Thread-4): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:39:06.726706 (Thread-4): Began running node model.github.issue_assignees
2020-05-05 23:39:06.726838 (Thread-4): 16:39:06 | 20 of 28 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:39:06.727098 (Thread-4): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:39:06.727187 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:39:06.727275 (Thread-4): Compiling model.github.issue_assignees
2020-05-05 23:39:06.734805 (Thread-4): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:39:06.735176 (Thread-3): finished collecting timing info
2020-05-05 23:39:06.739869 (Thread-3): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:39:06.740304 (Thread-4): finished collecting timing info
2020-05-05 23:39:06.744450 (Thread-4): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:39:06.744788 (Thread-3): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:39:06.745707 (Thread-4): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:39:06.752501 (Thread-1): finished collecting timing info
2020-05-05 23:39:06.752936 (Thread-1): Database Error in model issue_close_stack (models/transform/intermediate/issue_close_stack.sql)
  Unrecognized name: issue_id; Did you mean issue? at [19:7]
  compiled SQL at target/run/github/transform/intermediate/issue_close_stack.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/3d647723-d4b3-4c83-b79b-3b603803cc09?maxResults=0&location=US: Unrecognized name: issue_id; Did you mean issue? at [19:7]

(job ID: 3d647723-d4b3-4c83-b79b-3b603803cc09)

                                                                                     -----Query Job SQL Follows-----                                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:    
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_closed_history as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  16:  
  17:), close_events_stacked as (
  18:    select
  19:      issue_id,
  20:      created_at as updated_at,
  21:      FALSE as closed
  22:    from github.issue
  23:    union all
  24:    select
  25:      issue_id,
  26:      updated_at,
  27:      closed
  28:    from github.issue_closed_history
  29:    union all
  30:    select
  31:      issue_id,
  32:      closed_at as updated_at,
  33:      TRUE as closed
  34:    from issue
  35:    where closed_at is not null
  36:
  37:), close_events_stacked_ordered as (
  38:    select
  39:      *,
  40:      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
  41:    from close_events_stacked
  42:)
  43:
  44:select
  45:  issue_id,
  46:  updated_at as valid_starting,
  47:  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  48:  closed as is_closed
  49:from close_events_stacked_ordered
  50:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issue_close_stack (models/transform/intermediate/issue_close_stack.sql)
  Unrecognized name: issue_id; Did you mean issue? at [19:7]
  compiled SQL at target/run/github/transform/intermediate/issue_close_stack.sql
2020-05-05 23:39:06.753756 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111371e50>]}
2020-05-05 23:39:06.753955 (Thread-1): 16:39:06 | 17 of 28 ERROR creating view model dbt_erik.issue_close_stack........ [ERROR in 0.57s]
2020-05-05 23:39:06.754070 (Thread-1): Finished running node model.github.issue_close_stack
2020-05-05 23:39:06.754187 (Thread-1): Began running node model.github.issue_blocked_time
2020-05-05 23:39:06.754396 (Thread-1): 16:39:06 | 21 of 28 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:39:06.754667 (Thread-1): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:39:06.754750 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:39:06.754832 (Thread-1): Compiling model.github.issue_blocked_time
2020-05-05 23:39:06.761288 (Thread-1): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:39:06.761676 (Thread-1): finished collecting timing info
2020-05-05 23:39:06.766736 (Thread-1): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:39:06.767124 (Thread-1): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from github.issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:39:07.121679 (Thread-2): finished collecting timing info
2020-05-05 23:39:07.122696 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111229d10>]}
2020-05-05 23:39:07.123071 (Thread-2): 16:39:07 | 18 of 28 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.67s]
2020-05-05 23:39:07.123347 (Thread-2): Finished running node model.github.issue_labels
2020-05-05 23:39:07.123565 (Thread-2): Began running node model.github.issue_inbox_time
2020-05-05 23:39:07.123748 (Thread-2): 16:39:07 | 22 of 28 SKIP relation dbt_erik.issue_inbox_time..................... [SKIP]
2020-05-05 23:39:07.123911 (Thread-2): Finished running node model.github.issue_inbox_time
2020-05-05 23:39:07.124064 (Thread-2): Began running node model.github.issue_projects
2020-05-05 23:39:07.124218 (Thread-2): 16:39:07 | 23 of 28 SKIP relation dbt_erik.issue_projects....................... [SKIP]
2020-05-05 23:39:07.124516 (Thread-2): Finished running node model.github.issue_projects
2020-05-05 23:39:07.124700 (Thread-2): Began running node model.github.pull_request_times
2020-05-05 23:39:07.124870 (Thread-2): 16:39:07 | 24 of 28 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:39:07.125299 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:39:07.125432 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:39:07.125556 (Thread-2): Compiling model.github.pull_request_times
2020-05-05 23:39:07.174879 (Thread-2): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:39:07.175639 (Thread-1): finished collecting timing info
2020-05-05 23:39:07.176618 (Thread-2): finished collecting timing info
2020-05-05 23:39:07.182049 (Thread-2): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:39:07.176119 (Thread-1): Database Error in model issue_blocked_time (models/transform/intermediate/issue_blocked_time.sql)
  Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_label_history"
  compiled SQL at target/run/github/transform/intermediate/issue_blocked_time.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/f92953ae-c68f-4404-aff9-6f9e01f23e19?maxResults=0&location=US: Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_label_history"

(job ID: f92953ae-c68f-4404-aff9-6f9e01f23e19)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
   5:  OPTIONS()
   6:  as (
   7:    with issue_label_history as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  11:  
  12:), issue_label_times as (
  13:
  14:    select
  15:      issue_id,
  16:      label,
  17:      updated_at as valid_starting,
  18:      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
  19:      labeled
  20:    from github.issue_label_history
  21:    order by updated_at
  22:
  23:)
  24:
  25:select
  26:  issue_id,
  27:  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
  28:from issue_label_times
  29:where labeled
  30:  and lower(label) like '%blocked%'
  31:group by 1
  32:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issue_blocked_time (models/transform/intermediate/issue_blocked_time.sql)
  Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_label_history"
  compiled SQL at target/run/github/transform/intermediate/issue_blocked_time.sql
2020-05-05 23:39:07.182933 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129f6b50>]}
2020-05-05 23:39:07.183211 (Thread-1): 16:39:07 | 21 of 28 ERROR creating view model dbt_erik.issue_blocked_time....... [ERROR in 0.43s]
2020-05-05 23:39:07.183518 (Thread-1): Finished running node model.github.issue_blocked_time
2020-05-05 23:39:07.183701 (Thread-1): Began running node model.github.issue_open_length
2020-05-05 23:39:07.183845 (Thread-1): 16:39:07 | 25 of 28 SKIP relation dbt_erik.issue_open_length.................... [SKIP]
2020-05-05 23:39:07.183985 (Thread-2): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join github.requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join github.pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:39:07.184397 (Thread-1): Finished running node model.github.issue_open_length
2020-05-05 23:39:07.364868 (Thread-3): finished collecting timing info
2020-05-05 23:39:07.365881 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129c6c90>]}
2020-05-05 23:39:07.366244 (Thread-3): 16:39:07 | 19 of 28 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.65s]
2020-05-05 23:39:07.366446 (Thread-3): Finished running node model.github.pull_request_reviewers
2020-05-05 23:39:07.372173 (Thread-4): finished collecting timing info
2020-05-05 23:39:07.373016 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129df290>]}
2020-05-05 23:39:07.373312 (Thread-4): 16:39:07 | 20 of 28 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.65s]
2020-05-05 23:39:07.373479 (Thread-4): Finished running node model.github.issue_assignees
2020-05-05 23:39:07.373828 (Thread-1): Began running node model.github.github_issues
2020-05-05 23:39:07.374003 (Thread-1): 16:39:07 | 26 of 28 SKIP relation dbt_erik.github_issues........................ [SKIP]
2020-05-05 23:39:07.374164 (Thread-1): Finished running node model.github.github_issues
2020-05-05 23:39:07.645141 (Thread-2): finished collecting timing info
2020-05-05 23:39:07.646156 (Thread-2): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Duplicate alias pull_request_review for WITH subquery at [17:4]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/4ac13e4e-14ef-4f67-9b20-aa21cc5a144a?maxResults=0&location=US: Duplicate alias pull_request_review for WITH subquery at [17:4]

(job ID: 4ac13e4e-14ef-4f67-9b20-aa21cc5a144a)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
   5:  OPTIONS()
   6:  as (
   7:    with pull_request_review as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  11:  
  12:), pull_request as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  16:
  17:), pull_request_review as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  21:
  22:), requested_reviewer_history as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  26:
  27:), issue as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  31:  
  32:), issue_merged as (
  33:
  34:    select
  35:      issue_id,
  36:      min(merged_at) as merged_at
  37:      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  38:    group by 1
  39:
  40:), first_request_time as (
  41:
  42:    select
  43:      pull_request.issue_id,
  44:      pull_request.id,
  45:      min(requested_reviewer_history.created_at) as time_of_first_request,
  46:      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
  47:      -- Finds the first review that is by the requested reviewer and is not a dismissal
  48:      min(if(
  49:            requested_reviewer_history.requested_id = pull_request_review.user_id
  50:            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
  51:            pull_request_review.submitted_at,
  52:            NULL)) as time_of_first_requested_reviewer_review
  53:    from pull_request
  54:    join github.requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
  55:    left join github.pull_request_review on pull_request_review.pull_request_id = pull_request.id
  56:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
  57:    group by 1, 2
  58:
  59:)
  60:
  61:select
  62:  first_request_time.issue_id,
  63:  merged_at,
  64:  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  65:  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  66:  timestamp_diff(
  67:    least(
  68:    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
  69:    coalesce(issue.closed_at, current_timestamp())
  70:  ),
  71:  time_of_first_request,
  72:  second)/3600 as hours_first_action_post_request,
  73:  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
  74:from first_request_time
  75:join issue on first_request_time.issue_id = issue.id
  76:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  77:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Duplicate alias pull_request_review for WITH subquery at [17:4]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:39:07.647831 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a006ccf1-4499-4453-aae4-9d249b68adb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112977a90>]}
2020-05-05 23:39:07.648267 (Thread-2): 16:39:07 | 24 of 28 ERROR creating view model dbt_erik.pull_request_times....... [ERROR in 0.52s]
2020-05-05 23:39:07.648516 (Thread-2): Finished running node model.github.pull_request_times
2020-05-05 23:39:07.649390 (Thread-4): Began running node model.github.github_pull_requests
2020-05-05 23:39:07.649658 (Thread-4): 16:39:07 | 27 of 28 SKIP relation dbt_erik.github_pull_requests................. [SKIP]
2020-05-05 23:39:07.649862 (Thread-4): Finished running node model.github.github_pull_requests
2020-05-05 23:39:07.650227 (Thread-1): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:39:07.650429 (Thread-1): 16:39:07 | 28 of 28 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:39:07.650617 (Thread-1): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:39:07.699296 (MainThread): 16:39:07 | 
2020-05-05 23:39:07.699632 (MainThread): 16:39:07 | Finished running 28 view models in 7.14s.
2020-05-05 23:39:07.699856 (MainThread): Connection 'master' was left open.
2020-05-05 23:39:07.700019 (MainThread): Connection 'model.github.issue_blocked_time' was left open.
2020-05-05 23:39:07.700170 (MainThread): Connection 'model.github.pull_request_times' was left open.
2020-05-05 23:39:07.700314 (MainThread): Connection 'model.github.pull_request_reviewers' was left open.
2020-05-05 23:39:07.700456 (MainThread): Connection 'model.github.issue_assignees' was left open.
2020-05-05 23:39:07.766269 (MainThread): 
2020-05-05 23:39:07.766435 (MainThread): Completed with 4 errors and 0 warnings:
2020-05-05 23:39:07.766574 (MainThread): 
2020-05-05 23:39:07.766669 (MainThread): Database Error in model stg_github_card (models/base/stg_github_card.sql)
2020-05-05 23:39:07.766755 (MainThread):   Unrecognized name: upated_at; Did you mean updated_at? at [17:7]
2020-05-05 23:39:07.766862 (MainThread):   compiled SQL at target/run/github/base/stg_github_card.sql
2020-05-05 23:39:07.766998 (MainThread): 
2020-05-05 23:39:07.767086 (MainThread): Database Error in model issue_close_stack (models/transform/intermediate/issue_close_stack.sql)
2020-05-05 23:39:07.767188 (MainThread):   Unrecognized name: issue_id; Did you mean issue? at [19:7]
2020-05-05 23:39:07.767303 (MainThread):   compiled SQL at target/run/github/transform/intermediate/issue_close_stack.sql
2020-05-05 23:39:07.767449 (MainThread): 
2020-05-05 23:39:07.767537 (MainThread): Database Error in model issue_blocked_time (models/transform/intermediate/issue_blocked_time.sql)
2020-05-05 23:39:07.767657 (MainThread):   Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_label_history"
2020-05-05 23:39:07.767762 (MainThread):   compiled SQL at target/run/github/transform/intermediate/issue_blocked_time.sql
2020-05-05 23:39:07.767859 (MainThread): 
2020-05-05 23:39:07.767981 (MainThread): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
2020-05-05 23:39:07.768099 (MainThread):   Duplicate alias pull_request_review for WITH subquery at [17:4]
2020-05-05 23:39:07.768191 (MainThread):   compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:39:07.768363 (MainThread): 
Done. PASS=24 WARN=0 ERROR=4 SKIP=0 TOTAL=28
2020-05-05 23:39:07.768525 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112943cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111719f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111719ed0>]}
2020-05-05 23:39:07.768699 (MainThread): Flushing usage events
2020-05-05 23:43:10.106868 (MainThread): Running with dbt=0.16.1
2020-05-05 23:43:10.249717 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:43:10.250811 (MainThread): Tracking: tracking
2020-05-05 23:43:10.257299 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10560efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b450d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105611450>]}
2020-05-05 23:43:10.278464 (MainThread): Partial parsing not enabled
2020-05-05 23:43:10.280574 (MainThread): Parsing macros/core.sql
2020-05-05 23:43:10.285118 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:43:10.294398 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:43:10.296423 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:43:10.315236 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:43:10.351424 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:43:10.376006 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:43:10.378083 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:43:10.384645 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:43:10.399879 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:43:10.407451 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:43:10.414381 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:43:10.419800 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:43:10.420817 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:43:10.421936 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:43:10.423853 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:43:10.426671 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:43:10.436808 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:43:10.439218 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:43:10.440521 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:43:10.484992 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:43:10.486291 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:43:10.487378 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:43:10.488570 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:43:10.491253 (MainThread): Parsing macros/etc.sql
2020-05-05 23:43:10.492557 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:43:10.500369 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:43:10.523377 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:43:10.526031 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:43:10.527674 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:43:10.539065 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:43:10.553328 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:43:10.574534 (MainThread): Partial parsing not enabled
2020-05-05 23:43:10.609066 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:43:10.609204 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:43:10.632535 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:43:10.632670 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.639413 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:43:10.639512 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.654637 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:43:10.654881 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.662554 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:43:10.662687 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.669598 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:43:10.669743 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.676046 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:43:10.676158 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.682156 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:43:10.682270 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.688912 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:43:10.689022 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.695283 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:43:10.695404 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.701179 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:43:10.701292 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.708175 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:43:10.708288 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.713966 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:43:10.714066 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.724967 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:43:10.725336 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.731575 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:43:10.731695 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.737368 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:43:10.737470 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.743088 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:43:10.743195 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.749344 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:43:10.749521 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.755466 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:43:10.755590 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.762116 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:43:10.762236 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.767702 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:43:10.767791 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.773475 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:43:10.773577 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.779223 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:43:10.779317 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.785012 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:43:10.785114 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.791184 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:43:10.791290 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.797483 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:43:10.797600 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.803646 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:43:10.803757 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.809304 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:43:10.809399 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:10.939229 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:43:11.181691 (MainThread): Found 28 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 15 sources
2020-05-05 23:43:11.199373 (MainThread): 
2020-05-05 23:43:11.199741 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:43:11.199831 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:43:11.251308 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:43:11.251603 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:43:12.134860 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:43:12.135252 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:43:12.135568 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:43:12.326355 (MainThread): 16:43:12 | Concurrency: 4 threads (target='dev')
2020-05-05 23:43:12.326544 (MainThread): 16:43:12 | 
2020-05-05 23:43:12.328888 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:43:12.329081 (Thread-1): 16:43:12 | 1 of 28 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:43:12.329243 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:43:12.329399 (Thread-2): 16:43:12 | 2 of 28 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:43:12.329676 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:43:12.329768 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:43:12.329889 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:43:12.335108 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:43:12.335318 (Thread-3): 16:43:12 | 3 of 28 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:43:12.335761 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:43:12.335906 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:43:12.336053 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:43:12.347691 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:43:12.347903 (Thread-4): 16:43:12 | 4 of 28 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:43:12.351381 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:43:12.351807 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:43:12.351965 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:43:12.352100 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:43:12.358916 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:43:12.359840 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:43:12.360307 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:43:12.360851 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:43:12.361073 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:43:12.367628 (Thread-2): finished collecting timing info
2020-05-05 23:43:12.374212 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:43:12.374436 (Thread-3): finished collecting timing info
2020-05-05 23:43:12.386071 (Thread-1): finished collecting timing info
2020-05-05 23:43:12.457146 (Thread-4): finished collecting timing info
2020-05-05 23:43:12.868373 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:43:12.868965 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:43:12.869281 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:43:12.869756 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:43:12.871541 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:43:12.872090 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:43:12.872212 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:43:12.873823 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:43:13.573771 (Thread-1): finished collecting timing info
2020-05-05 23:43:13.574660 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dfdb50>]}
2020-05-05 23:43:13.574929 (Thread-1): 16:43:13 | 1 of 28 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.24s]
2020-05-05 23:43:13.575081 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:43:13.575226 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:43:13.575492 (Thread-1): 16:43:13 | 5 of 28 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:43:13.575850 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:43:13.575969 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:43:13.576075 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:43:13.583834 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:43:13.584204 (Thread-1): finished collecting timing info
2020-05-05 23:43:13.588776 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:43:13.589160 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:43:13.693338 (Thread-4): finished collecting timing info
2020-05-05 23:43:13.694418 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072c4b90>]}
2020-05-05 23:43:13.694779 (Thread-4): 16:43:13 | 4 of 28 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.33s]
2020-05-05 23:43:13.695147 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:43:13.695386 (Thread-4): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:43:13.695564 (Thread-4): 16:43:13 | 6 of 28 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:43:13.695905 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:43:13.696022 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:43:13.696140 (Thread-4): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:43:13.704805 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:43:13.708242 (Thread-2): finished collecting timing info
2020-05-05 23:43:13.708829 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4e810>]}
2020-05-05 23:43:13.709050 (Thread-2): 16:43:13 | 2 of 28 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.37s]
2020-05-05 23:43:13.709228 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:43:13.709374 (Thread-2): Began running node model.github.stg_github_issue_label
2020-05-05 23:43:13.709508 (Thread-2): 16:43:13 | 7 of 28 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:43:13.709750 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:43:13.709837 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:43:13.709923 (Thread-2): Compiling model.github.stg_github_issue_label
2020-05-05 23:43:13.716435 (Thread-4): finished collecting timing info
2020-05-05 23:43:13.716941 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:43:13.721542 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:43:13.722208 (Thread-2): finished collecting timing info
2020-05-05 23:43:13.727003 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:43:13.727271 (Thread-4): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:43:13.728383 (Thread-2): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:43:13.989649 (Thread-3): finished collecting timing info
2020-05-05 23:43:13.992488 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d4ef10>]}
2020-05-05 23:43:13.993535 (Thread-3): 16:43:13 | 3 of 28 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.64s]
2020-05-05 23:43:13.993864 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:43:13.994070 (Thread-3): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:43:13.994260 (Thread-3): 16:43:13 | 8 of 28 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:43:13.994614 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:43:13.994978 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:43:13.995364 (Thread-3): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:43:14.003966 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:43:14.004914 (Thread-3): finished collecting timing info
2020-05-05 23:43:14.010805 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:43:14.011277 (Thread-3): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:43:14.230426 (Thread-1): finished collecting timing info
2020-05-05 23:43:14.231446 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dfd590>]}
2020-05-05 23:43:14.231747 (Thread-1): 16:43:14 | 5 of 28 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.66s]
2020-05-05 23:43:14.231915 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:43:14.232082 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:43:14.232261 (Thread-1): 16:43:14 | 9 of 28 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:43:14.232717 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:43:14.232851 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:43:14.232971 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:43:14.240851 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:43:14.241273 (Thread-1): finished collecting timing info
2020-05-05 23:43:14.245754 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:43:14.246114 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:43:14.273996 (Thread-2): finished collecting timing info
2020-05-05 23:43:14.274914 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107409710>]}
2020-05-05 23:43:14.275214 (Thread-2): 16:43:14 | 7 of 28 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.56s]
2020-05-05 23:43:14.275377 (Thread-2): Finished running node model.github.stg_github_issue_label
2020-05-05 23:43:14.275545 (Thread-2): Began running node model.github.stg_github_issue_merged
2020-05-05 23:43:14.275992 (Thread-2): 16:43:14 | 10 of 28 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:43:14.276345 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:43:14.276463 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:43:14.276578 (Thread-2): Compiling model.github.stg_github_issue_merged
2020-05-05 23:43:14.284429 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:43:14.284805 (Thread-2): finished collecting timing info
2020-05-05 23:43:14.289237 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:43:14.289594 (Thread-2): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:43:14.364304 (Thread-4): finished collecting timing info
2020-05-05 23:43:14.365340 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d65dd0>]}
2020-05-05 23:43:14.365700 (Thread-4): 16:43:14 | 6 of 28 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.67s]
2020-05-05 23:43:14.365907 (Thread-4): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:43:14.366075 (Thread-4): Began running node model.github.stg_github_pull_request
2020-05-05 23:43:14.366243 (Thread-4): 16:43:14 | 11 of 28 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:43:14.366708 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:43:14.366979 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:43:14.367132 (Thread-4): Compiling model.github.stg_github_pull_request
2020-05-05 23:43:14.375462 (Thread-4): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:43:14.375863 (Thread-4): finished collecting timing info
2020-05-05 23:43:14.380292 (Thread-4): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:43:14.380670 (Thread-4): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id as pull_request_id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:43:14.592348 (Thread-3): finished collecting timing info
2020-05-05 23:43:14.593382 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f6d10>]}
2020-05-05 23:43:14.593751 (Thread-3): 16:43:14 | 8 of 28 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.60s]
2020-05-05 23:43:14.593955 (Thread-3): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:43:14.594159 (Thread-3): Began running node model.github.stg_github_repository
2020-05-05 23:43:14.594394 (Thread-3): 16:43:14 | 12 of 28 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:43:14.594967 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:43:14.595101 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:43:14.595227 (Thread-3): Compiling model.github.stg_github_repository
2020-05-05 23:43:14.603834 (Thread-3): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:43:14.604262 (Thread-3): finished collecting timing info
2020-05-05 23:43:14.608875 (Thread-3): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:43:14.610769 (Thread-3): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:43:14.911829 (Thread-2): finished collecting timing info
2020-05-05 23:43:14.912859 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072b9150>]}
2020-05-05 23:43:14.913222 (Thread-2): 16:43:14 | 10 of 28 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.64s]
2020-05-05 23:43:14.913421 (Thread-2): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:43:14.913623 (Thread-2): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:43:14.913830 (Thread-2): 16:43:14 | 13 of 28 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:43:14.914218 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:43:14.914376 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:43:14.914494 (Thread-2): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:43:14.923067 (Thread-2): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:43:14.923524 (Thread-2): finished collecting timing info
2020-05-05 23:43:14.928427 (Thread-2): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:43:14.928851 (Thread-2): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:43:14.974376 (Thread-1): finished collecting timing info
2020-05-05 23:43:14.975402 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073b7c50>]}
2020-05-05 23:43:14.975752 (Thread-1): 16:43:14 | 9 of 28 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.74s]
2020-05-05 23:43:14.975956 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:43:14.976158 (Thread-1): Began running node model.github.stg_github_milestone
2020-05-05 23:43:14.976365 (Thread-1): 16:43:14 | 14 of 28 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:43:14.976772 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:43:14.976891 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:43:14.977010 (Thread-1): Compiling model.github.stg_github_milestone
2020-05-05 23:43:14.985812 (Thread-1): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:43:14.986264 (Thread-1): finished collecting timing info
2020-05-05 23:43:14.991971 (Thread-1): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:43:14.992475 (Thread-1): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:43:15.061210 (Thread-4): finished collecting timing info
2020-05-05 23:43:15.063182 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d45990>]}
2020-05-05 23:43:15.064030 (Thread-4): 16:43:15 | 11 of 28 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.70s]
2020-05-05 23:43:15.064219 (Thread-4): Finished running node model.github.stg_github_pull_request
2020-05-05 23:43:15.065052 (Thread-4): Began running node model.github.stg_github_issue_comment
2020-05-05 23:43:15.065268 (Thread-4): 16:43:15 | 15 of 28 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:43:15.065621 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:43:15.065743 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:43:15.065865 (Thread-4): Compiling model.github.stg_github_issue_comment
2020-05-05 23:43:15.074200 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:43:15.075108 (Thread-4): finished collecting timing info
2020-05-05 23:43:15.079624 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:43:15.080289 (Thread-4): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:43:15.213919 (Thread-3): finished collecting timing info
2020-05-05 23:43:15.214929 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f6d10>]}
2020-05-05 23:43:15.215288 (Thread-3): 16:43:15 | 12 of 28 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.62s]
2020-05-05 23:43:15.215489 (Thread-3): Finished running node model.github.stg_github_repository
2020-05-05 23:43:15.215692 (Thread-3): Began running node model.github.issue_status_windows
2020-05-05 23:43:15.215898 (Thread-3): 16:43:15 | 16 of 28 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:43:15.216260 (Thread-3): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:43:15.216377 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:43:15.216494 (Thread-3): Compiling model.github.issue_status_windows
2020-05-05 23:43:15.226451 (Thread-3): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:43:15.226871 (Thread-3): finished collecting timing info
2020-05-05 23:43:15.231301 (Thread-3): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:43:15.231722 (Thread-3): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from github.issue_project_history
join github.card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:43:15.521313 (Thread-2): finished collecting timing info
2020-05-05 23:43:15.522232 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107410450>]}
2020-05-05 23:43:15.522525 (Thread-2): 16:43:15 | 13 of 28 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.61s]
2020-05-05 23:43:15.522689 (Thread-2): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:43:15.522953 (Thread-2): Began running node model.github.issue_close_stack
2020-05-05 23:43:15.523169 (Thread-2): 16:43:15 | 17 of 28 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:43:15.523514 (Thread-2): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:43:15.523635 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:43:15.523828 (Thread-2): Compiling model.github.issue_close_stack
2020-05-05 23:43:15.533428 (Thread-2): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:43:15.533870 (Thread-2): finished collecting timing info
2020-05-05 23:43:15.538424 (Thread-2): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:43:15.538799 (Thread-2): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:43:15.545665 (Thread-1): finished collecting timing info
2020-05-05 23:43:15.546394 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105de6d90>]}
2020-05-05 23:43:15.546625 (Thread-1): 16:43:15 | 14 of 28 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.57s]
2020-05-05 23:43:15.546754 (Thread-1): Finished running node model.github.stg_github_milestone
2020-05-05 23:43:15.546880 (Thread-1): Began running node model.github.issue_labels
2020-05-05 23:43:15.547005 (Thread-1): 16:43:15 | 18 of 28 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:43:15.547349 (Thread-1): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:43:15.547450 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:43:15.547540 (Thread-1): Compiling model.github.issue_labels
2020-05-05 23:43:15.553997 (Thread-1): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:43:15.554361 (Thread-1): finished collecting timing info
2020-05-05 23:43:15.559257 (Thread-1): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:43:15.559706 (Thread-1): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:43:15.635979 (Thread-4): finished collecting timing info
2020-05-05 23:43:15.637194 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107418690>]}
2020-05-05 23:43:15.637505 (Thread-4): 16:43:15 | 15 of 28 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.57s]
2020-05-05 23:43:15.637742 (Thread-4): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:43:15.637948 (Thread-4): Began running node model.github.issue_assignees
2020-05-05 23:43:15.638129 (Thread-4): 16:43:15 | 19 of 28 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:43:15.638466 (Thread-4): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:43:15.638585 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:43:15.638705 (Thread-4): Compiling model.github.issue_assignees
2020-05-05 23:43:15.647908 (Thread-4): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:43:15.648361 (Thread-4): finished collecting timing info
2020-05-05 23:43:15.653759 (Thread-4): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:43:15.654167 (Thread-4): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:43:15.768352 (Thread-3): finished collecting timing info
2020-05-05 23:43:15.769365 (Thread-3): Database Error in model issue_status_windows (models/transform/intermediate/issue_status_windows.sql)
  Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_project_history", "github.card"
  compiled SQL at target/run/github/transform/intermediate/issue_status_windows.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/a036ef47-f7e0-490a-a883-a150c9cb6d6f?maxResults=0&location=US: Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_project_history", "github.card"

(job ID: a036ef47-f7e0-490a-a883-a150c9cb6d6f)

                                                                           -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
   5:  OPTIONS()
   6:  as (
   7:    with issue_project_history as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  11:  
  12:), card as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  16:  
  17:)
  18:
  19:select
  20:  issue_project_history.issue_id,
  21:  issue_project_history.project_id,
  22:  issue_project_history.column_name,
  23:  issue_project_history.removed,
  24:  issue_project_history.updated_at as valid_starting,
  25:  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
  26:    if(card.archived, card.updated_at, null),
  27:    current_timestamp()) as valid_until
  28:from github.issue_project_history
  29:join github.card on issue_project_history.card_id = card.id
  30:  and not coalesce(card.is_deleted, false)
  31:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issue_status_windows (models/transform/intermediate/issue_status_windows.sql)
  Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_project_history", "github.card"
  compiled SQL at target/run/github/transform/intermediate/issue_status_windows.sql
2020-05-05 23:43:15.775641 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072af610>]}
2020-05-05 23:43:15.775947 (Thread-3): 16:43:15 | 16 of 28 ERROR creating view model dbt_erik.issue_status_windows..... [ERROR in 0.56s]
2020-05-05 23:43:15.776114 (Thread-3): Finished running node model.github.issue_status_windows
2020-05-05 23:43:15.776285 (Thread-3): Began running node model.github.pull_request_reviewers
2020-05-05 23:43:15.776452 (Thread-3): 16:43:15 | 20 of 28 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:43:15.777003 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:43:15.777141 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:43:15.777267 (Thread-3): Compiling model.github.pull_request_reviewers
2020-05-05 23:43:15.819517 (Thread-3): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:43:15.820045 (Thread-3): finished collecting timing info
2020-05-05 23:43:15.825546 (Thread-3): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:43:15.826047 (Thread-3): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:43:16.241723 (Thread-2): finished collecting timing info
2020-05-05 23:43:16.242804 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10731aed0>]}
2020-05-05 23:43:16.243179 (Thread-2): 16:43:16 | 17 of 28 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.72s]
2020-05-05 23:43:16.243384 (Thread-2): Finished running node model.github.issue_close_stack
2020-05-05 23:43:16.243587 (Thread-2): Began running node model.github.issue_blocked_time
2020-05-05 23:43:16.244069 (Thread-2): 16:43:16 | 21 of 28 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:43:16.244440 (Thread-2): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:43:16.244563 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:43:16.244683 (Thread-2): Compiling model.github.issue_blocked_time
2020-05-05 23:43:16.252801 (Thread-2): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:43:16.253289 (Thread-2): finished collecting timing info
2020-05-05 23:43:16.257985 (Thread-2): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:43:16.258425 (Thread-2): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:43:16.262268 (Thread-1): finished collecting timing info
2020-05-05 23:43:16.262881 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107431e10>]}
2020-05-05 23:43:16.263368 (Thread-1): 16:43:16 | 18 of 28 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.72s]
2020-05-05 23:43:16.263817 (Thread-1): Finished running node model.github.issue_labels
2020-05-05 23:43:16.264104 (Thread-1): Began running node model.github.pull_request_times
2020-05-05 23:43:16.264289 (Thread-1): 16:43:16 | 22 of 28 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:43:16.265055 (Thread-1): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:43:16.265421 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:43:16.265670 (Thread-1): Compiling model.github.pull_request_times
2020-05-05 23:43:16.276860 (Thread-1): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:43:16.277234 (Thread-1): finished collecting timing info
2020-05-05 23:43:16.282153 (Thread-1): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:43:16.283089 (Thread-1): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join github.requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join github.pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:43:16.289622 (Thread-4): finished collecting timing info
2020-05-05 23:43:16.290266 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10742de10>]}
2020-05-05 23:43:16.290489 (Thread-4): 16:43:16 | 19 of 28 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.65s]
2020-05-05 23:43:16.290613 (Thread-4): Finished running node model.github.issue_assignees
2020-05-05 23:43:16.290739 (Thread-4): Began running node model.github.issue_inbox_time
2020-05-05 23:43:16.290862 (Thread-4): 16:43:16 | 23 of 28 SKIP relation dbt_erik.issue_inbox_time..................... [SKIP]
2020-05-05 23:43:16.290998 (Thread-4): Finished running node model.github.issue_inbox_time
2020-05-05 23:43:16.291253 (Thread-4): Began running node model.github.issue_projects
2020-05-05 23:43:16.291477 (Thread-4): 16:43:16 | 24 of 28 SKIP relation dbt_erik.issue_projects....................... [SKIP]
2020-05-05 23:43:16.291603 (Thread-4): Finished running node model.github.issue_projects
2020-05-05 23:43:16.291716 (Thread-4): Began running node model.github.issue_open_length
2020-05-05 23:43:16.291830 (Thread-4): 16:43:16 | 25 of 28 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:43:16.292080 (Thread-4): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:43:16.292217 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:43:16.292322 (Thread-4): Compiling model.github.issue_open_length
2020-05-05 23:43:16.299330 (Thread-4): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:43:16.299722 (Thread-4): finished collecting timing info
2020-05-05 23:43:16.303860 (Thread-4): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:43:16.304219 (Thread-4): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:43:16.606578 (Thread-3): finished collecting timing info
2020-05-05 23:43:16.607601 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105de17d0>]}
2020-05-05 23:43:16.607963 (Thread-3): 16:43:16 | 20 of 28 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.83s]
2020-05-05 23:43:16.608163 (Thread-3): Finished running node model.github.pull_request_reviewers
2020-05-05 23:43:16.764747 (Thread-1): finished collecting timing info
2020-05-05 23:43:16.766245 (Thread-1): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside pull_request at [49:105]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/15518e3d-8de7-4119-aa00-43f86650baa1?maxResults=0&location=US: Name id not found inside pull_request at [49:105]

(job ID: 15518e3d-8de7-4119-aa00-43f86650baa1)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
   5:  OPTIONS()
   6:  as (
   7:    with pull_request_review as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  11:  
  12:), pull_request as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  16:
  17:), requested_reviewer_history as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  21:
  22:), issue as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  26:  
  27:), issue_merged as (
  28:
  29:    select
  30:      issue_id,
  31:      min(merged_at) as merged_at
  32:      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  33:    group by 1
  34:
  35:), first_request_time as (
  36:
  37:    select
  38:      pull_request.issue_id,
  39:      pull_request.id,
  40:      min(requested_reviewer_history.created_at) as time_of_first_request,
  41:      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
  42:      -- Finds the first review that is by the requested reviewer and is not a dismissal
  43:      min(if(
  44:            requested_reviewer_history.requested_id = pull_request_review.user_id
  45:            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
  46:            pull_request_review.submitted_at,
  47:            NULL)) as time_of_first_requested_reviewer_review
  48:    from pull_request
  49:    join github.requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
  50:    left join github.pull_request_review on pull_request_review.pull_request_id = pull_request.id
  51:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
  52:    group by 1, 2
  53:
  54:)
  55:
  56:select
  57:  first_request_time.issue_id,
  58:  merged_at,
  59:  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  60:  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  61:  timestamp_diff(
  62:    least(
  63:    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
  64:    coalesce(issue.closed_at, current_timestamp())
  65:  ),
  66:  time_of_first_request,
  67:  second)/3600 as hours_first_action_post_request,
  68:  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
  69:from first_request_time
  70:join issue on first_request_time.issue_id = issue.id
  71:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  72:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside pull_request at [49:105]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:43:16.767727 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107352a90>]}
2020-05-05 23:43:16.768060 (Thread-1): 16:43:16 | 22 of 28 ERROR creating view model dbt_erik.pull_request_times....... [ERROR in 0.50s]
2020-05-05 23:43:16.768260 (Thread-1): Finished running node model.github.pull_request_times
2020-05-05 23:43:16.926673 (Thread-2): finished collecting timing info
2020-05-05 23:43:16.927729 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107235f10>]}
2020-05-05 23:43:16.928088 (Thread-2): 16:43:16 | 21 of 28 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.68s]
2020-05-05 23:43:16.928289 (Thread-2): Finished running node model.github.issue_blocked_time
2020-05-05 23:43:17.209176 (Thread-4): finished collecting timing info
2020-05-05 23:43:17.210256 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6876e61-ff3f-4873-b10d-1bff0371daf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a96450>]}
2020-05-05 23:43:17.210616 (Thread-4): 16:43:17 | 25 of 28 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.92s]
2020-05-05 23:43:17.210819 (Thread-4): Finished running node model.github.issue_open_length
2020-05-05 23:43:17.211285 (Thread-3): Began running node model.github.github_issues
2020-05-05 23:43:17.211509 (Thread-1): Began running node model.github.github_pull_requests
2020-05-05 23:43:17.211672 (Thread-3): 16:43:17 | 26 of 28 SKIP relation dbt_erik.github_issues........................ [SKIP]
2020-05-05 23:43:17.211840 (Thread-1): 16:43:17 | 27 of 28 SKIP relation dbt_erik.github_pull_requests................. [SKIP]
2020-05-05 23:43:17.212003 (Thread-3): Finished running node model.github.github_issues
2020-05-05 23:43:17.212273 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-05 23:43:17.212699 (Thread-4): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:43:17.212877 (Thread-4): 16:43:17 | 28 of 28 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:43:17.213040 (Thread-4): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:43:17.317139 (MainThread): 16:43:17 | 
2020-05-05 23:43:17.317607 (MainThread): 16:43:17 | Finished running 28 view models in 6.12s.
2020-05-05 23:43:17.317926 (MainThread): Connection 'master' was left open.
2020-05-05 23:43:17.318167 (MainThread): Connection 'model.github.pull_request_times' was left open.
2020-05-05 23:43:17.318363 (MainThread): Connection 'model.github.issue_blocked_time' was left open.
2020-05-05 23:43:17.318513 (MainThread): Connection 'model.github.pull_request_reviewers' was left open.
2020-05-05 23:43:17.318659 (MainThread): Connection 'model.github.issue_open_length' was left open.
2020-05-05 23:43:17.385567 (MainThread): 
2020-05-05 23:43:17.385776 (MainThread): Completed with 2 errors and 0 warnings:
2020-05-05 23:43:17.386010 (MainThread): 
2020-05-05 23:43:17.386220 (MainThread): Database Error in model issue_status_windows (models/transform/intermediate/issue_status_windows.sql)
2020-05-05 23:43:17.386379 (MainThread):   Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.issue_project_history", "github.card"
2020-05-05 23:43:17.386564 (MainThread):   compiled SQL at target/run/github/transform/intermediate/issue_status_windows.sql
2020-05-05 23:43:17.386717 (MainThread): 
2020-05-05 23:43:17.386924 (MainThread): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
2020-05-05 23:43:17.387059 (MainThread):   Name id not found inside pull_request at [49:105]
2020-05-05 23:43:17.387184 (MainThread):   compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:43:17.387319 (MainThread): 
Done. PASS=26 WARN=0 ERROR=2 SKIP=0 TOTAL=28
2020-05-05 23:43:17.387468 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107442250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e981d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107422c90>]}
2020-05-05 23:43:17.387635 (MainThread): Flushing usage events
2020-05-05 23:44:04.782505 (MainThread): Running with dbt=0.16.1
2020-05-05 23:44:04.929743 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:44:04.930668 (MainThread): Tracking: tracking
2020-05-05 23:44:04.937190 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110edae90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f0c710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109d9190>]}
2020-05-05 23:44:04.959479 (MainThread): Partial parsing not enabled
2020-05-05 23:44:04.961665 (MainThread): Parsing macros/core.sql
2020-05-05 23:44:04.966267 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:44:04.974978 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:44:04.977103 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:44:04.996361 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:44:05.032780 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:44:05.056470 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:44:05.058949 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:44:05.065873 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:44:05.079697 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:44:05.088057 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:44:05.094929 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:44:05.100331 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:44:05.101354 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:44:05.102583 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:44:05.104427 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:44:05.106867 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:44:05.116590 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:44:05.119062 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:44:05.120831 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:44:05.166791 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:44:05.168188 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:44:05.169357 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:44:05.170627 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:44:05.173125 (MainThread): Parsing macros/etc.sql
2020-05-05 23:44:05.173830 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:44:05.181613 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:44:05.205117 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:44:05.207498 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:44:05.209022 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:44:05.220669 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:44:05.234700 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:44:05.255299 (MainThread): Partial parsing not enabled
2020-05-05 23:44:05.289967 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:44:05.290109 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:44:05.312796 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:44:05.312930 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.320802 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:44:05.320937 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.336602 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:44:05.336735 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.343425 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:44:05.343537 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.349994 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:44:05.350100 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.357981 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:44:05.358109 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.364007 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:44:05.364122 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.370866 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:44:05.370987 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.376938 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:44:05.377053 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.382624 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:44:05.382757 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.390142 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:44:05.390269 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.396191 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:44:05.396306 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.405969 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:44:05.406095 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.412016 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:44:05.412131 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.418135 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:44:05.418290 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.424739 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:44:05.424861 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.431140 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:44:05.431255 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.437488 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:44:05.437612 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.443150 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:44:05.443251 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.449064 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:44:05.449175 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.455861 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:44:05.456018 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.461955 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:44:05.462071 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.467581 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:44:05.467679 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.473362 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:44:05.473472 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.479077 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:44:05.479185 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.485046 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:44:05.485154 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.491632 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:44:05.491758 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.621913 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:44:05.865648 (MainThread): Found 28 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 15 sources
2020-05-05 23:44:05.882276 (MainThread): 
2020-05-05 23:44:05.882635 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:44:05.882732 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:44:05.935041 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:44:05.935256 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:44:06.911709 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:44:06.912109 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:44:06.912429 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:44:07.083765 (MainThread): 16:44:07 | Concurrency: 4 threads (target='dev')
2020-05-05 23:44:07.083994 (MainThread): 16:44:07 | 
2020-05-05 23:44:07.086315 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:44:07.086558 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:44:07.086732 (Thread-1): 16:44:07 | 1 of 28 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:44:07.086831 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:44:07.086977 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:44:07.087101 (Thread-2): 16:44:07 | 2 of 28 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:44:07.087447 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:44:07.087564 (Thread-3): 16:44:07 | 3 of 28 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:44:07.087707 (Thread-4): 16:44:07 | 4 of 28 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:44:07.088052 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:44:07.088155 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:44:07.088453 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:44:07.088765 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:44:07.088851 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:44:07.088969 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:44:07.089066 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:44:07.089179 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:44:07.089331 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:44:07.101830 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:44:07.103754 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:44:07.104004 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:44:07.109949 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:44:07.116505 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:44:07.124310 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:44:07.124765 (Thread-1): finished collecting timing info
2020-05-05 23:44:07.130567 (Thread-2): finished collecting timing info
2020-05-05 23:44:07.137166 (Thread-3): finished collecting timing info
2020-05-05 23:44:07.142700 (Thread-4): finished collecting timing info
2020-05-05 23:44:07.586339 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:44:07.594936 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:44:07.595487 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:44:07.617177 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:44:07.619159 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:44:07.620198 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:44:07.620328 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:44:07.620914 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:44:08.318013 (Thread-1): finished collecting timing info
2020-05-05 23:44:08.319118 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111150a50>]}
2020-05-05 23:44:08.319644 (Thread-1): 16:44:08 | 1 of 28 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.23s]
2020-05-05 23:44:08.319894 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:44:08.320123 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:44:08.320307 (Thread-1): 16:44:08 | 5 of 28 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:44:08.320675 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:44:08.320801 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:44:08.320927 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:44:08.330234 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:44:08.330692 (Thread-1): finished collecting timing info
2020-05-05 23:44:08.335994 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:44:08.338169 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:44:08.351902 (Thread-4): finished collecting timing info
2020-05-05 23:44:08.352675 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111118dd0>]}
2020-05-05 23:44:08.352957 (Thread-4): 16:44:08 | 4 of 28 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.26s]
2020-05-05 23:44:08.353087 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:44:08.353213 (Thread-4): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:44:08.353435 (Thread-4): 16:44:08 | 6 of 28 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:44:08.353705 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:44:08.353804 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:44:08.353903 (Thread-4): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:44:08.360853 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:44:08.361226 (Thread-4): finished collecting timing info
2020-05-05 23:44:08.365421 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:44:08.365744 (Thread-4): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:44:08.384483 (Thread-3): finished collecting timing info
2020-05-05 23:44:08.385522 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112622490>]}
2020-05-05 23:44:08.385883 (Thread-3): 16:44:08 | 3 of 28 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.30s]
2020-05-05 23:44:08.386089 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:44:08.386304 (Thread-3): Began running node model.github.stg_github_issue_label
2020-05-05 23:44:08.386517 (Thread-3): 16:44:08 | 7 of 28 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:44:08.386895 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:44:08.387069 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:44:08.387500 (Thread-3): Compiling model.github.stg_github_issue_label
2020-05-05 23:44:08.396341 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:44:08.396735 (Thread-3): finished collecting timing info
2020-05-05 23:44:08.401148 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:44:08.401535 (Thread-3): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:44:08.485883 (Thread-2): finished collecting timing info
2020-05-05 23:44:08.487134 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11277cd50>]}
2020-05-05 23:44:08.487527 (Thread-2): 16:44:08 | 2 of 28 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.40s]
2020-05-05 23:44:08.487767 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:44:08.488129 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:44:08.488362 (Thread-2): 16:44:08 | 8 of 28 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:44:08.488804 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:44:08.489095 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:44:08.489394 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:44:08.498566 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:44:08.499032 (Thread-2): finished collecting timing info
2020-05-05 23:44:08.504629 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:44:08.505167 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:44:09.043746 (Thread-4): finished collecting timing info
2020-05-05 23:44:09.044831 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112608710>]}
2020-05-05 23:44:09.045211 (Thread-4): 16:44:09 | 6 of 28 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.69s]
2020-05-05 23:44:09.045423 (Thread-4): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:44:09.045638 (Thread-4): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:44:09.045854 (Thread-4): 16:44:09 | 9 of 28 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:44:09.046259 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:44:09.046542 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:44:09.046698 (Thread-4): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:44:09.055403 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:44:09.055959 (Thread-4): finished collecting timing info
2020-05-05 23:44:09.061129 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:44:09.061524 (Thread-4): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:44:09.070778 (Thread-3): finished collecting timing info
2020-05-05 23:44:09.071455 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127ba290>]}
2020-05-05 23:44:09.071699 (Thread-3): 16:44:09 | 7 of 28 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.68s]
2020-05-05 23:44:09.072455 (Thread-3): Finished running node model.github.stg_github_issue_label
2020-05-05 23:44:09.072620 (Thread-3): Began running node model.github.stg_github_issue_merged
2020-05-05 23:44:09.072761 (Thread-3): 16:44:09 | 10 of 28 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:44:09.073036 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:44:09.073130 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:44:09.073224 (Thread-3): Compiling model.github.stg_github_issue_merged
2020-05-05 23:44:09.082394 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:44:09.086291 (Thread-2): finished collecting timing info
2020-05-05 23:44:09.087176 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11277a310>]}
2020-05-05 23:44:09.087669 (Thread-2): 16:44:09 | 8 of 28 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.60s]
2020-05-05 23:44:09.087833 (Thread-3): finished collecting timing info
2020-05-05 23:44:09.088492 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:44:09.092870 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:44:09.093431 (Thread-2): Began running node model.github.stg_github_pull_request
2020-05-05 23:44:09.093869 (Thread-2): 16:44:09 | 11 of 28 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:44:09.094145 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:44:09.094247 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:44:09.094338 (Thread-2): Compiling model.github.stg_github_pull_request
2020-05-05 23:44:09.100858 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:44:09.101293 (Thread-3): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:44:09.102173 (Thread-2): finished collecting timing info
2020-05-05 23:44:09.106937 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:44:09.107602 (Thread-2): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id as pull_request_id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:44:09.213188 (Thread-1): finished collecting timing info
2020-05-05 23:44:09.214233 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126ce610>]}
2020-05-05 23:44:09.214604 (Thread-1): 16:44:09 | 5 of 28 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.89s]
2020-05-05 23:44:09.214816 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:44:09.215028 (Thread-1): Began running node model.github.stg_github_repository
2020-05-05 23:44:09.215240 (Thread-1): 16:44:09 | 12 of 28 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:44:09.215644 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:44:09.215768 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:44:09.215890 (Thread-1): Compiling model.github.stg_github_repository
2020-05-05 23:44:09.225318 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:44:09.225829 (Thread-1): finished collecting timing info
2020-05-05 23:44:09.230571 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:44:09.230922 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:44:09.786708 (Thread-4): finished collecting timing info
2020-05-05 23:44:09.787967 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112682590>]}
2020-05-05 23:44:09.788387 (Thread-4): 16:44:09 | 9 of 28 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.74s]
2020-05-05 23:44:09.788638 (Thread-4): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:44:09.788904 (Thread-4): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:44:09.789088 (Thread-4): 16:44:09 | 13 of 28 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:44:09.790286 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:44:09.790563 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:44:09.790921 (Thread-4): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:44:09.799587 (Thread-4): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:44:09.802386 (Thread-2): finished collecting timing info
2020-05-05 23:44:09.803009 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112699390>]}
2020-05-05 23:44:09.803246 (Thread-2): 16:44:09 | 11 of 28 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.71s]
2020-05-05 23:44:09.803445 (Thread-2): Finished running node model.github.stg_github_pull_request
2020-05-05 23:44:09.803616 (Thread-2): Began running node model.github.stg_github_milestone
2020-05-05 23:44:09.803750 (Thread-2): 16:44:09 | 14 of 28 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:44:09.804000 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:44:09.804094 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:44:09.804187 (Thread-2): Compiling model.github.stg_github_milestone
2020-05-05 23:44:09.811204 (Thread-2): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:44:09.811408 (Thread-4): finished collecting timing info
2020-05-05 23:44:09.816710 (Thread-4): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:44:09.817094 (Thread-2): finished collecting timing info
2020-05-05 23:44:09.822064 (Thread-2): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:44:09.822328 (Thread-4): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:44:09.823892 (Thread-2): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:44:09.871155 (Thread-1): finished collecting timing info
2020-05-05 23:44:09.872136 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112785390>]}
2020-05-05 23:44:09.873233 (Thread-1): 16:44:09 | 12 of 28 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.66s]
2020-05-05 23:44:09.873572 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-05 23:44:09.876930 (Thread-3): finished collecting timing info
2020-05-05 23:44:09.877194 (Thread-1): Began running node model.github.stg_github_issue_comment
2020-05-05 23:44:09.877881 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111e8390>]}
2020-05-05 23:44:09.878055 (Thread-1): 16:44:09 | 15 of 28 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:44:09.878296 (Thread-3): 16:44:09 | 10 of 28 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.80s]
2020-05-05 23:44:09.878587 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:44:09.878735 (Thread-3): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:44:09.878924 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:44:09.879072 (Thread-3): Began running node model.github.issue_close_stack
2020-05-05 23:44:09.879302 (Thread-1): Compiling model.github.stg_github_issue_comment
2020-05-05 23:44:09.879465 (Thread-3): 16:44:09 | 16 of 28 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:44:09.885246 (Thread-3): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:44:09.885367 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:44:09.885491 (Thread-3): Compiling model.github.issue_close_stack
2020-05-05 23:44:09.888808 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:44:09.896466 (Thread-3): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:44:09.896912 (Thread-1): finished collecting timing info
2020-05-05 23:44:09.901200 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:44:09.901406 (Thread-3): finished collecting timing info
2020-05-05 23:44:09.905549 (Thread-3): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:44:09.905930 (Thread-1): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:44:09.906845 (Thread-3): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:44:10.377179 (Thread-4): finished collecting timing info
2020-05-05 23:44:10.378254 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111c3090>]}
2020-05-05 23:44:10.378629 (Thread-4): 16:44:10 | 13 of 28 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.59s]
2020-05-05 23:44:10.378846 (Thread-4): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:44:10.379065 (Thread-4): Began running node model.github.issue_status_windows
2020-05-05 23:44:10.379285 (Thread-4): 16:44:10 | 17 of 28 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:44:10.379705 (Thread-4): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:44:10.379858 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:44:10.380009 (Thread-4): Compiling model.github.issue_status_windows
2020-05-05 23:44:10.390302 (Thread-4): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:44:10.390734 (Thread-4): finished collecting timing info
2020-05-05 23:44:10.395230 (Thread-4): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:44:10.395662 (Thread-4): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:44:10.479938 (Thread-1): finished collecting timing info
2020-05-05 23:44:10.481092 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126b93d0>]}
2020-05-05 23:44:10.481499 (Thread-1): 16:44:10 | 15 of 28 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.60s]
2020-05-05 23:44:10.481714 (Thread-1): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:44:10.481930 (Thread-1): Began running node model.github.issue_labels
2020-05-05 23:44:10.482158 (Thread-1): 16:44:10 | 18 of 28 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:44:10.482496 (Thread-1): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:44:10.482620 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:44:10.482744 (Thread-1): Compiling model.github.issue_labels
2020-05-05 23:44:10.491392 (Thread-1): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:44:10.491903 (Thread-1): finished collecting timing info
2020-05-05 23:44:10.496569 (Thread-1): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:44:10.496964 (Thread-1): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:44:10.544327 (Thread-2): finished collecting timing info
2020-05-05 23:44:10.547395 (Thread-3): finished collecting timing info
2020-05-05 23:44:10.548075 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126ad890>]}
2020-05-05 23:44:10.548626 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127949d0>]}
2020-05-05 23:44:10.548898 (Thread-2): 16:44:10 | 14 of 28 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.74s]
2020-05-05 23:44:10.549116 (Thread-3): 16:44:10 | 16 of 28 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.66s]
2020-05-05 23:44:10.549272 (Thread-2): Finished running node model.github.stg_github_milestone
2020-05-05 23:44:10.549422 (Thread-3): Finished running node model.github.issue_close_stack
2020-05-05 23:44:10.549608 (Thread-2): Began running node model.github.issue_assignees
2020-05-05 23:44:10.549758 (Thread-3): Began running node model.github.pull_request_reviewers
2020-05-05 23:44:10.550057 (Thread-2): 16:44:10 | 19 of 28 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:44:10.550178 (Thread-3): 16:44:10 | 20 of 28 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:44:10.550434 (Thread-2): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:44:10.550677 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:44:10.550787 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:44:10.550887 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:44:10.551014 (Thread-2): Compiling model.github.issue_assignees
2020-05-05 23:44:10.551123 (Thread-3): Compiling model.github.pull_request_reviewers
2020-05-05 23:44:10.559614 (Thread-2): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:44:10.566835 (Thread-3): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:44:10.567330 (Thread-2): finished collecting timing info
2020-05-05 23:44:10.573029 (Thread-3): finished collecting timing info
2020-05-05 23:44:10.606171 (Thread-2): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:44:10.609254 (Thread-3): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:44:10.609802 (Thread-2): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:44:10.610398 (Thread-3): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:44:10.885823 (Thread-4): finished collecting timing info
2020-05-05 23:44:10.887226 (Thread-4): Database Error in model issue_status_windows (models/transform/intermediate/issue_status_windows.sql)
  Name card_id not found inside issue_project_history at [29:36]
  compiled SQL at target/run/github/transform/intermediate/issue_status_windows.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/70c6ef54-1aaf-488f-bc73-3d9e25716f4b?maxResults=0&location=US: Name card_id not found inside issue_project_history at [29:36]

(job ID: 70c6ef54-1aaf-488f-bc73-3d9e25716f4b)

                                                                           -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
   5:  OPTIONS()
   6:  as (
   7:    with issue_project_history as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  11:  
  12:), card as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  16:  
  17:)
  18:
  19:select
  20:  issue_project_history.issue_id,
  21:  issue_project_history.project_id,
  22:  issue_project_history.column_name,
  23:  issue_project_history.removed,
  24:  issue_project_history.updated_at as valid_starting,
  25:  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
  26:    if(card.archived, card.updated_at, null),
  27:    current_timestamp()) as valid_until
  28:from issue_project_history
  29:join card on issue_project_history.card_id = card.id
  30:  and not coalesce(card.is_deleted, false)
  31:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issue_status_windows (models/transform/intermediate/issue_status_windows.sql)
  Name card_id not found inside issue_project_history at [29:36]
  compiled SQL at target/run/github/transform/intermediate/issue_status_windows.sql
2020-05-05 23:44:10.892769 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11273c2d0>]}
2020-05-05 23:44:10.893060 (Thread-4): 16:44:10 | 17 of 28 ERROR creating view model dbt_erik.issue_status_windows..... [ERROR in 0.51s]
2020-05-05 23:44:10.893229 (Thread-4): Finished running node model.github.issue_status_windows
2020-05-05 23:44:10.893406 (Thread-4): Began running node model.github.issue_blocked_time
2020-05-05 23:44:10.893799 (Thread-4): 16:44:10 | 21 of 28 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:44:10.894396 (Thread-4): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:44:10.894534 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:44:10.894658 (Thread-4): Compiling model.github.issue_blocked_time
2020-05-05 23:44:10.903121 (Thread-4): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:44:10.903551 (Thread-4): finished collecting timing info
2020-05-05 23:44:10.908224 (Thread-4): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:44:10.908653 (Thread-4): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:44:11.154086 (Thread-1): finished collecting timing info
2020-05-05 23:44:11.156308 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111f4910>]}
2020-05-05 23:44:11.159739 (Thread-2): finished collecting timing info
2020-05-05 23:44:11.160617 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112704f10>]}
2020-05-05 23:44:11.160880 (Thread-2): 16:44:11 | 19 of 28 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.61s]
2020-05-05 23:44:11.161130 (Thread-1): 16:44:11 | 18 of 28 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.67s]
2020-05-05 23:44:11.161297 (Thread-2): Finished running node model.github.issue_assignees
2020-05-05 23:44:11.161434 (Thread-1): Finished running node model.github.issue_labels
2020-05-05 23:44:11.161596 (Thread-2): Began running node model.github.pull_request_times
2020-05-05 23:44:11.161781 (Thread-1): Began running node model.github.issue_open_length
2020-05-05 23:44:11.162048 (Thread-2): 16:44:11 | 22 of 28 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:44:11.162189 (Thread-1): 16:44:11 | 23 of 28 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:44:11.162484 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:44:11.162846 (Thread-1): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:44:11.162937 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:44:11.163046 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:44:11.163156 (Thread-2): Compiling model.github.pull_request_times
2020-05-05 23:44:11.163255 (Thread-1): Compiling model.github.issue_open_length
2020-05-05 23:44:11.181064 (Thread-2): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:44:11.181548 (Thread-1): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:44:11.182114 (Thread-2): finished collecting timing info
2020-05-05 23:44:11.187266 (Thread-2): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:44:11.187437 (Thread-1): finished collecting timing info
2020-05-05 23:44:11.194050 (Thread-1): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:44:11.197043 (Thread-3): finished collecting timing info
2020-05-05 23:44:11.197787 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11110dfd0>]}
2020-05-05 23:44:11.198026 (Thread-2): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:44:11.198276 (Thread-3): 16:44:11 | 20 of 28 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.65s]
2020-05-05 23:44:11.199395 (Thread-1): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:44:11.199559 (Thread-3): Finished running node model.github.pull_request_reviewers
2020-05-05 23:44:11.200356 (Thread-3): Began running node model.github.issue_inbox_time
2020-05-05 23:44:11.200495 (Thread-3): 16:44:11 | 24 of 28 SKIP relation dbt_erik.issue_inbox_time..................... [SKIP]
2020-05-05 23:44:11.200834 (Thread-3): Finished running node model.github.issue_inbox_time
2020-05-05 23:44:11.200976 (Thread-3): Began running node model.github.issue_projects
2020-05-05 23:44:11.201481 (Thread-3): 16:44:11 | 25 of 28 SKIP relation dbt_erik.issue_projects....................... [SKIP]
2020-05-05 23:44:11.201825 (Thread-3): Finished running node model.github.issue_projects
2020-05-05 23:44:11.552884 (Thread-4): finished collecting timing info
2020-05-05 23:44:11.553986 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110f5410>]}
2020-05-05 23:44:11.554351 (Thread-4): 16:44:11 | 21 of 28 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.66s]
2020-05-05 23:44:11.554559 (Thread-4): Finished running node model.github.issue_blocked_time
2020-05-05 23:44:11.608605 (Thread-2): finished collecting timing info
2020-05-05 23:44:11.609676 (Thread-2): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside pull_request at [49:98]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/5d54d108-c41f-4aea-ace6-6cabfc0b58a3?maxResults=0&location=US: Name id not found inside pull_request at [49:98]

(job ID: 5d54d108-c41f-4aea-ace6-6cabfc0b58a3)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
   5:  OPTIONS()
   6:  as (
   7:    with pull_request_review as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  11:  
  12:), pull_request as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  16:
  17:), requested_reviewer_history as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  21:
  22:), issue as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  26:  
  27:), issue_merged as (
  28:
  29:    select
  30:      issue_id,
  31:      min(merged_at) as merged_at
  32:      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  33:    group by 1
  34:
  35:), first_request_time as (
  36:
  37:    select
  38:      pull_request.issue_id,
  39:      pull_request.id,
  40:      min(requested_reviewer_history.created_at) as time_of_first_request,
  41:      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
  42:      -- Finds the first review that is by the requested reviewer and is not a dismissal
  43:      min(if(
  44:            requested_reviewer_history.requested_id = pull_request_review.user_id
  45:            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
  46:            pull_request_review.submitted_at,
  47:            NULL)) as time_of_first_requested_reviewer_review
  48:    from pull_request
  49:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
  50:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
  51:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
  52:    group by 1, 2
  53:
  54:)
  55:
  56:select
  57:  first_request_time.issue_id,
  58:  merged_at,
  59:  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  60:  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  61:  timestamp_diff(
  62:    least(
  63:    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
  64:    coalesce(issue.closed_at, current_timestamp())
  65:  ),
  66:  time_of_first_request,
  67:  second)/3600 as hours_first_action_post_request,
  68:  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
  69:from first_request_time
  70:join issue on first_request_time.issue_id = issue.id
  71:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  72:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside pull_request at [49:98]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:44:11.611189 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111b3d10>]}
2020-05-05 23:44:11.611632 (Thread-2): 16:44:11 | 22 of 28 ERROR creating view model dbt_erik.pull_request_times....... [ERROR in 0.45s]
2020-05-05 23:44:11.611948 (Thread-2): Finished running node model.github.pull_request_times
2020-05-05 23:44:11.881185 (Thread-1): finished collecting timing info
2020-05-05 23:44:11.882216 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdd8d412-3b3c-4d78-a02b-161faf2d41ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110ea890>]}
2020-05-05 23:44:11.882592 (Thread-1): 16:44:11 | 23 of 28 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.72s]
2020-05-05 23:44:11.882797 (Thread-1): Finished running node model.github.issue_open_length
2020-05-05 23:44:11.883324 (Thread-3): Began running node model.github.github_issues
2020-05-05 23:44:11.883555 (Thread-3): 16:44:11 | 26 of 28 SKIP relation dbt_erik.github_issues........................ [SKIP]
2020-05-05 23:44:11.883721 (Thread-3): Finished running node model.github.github_issues
2020-05-05 23:44:11.883880 (Thread-3): Began running node model.github.github_pull_requests
2020-05-05 23:44:11.884073 (Thread-3): 16:44:11 | 27 of 28 SKIP relation dbt_erik.github_pull_requests................. [SKIP]
2020-05-05 23:44:11.884315 (Thread-3): Finished running node model.github.github_pull_requests
2020-05-05 23:44:11.884633 (Thread-2): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:44:11.884805 (Thread-2): 16:44:11 | 28 of 28 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:44:11.884962 (Thread-2): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:44:11.903521 (MainThread): 16:44:11 | 
2020-05-05 23:44:11.903991 (MainThread): 16:44:11 | Finished running 28 view models in 6.02s.
2020-05-05 23:44:11.904274 (MainThread): Connection 'master' was left open.
2020-05-05 23:44:11.904441 (MainThread): Connection 'model.github.issue_open_length' was left open.
2020-05-05 23:44:11.904596 (MainThread): Connection 'model.github.pull_request_times' was left open.
2020-05-05 23:44:11.904742 (MainThread): Connection 'model.github.pull_request_reviewers' was left open.
2020-05-05 23:44:11.904886 (MainThread): Connection 'model.github.issue_blocked_time' was left open.
2020-05-05 23:44:11.972915 (MainThread): 
2020-05-05 23:44:11.973073 (MainThread): Completed with 2 errors and 0 warnings:
2020-05-05 23:44:11.973174 (MainThread): 
2020-05-05 23:44:11.973268 (MainThread): Database Error in model issue_status_windows (models/transform/intermediate/issue_status_windows.sql)
2020-05-05 23:44:11.973353 (MainThread):   Name card_id not found inside issue_project_history at [29:36]
2020-05-05 23:44:11.973431 (MainThread):   compiled SQL at target/run/github/transform/intermediate/issue_status_windows.sql
2020-05-05 23:44:11.973558 (MainThread): 
2020-05-05 23:44:11.973645 (MainThread): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
2020-05-05 23:44:11.973767 (MainThread):   Name id not found inside pull_request at [49:98]
2020-05-05 23:44:11.973870 (MainThread):   compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:44:11.973986 (MainThread): 
Done. PASS=26 WARN=0 ERROR=2 SKIP=0 TOTAL=28
2020-05-05 23:44:11.974139 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110b9890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109d5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f21e90>]}
2020-05-05 23:44:11.974451 (MainThread): Flushing usage events
2020-05-05 23:47:38.873338 (MainThread): Running with dbt=0.16.1
2020-05-05 23:47:39.015033 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:47:39.015879 (MainThread): Tracking: tracking
2020-05-05 23:47:39.022261 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fece50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10452e890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10453c690>]}
2020-05-05 23:47:39.043680 (MainThread): Partial parsing not enabled
2020-05-05 23:47:39.045578 (MainThread): Parsing macros/core.sql
2020-05-05 23:47:39.050051 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:47:39.058904 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:47:39.060863 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:47:39.079879 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:47:39.116172 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:47:39.140218 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:47:39.142271 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:47:39.148982 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:47:39.162231 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:47:39.170807 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:47:39.177656 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:47:39.183094 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:47:39.184130 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:47:39.185271 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:47:39.187028 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:47:39.189143 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:47:39.199884 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:47:39.202534 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:47:39.203675 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:47:39.248644 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:47:39.249894 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:47:39.250857 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:47:39.251989 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:47:39.254390 (MainThread): Parsing macros/etc.sql
2020-05-05 23:47:39.255210 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:47:39.262716 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:47:39.287922 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:47:39.290203 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:47:39.292040 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:47:39.303915 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:47:39.319464 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:47:39.340622 (MainThread): Partial parsing not enabled
2020-05-05 23:47:39.375507 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:47:39.375652 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:47:39.399022 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:47:39.399161 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.406355 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:47:39.406479 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.421273 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:47:39.421420 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.428005 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:47:39.428127 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.435412 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:47:39.435540 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.442359 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:47:39.442483 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.448387 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:47:39.448516 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.455060 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:47:39.455160 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.461043 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:47:39.461158 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.467548 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:47:39.467677 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.474368 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:47:39.474476 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.480052 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:47:39.480163 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.489579 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:47:39.489758 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.495387 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:47:39.495494 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.501941 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:47:39.502067 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.507677 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:47:39.507850 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.514151 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:47:39.514276 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.519805 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:47:39.519906 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.525909 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:47:39.526023 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.531975 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:47:39.532434 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.538227 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:47:39.538329 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.543952 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:47:39.544066 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.549667 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:47:39.549772 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.555486 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:47:39.555648 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.561392 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:47:39.561499 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.567721 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:47:39.567844 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.573411 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:47:39.573510 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:39.702564 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:47:39.945625 (MainThread): Found 28 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 15 sources
2020-05-05 23:47:39.964224 (MainThread): 
2020-05-05 23:47:39.964712 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:47:39.964837 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:47:40.015928 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:47:40.016144 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:47:40.880613 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:47:40.881008 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:47:40.881332 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:47:41.070469 (MainThread): 16:47:41 | Concurrency: 4 threads (target='dev')
2020-05-05 23:47:41.070651 (MainThread): 16:47:41 | 
2020-05-05 23:47:41.072785 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:47:41.072986 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:47:41.073128 (Thread-1): 16:47:41 | 1 of 28 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:47:41.073259 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:47:41.073472 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:47:41.073626 (Thread-2): 16:47:41 | 2 of 28 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:47:41.074072 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:47:41.074363 (Thread-3): 16:47:41 | 3 of 28 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:47:41.074608 (Thread-4): 16:47:41 | 4 of 28 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:47:41.074941 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:47:41.075039 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:47:41.075456 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:47:41.075636 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:47:41.075861 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:47:41.076011 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:47:41.076130 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:47:41.076260 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:47:41.076360 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:47:41.089143 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:47:41.090802 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:47:41.097326 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:47:41.097461 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:47:41.104264 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:47:41.111186 (Thread-2): finished collecting timing info
2020-05-05 23:47:41.111757 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:47:41.111836 (Thread-1): finished collecting timing info
2020-05-05 23:47:41.147292 (Thread-3): finished collecting timing info
2020-05-05 23:47:41.165589 (Thread-4): finished collecting timing info
2020-05-05 23:47:41.539601 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:47:41.548193 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:47:41.573967 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:47:41.574485 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:47:41.581469 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:47:41.583753 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:47:41.585061 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:47:41.586222 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:47:42.247623 (Thread-1): finished collecting timing info
2020-05-05 23:47:42.248481 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047ebd90>]}
2020-05-05 23:47:42.248725 (Thread-1): 16:47:42 | 1 of 28 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.17s]
2020-05-05 23:47:42.248861 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:47:42.248987 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:47:42.249213 (Thread-1): 16:47:42 | 5 of 28 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:47:42.249533 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:47:42.249637 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:47:42.249730 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:47:42.256410 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:47:42.256795 (Thread-1): finished collecting timing info
2020-05-05 23:47:42.261133 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:47:42.261537 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:47:42.436611 (Thread-2): finished collecting timing info
2020-05-05 23:47:42.437672 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c9bd50>]}
2020-05-05 23:47:42.438054 (Thread-2): 16:47:42 | 2 of 28 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.36s]
2020-05-05 23:47:42.438267 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:47:42.438477 (Thread-2): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:47:42.438698 (Thread-2): 16:47:42 | 6 of 28 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:47:42.440350 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:47:42.440613 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:47:42.440767 (Thread-2): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:47:42.448725 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:47:42.449112 (Thread-2): finished collecting timing info
2020-05-05 23:47:42.453648 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:47:42.453987 (Thread-2): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:47:42.568357 (Thread-4): finished collecting timing info
2020-05-05 23:47:42.569579 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dd5390>]}
2020-05-05 23:47:42.571335 (Thread-4): 16:47:42 | 4 of 28 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.49s]
2020-05-05 23:47:42.571659 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:47:42.571861 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-05 23:47:42.572524 (Thread-4): 16:47:42 | 7 of 28 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:47:42.573418 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:47:42.573560 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:47:42.573695 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-05 23:47:42.582239 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:47:42.582632 (Thread-4): finished collecting timing info
2020-05-05 23:47:42.587465 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:47:42.587881 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:47:42.594991 (Thread-3): finished collecting timing info
2020-05-05 23:47:42.595645 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dd5510>]}
2020-05-05 23:47:42.595878 (Thread-3): 16:47:42 | 3 of 28 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.52s]
2020-05-05 23:47:42.596007 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:47:42.596133 (Thread-3): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:47:42.596261 (Thread-3): 16:47:42 | 8 of 28 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:47:42.596685 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:47:42.596801 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:47:42.596887 (Thread-3): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:47:42.603518 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:47:42.603914 (Thread-3): finished collecting timing info
2020-05-05 23:47:42.608571 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:47:42.609289 (Thread-3): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:47:42.859969 (Thread-1): finished collecting timing info
2020-05-05 23:47:42.860938 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047f9ed0>]}
2020-05-05 23:47:42.861274 (Thread-1): 16:47:42 | 5 of 28 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.61s]
2020-05-05 23:47:42.861452 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:47:42.861627 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:47:42.861804 (Thread-1): 16:47:42 | 9 of 28 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:47:42.862136 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:47:42.862262 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:47:42.862386 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:47:42.870446 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:47:42.870859 (Thread-1): finished collecting timing info
2020-05-05 23:47:42.875349 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:47:42.875763 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:47:43.260993 (Thread-3): finished collecting timing info
2020-05-05 23:47:43.262045 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ccd710>]}
2020-05-05 23:47:43.262419 (Thread-3): 16:47:43 | 8 of 28 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.67s]
2020-05-05 23:47:43.262633 (Thread-3): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:47:43.262846 (Thread-3): Began running node model.github.stg_github_issue_merged
2020-05-05 23:47:43.263060 (Thread-3): 16:47:43 | 10 of 28 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:47:43.263430 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:47:43.263554 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:47:43.263900 (Thread-3): Compiling model.github.stg_github_issue_merged
2020-05-05 23:47:43.272720 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:47:43.276228 (Thread-2): finished collecting timing info
2020-05-05 23:47:43.276978 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ccdf90>]}
2020-05-05 23:47:43.277231 (Thread-2): 16:47:43 | 6 of 28 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.84s]
2020-05-05 23:47:43.277432 (Thread-2): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:47:43.277600 (Thread-2): Began running node model.github.stg_github_pull_request
2020-05-05 23:47:43.277748 (Thread-2): 16:47:43 | 11 of 28 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:47:43.277899 (Thread-3): finished collecting timing info
2020-05-05 23:47:43.283695 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:47:43.284140 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:47:43.284248 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:47:43.284342 (Thread-2): Compiling model.github.stg_github_pull_request
2020-05-05 23:47:43.291132 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:47:43.291563 (Thread-3): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:47:43.292511 (Thread-2): finished collecting timing info
2020-05-05 23:47:43.297547 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:47:43.298285 (Thread-2): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:47:43.326649 (Thread-4): finished collecting timing info
2020-05-05 23:47:43.327674 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ccdc90>]}
2020-05-05 23:47:43.328056 (Thread-4): 16:47:43 | 7 of 28 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.75s]
2020-05-05 23:47:43.328273 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-05 23:47:43.329321 (Thread-4): Began running node model.github.stg_github_repository
2020-05-05 23:47:43.329529 (Thread-4): 16:47:43 | 12 of 28 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:47:43.330154 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:47:43.330440 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:47:43.330593 (Thread-4): Compiling model.github.stg_github_repository
2020-05-05 23:47:43.339289 (Thread-4): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:47:43.340157 (Thread-4): finished collecting timing info
2020-05-05 23:47:43.344728 (Thread-4): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:47:43.345589 (Thread-4): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:47:43.488698 (Thread-1): finished collecting timing info
2020-05-05 23:47:43.489731 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ccd650>]}
2020-05-05 23:47:43.490114 (Thread-1): 16:47:43 | 9 of 28 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.63s]
2020-05-05 23:47:43.490334 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:47:43.490543 (Thread-1): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:47:43.490770 (Thread-1): 16:47:43 | 13 of 28 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:47:43.491262 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:47:43.491398 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:47:43.491523 (Thread-1): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:47:43.500333 (Thread-1): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:47:43.500787 (Thread-1): finished collecting timing info
2020-05-05 23:47:43.505467 (Thread-1): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:47:43.505830 (Thread-1): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:47:43.907193 (Thread-4): finished collecting timing info
2020-05-05 23:47:43.908177 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c54110>]}
2020-05-05 23:47:43.908794 (Thread-4): 16:47:43 | 12 of 28 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.58s]
2020-05-05 23:47:43.908983 (Thread-4): Finished running node model.github.stg_github_repository
2020-05-05 23:47:43.909504 (Thread-4): Began running node model.github.stg_github_milestone
2020-05-05 23:47:43.909711 (Thread-4): 16:47:43 | 14 of 28 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:47:43.910057 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:47:43.910178 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:47:43.910299 (Thread-4): Compiling model.github.stg_github_milestone
2020-05-05 23:47:43.918192 (Thread-4): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:47:43.918964 (Thread-4): finished collecting timing info
2020-05-05 23:47:43.923476 (Thread-4): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:47:43.923843 (Thread-4): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:47:43.929971 (Thread-2): finished collecting timing info
2020-05-05 23:47:43.931038 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c92550>]}
2020-05-05 23:47:43.931425 (Thread-2): 16:47:43 | 11 of 28 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.65s]
2020-05-05 23:47:43.931681 (Thread-2): Finished running node model.github.stg_github_pull_request
2020-05-05 23:47:43.931836 (Thread-2): Began running node model.github.stg_github_issue_comment
2020-05-05 23:47:43.931997 (Thread-2): 16:47:43 | 15 of 28 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:47:43.932553 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:47:43.932679 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:47:43.932763 (Thread-2): Compiling model.github.stg_github_issue_comment
2020-05-05 23:47:43.939327 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:47:43.939701 (Thread-2): finished collecting timing info
2020-05-05 23:47:43.944914 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:47:43.945323 (Thread-2): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:47:44.213072 (Thread-1): finished collecting timing info
2020-05-05 23:47:44.214091 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cb73d0>]}
2020-05-05 23:47:44.214465 (Thread-1): 16:47:44 | 13 of 28 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.72s]
2020-05-05 23:47:44.214672 (Thread-1): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:47:44.214878 (Thread-1): Began running node model.github.issue_status_windows
2020-05-05 23:47:44.215383 (Thread-1): 16:47:44 | 16 of 28 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:47:44.215840 (Thread-1): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:47:44.215987 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:47:44.216143 (Thread-1): Compiling model.github.issue_status_windows
2020-05-05 23:47:44.225764 (Thread-1): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:47:44.226686 (Thread-1): finished collecting timing info
2020-05-05 23:47:44.231464 (Thread-1): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:47:44.232753 (Thread-1): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:47:44.357386 (Thread-3): finished collecting timing info
2020-05-05 23:47:44.358410 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d0eb10>]}
2020-05-05 23:47:44.358775 (Thread-3): 16:47:44 | 10 of 28 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 1.09s]
2020-05-05 23:47:44.358987 (Thread-3): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:47:44.359193 (Thread-3): Began running node model.github.issue_close_stack
2020-05-05 23:47:44.359403 (Thread-3): 16:47:44 | 17 of 28 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:47:44.359816 (Thread-3): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:47:44.360077 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:47:44.360380 (Thread-3): Compiling model.github.issue_close_stack
2020-05-05 23:47:44.370431 (Thread-3): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:47:44.370860 (Thread-3): finished collecting timing info
2020-05-05 23:47:44.375520 (Thread-3): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:47:44.375903 (Thread-3): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:47:44.590490 (Thread-2): finished collecting timing info
2020-05-05 23:47:44.591527 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d0e110>]}
2020-05-05 23:47:44.591888 (Thread-2): 16:47:44 | 15 of 28 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.66s]
2020-05-05 23:47:44.592097 (Thread-2): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:47:44.592303 (Thread-2): Began running node model.github.pull_request_reviewers
2020-05-05 23:47:44.592514 (Thread-2): 16:47:44 | 18 of 28 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:47:44.592917 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:47:44.593037 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:47:44.593181 (Thread-2): Compiling model.github.pull_request_reviewers
2020-05-05 23:47:44.603190 (Thread-2): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:47:44.603653 (Thread-2): finished collecting timing info
2020-05-05 23:47:44.608299 (Thread-2): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:47:44.608688 (Thread-2): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:47:44.807717 (Thread-4): finished collecting timing info
2020-05-05 23:47:44.808553 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047eba50>]}
2020-05-05 23:47:44.808857 (Thread-4): 16:47:44 | 14 of 28 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.90s]
2020-05-05 23:47:44.809042 (Thread-4): Finished running node model.github.stg_github_milestone
2020-05-05 23:47:44.809211 (Thread-4): Began running node model.github.issue_assignees
2020-05-05 23:47:44.809383 (Thread-4): 16:47:44 | 19 of 28 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:47:44.809706 (Thread-4): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:47:44.809825 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:47:44.809942 (Thread-4): Compiling model.github.issue_assignees
2020-05-05 23:47:44.818898 (Thread-4): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:47:44.819340 (Thread-4): finished collecting timing info
2020-05-05 23:47:44.823821 (Thread-4): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:47:44.824216 (Thread-4): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:47:44.887080 (Thread-1): finished collecting timing info
2020-05-05 23:47:44.888105 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e1d350>]}
2020-05-05 23:47:44.888472 (Thread-1): 16:47:44 | 16 of 28 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.67s]
2020-05-05 23:47:44.888679 (Thread-1): Finished running node model.github.issue_status_windows
2020-05-05 23:47:44.888885 (Thread-1): Began running node model.github.issue_labels
2020-05-05 23:47:44.889093 (Thread-1): 16:47:44 | 20 of 28 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:47:44.889489 (Thread-1): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:47:44.889632 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:47:44.889789 (Thread-1): Compiling model.github.issue_labels
2020-05-05 23:47:44.898607 (Thread-1): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:47:44.899080 (Thread-1): finished collecting timing info
2020-05-05 23:47:44.904870 (Thread-1): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:47:44.905265 (Thread-1): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:47:45.321190 (Thread-2): finished collecting timing info
2020-05-05 23:47:45.322349 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047eb590>]}
2020-05-05 23:47:45.322672 (Thread-2): 16:47:45 | 18 of 28 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.73s]
2020-05-05 23:47:45.323240 (Thread-2): Finished running node model.github.pull_request_reviewers
2020-05-05 23:47:45.323446 (Thread-2): Began running node model.github.issue_blocked_time
2020-05-05 23:47:45.323630 (Thread-2): 16:47:45 | 21 of 28 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:47:45.323973 (Thread-2): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:47:45.324094 (Thread-2): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-05 23:47:45.324393 (Thread-2): Compiling model.github.issue_blocked_time
2020-05-05 23:47:45.366297 (Thread-2): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:47:45.369802 (Thread-3): finished collecting timing info
2020-05-05 23:47:45.370683 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048ba9d0>]}
2020-05-05 23:47:45.370964 (Thread-3): 16:47:45 | 17 of 28 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 1.01s]
2020-05-05 23:47:45.371248 (Thread-3): Finished running node model.github.issue_close_stack
2020-05-05 23:47:45.371398 (Thread-2): finished collecting timing info
2020-05-05 23:47:45.371702 (Thread-3): Began running node model.github.pull_request_times
2020-05-05 23:47:45.376919 (Thread-2): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:47:45.377260 (Thread-3): 16:47:45 | 22 of 28 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:47:45.377798 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:47:45.377917 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:47:45.378024 (Thread-3): Compiling model.github.pull_request_times
2020-05-05 23:47:45.384193 (Thread-2): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:47:45.391581 (Thread-3): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:47:45.392328 (Thread-3): finished collecting timing info
2020-05-05 23:47:45.396754 (Thread-3): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:47:45.397572 (Thread-3): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:47:45.480897 (Thread-4): finished collecting timing info
2020-05-05 23:47:45.481904 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048bad10>]}
2020-05-05 23:47:45.482265 (Thread-4): 16:47:45 | 19 of 28 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.67s]
2020-05-05 23:47:45.482467 (Thread-4): Finished running node model.github.issue_assignees
2020-05-05 23:47:45.482670 (Thread-4): Began running node model.github.issue_inbox_time
2020-05-05 23:47:45.482877 (Thread-4): 16:47:45 | 23 of 28 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-05 23:47:45.483273 (Thread-4): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:47:45.483389 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:47:45.483506 (Thread-4): Compiling model.github.issue_inbox_time
2020-05-05 23:47:45.491967 (Thread-4): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-05 23:47:45.492412 (Thread-4): finished collecting timing info
2020-05-05 23:47:45.496975 (Thread-4): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-05 23:47:45.497435 (Thread-4): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-05 23:47:45.699182 (Thread-1): finished collecting timing info
2020-05-05 23:47:45.700312 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048ba290>]}
2020-05-05 23:47:45.700719 (Thread-1): 16:47:45 | 20 of 28 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.81s]
2020-05-05 23:47:45.700893 (Thread-1): Finished running node model.github.issue_labels
2020-05-05 23:47:45.701060 (Thread-1): Began running node model.github.issue_projects
2020-05-05 23:47:45.701229 (Thread-1): 16:47:45 | 24 of 28 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-05 23:47:45.701674 (Thread-1): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:47:45.701804 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:47:45.701923 (Thread-1): Compiling model.github.issue_projects
2020-05-05 23:47:45.710824 (Thread-1): Writing injected SQL for node "model.github.issue_projects"
2020-05-05 23:47:45.712689 (Thread-1): finished collecting timing info
2020-05-05 23:47:45.717290 (Thread-1): Writing runtime SQL for node "model.github.issue_projects"
2020-05-05 23:47:45.718432 (Thread-1): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join github.project on project_id = project.id
group by 1
  );

2020-05-05 23:47:45.976004 (Thread-3): finished collecting timing info
2020-05-05 23:47:45.977093 (Thread-3): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside issue at [70:51]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/362f5043-b213-41e8-acba-0031ecc8a842?maxResults=0&location=US: Name id not found inside issue at [70:51]

(job ID: 362f5043-b213-41e8-acba-0031ecc8a842)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
   5:  OPTIONS()
   6:  as (
   7:    with pull_request_review as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  11:  
  12:), pull_request as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  16:
  17:), requested_reviewer_history as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  21:
  22:), issue as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  26:  
  27:), issue_merged as (
  28:
  29:    select
  30:      issue_id,
  31:      min(merged_at) as merged_at
  32:      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  33:    group by 1
  34:
  35:), first_request_time as (
  36:
  37:    select
  38:      pull_request.issue_id,
  39:      pull_request.id,
  40:      min(requested_reviewer_history.created_at) as time_of_first_request,
  41:      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
  42:      -- Finds the first review that is by the requested reviewer and is not a dismissal
  43:      min(if(
  44:            requested_reviewer_history.requested_id = pull_request_review.user_id
  45:            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
  46:            pull_request_review.submitted_at,
  47:            NULL)) as time_of_first_requested_reviewer_review
  48:    from pull_request
  49:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
  50:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
  51:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
  52:    group by 1, 2
  53:
  54:)
  55:
  56:select
  57:  first_request_time.issue_id,
  58:  merged_at,
  59:  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  60:  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  61:  timestamp_diff(
  62:    least(
  63:    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
  64:    coalesce(issue.closed_at, current_timestamp())
  65:  ),
  66:  time_of_first_request,
  67:  second)/3600 as hours_first_action_post_request,
  68:  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
  69:from first_request_time
  70:join issue on first_request_time.issue_id = issue.id
  71:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  72:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside issue at [70:51]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:47:45.982657 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e361d0>]}
2020-05-05 23:47:45.983032 (Thread-3): 16:47:45 | 22 of 28 ERROR creating view model dbt_erik.pull_request_times....... [ERROR in 0.60s]
2020-05-05 23:47:45.983202 (Thread-3): Finished running node model.github.pull_request_times
2020-05-05 23:47:45.983374 (Thread-3): Began running node model.github.issue_open_length
2020-05-05 23:47:45.983550 (Thread-3): 16:47:45 | 25 of 28 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:47:45.984060 (Thread-3): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:47:45.984193 (Thread-3): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-05 23:47:45.984314 (Thread-3): Compiling model.github.issue_open_length
2020-05-05 23:47:45.992679 (Thread-3): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:47:45.993072 (Thread-3): finished collecting timing info
2020-05-05 23:47:45.997573 (Thread-3): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:47:45.998049 (Thread-3): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:47:46.030686 (Thread-2): finished collecting timing info
2020-05-05 23:47:46.031554 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dd5d90>]}
2020-05-05 23:47:46.031855 (Thread-2): 16:47:46 | 21 of 28 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.71s]
2020-05-05 23:47:46.032022 (Thread-2): Finished running node model.github.issue_blocked_time
2020-05-05 23:47:46.211444 (Thread-1): finished collecting timing info
2020-05-05 23:47:46.212400 (Thread-1): Database Error in model issue_projects (models/transform/intermediate/issue_projects.sql)
  Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.project"
  compiled SQL at target/run/github/transform/intermediate/issue_projects.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/0dc14232-cf28-496b-b229-0e27267d6e5a?maxResults=0&location=US: Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.project"

(job ID: 0dc14232-cf28-496b-b229-0e27267d6e5a)

                                                       -----Query Job SQL Follows-----                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
   5:  OPTIONS()
   6:  as (
   7:    with issue_status_windows as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  11:  
  12:), current_status as (
  13:
  14:    select
  15:      issue_id,
  16:      project_id,
  17:      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
  18:    from issue_status_windows
  19:    group by 1, 2
  20:
  21:), current_project_issues_with_ids as (
  22:
  23:    select
  24:      issue_id,
  25:      array_agg(distinct project_id) as projects_array
  26:    from issue_status_windows
  27:    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
  28:      select
  29:        concat(issue_id, '-', project_id) as issue_project
  30:      from current_status
  31:      where most_recent_removed_status = true
  32:    )
  33:    group by 1
  34:
  35:)
  36:select
  37:  issue_id,
  38:  string_agg(project.name, ', ') as projects
  39:from current_project_issues_with_ids, unnest(projects_array) as project_id
  40:join github.project on project_id = project.id
  41:group by 1
  42:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issue_projects (models/transform/intermediate/issue_projects.sql)
  Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.project"
  compiled SQL at target/run/github/transform/intermediate/issue_projects.sql
2020-05-05 23:47:46.213933 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c91250>]}
2020-05-05 23:47:46.214364 (Thread-1): 16:47:46 | 24 of 28 ERROR creating view model dbt_erik.issue_projects........... [ERROR in 0.51s]
2020-05-05 23:47:46.214568 (Thread-1): Finished running node model.github.issue_projects
2020-05-05 23:47:46.372193 (Thread-4): finished collecting timing info
2020-05-05 23:47:46.373234 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2f390>]}
2020-05-05 23:47:46.373607 (Thread-4): 16:47:46 | 23 of 28 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.89s]
2020-05-05 23:47:46.373775 (Thread-4): Finished running node model.github.issue_inbox_time
2020-05-05 23:47:46.943691 (Thread-3): finished collecting timing info
2020-05-05 23:47:46.944715 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fcc55f62-0d97-4e87-9380-0a02d43bcb9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d1a290>]}
2020-05-05 23:47:46.945163 (Thread-3): 16:47:46 | 25 of 28 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.96s]
2020-05-05 23:47:46.945395 (Thread-3): Finished running node model.github.issue_open_length
2020-05-05 23:47:46.946051 (Thread-2): Began running node model.github.github_issues
2020-05-05 23:47:46.946256 (Thread-1): Began running node model.github.github_pull_requests
2020-05-05 23:47:46.946495 (Thread-2): 16:47:46 | 26 of 28 SKIP relation dbt_erik.github_issues........................ [SKIP]
2020-05-05 23:47:46.946668 (Thread-1): 16:47:46 | 27 of 28 SKIP relation dbt_erik.github_pull_requests................. [SKIP]
2020-05-05 23:47:46.946981 (Thread-2): Finished running node model.github.github_issues
2020-05-05 23:47:46.947218 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-05 23:47:46.947666 (Thread-3): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:47:46.947847 (Thread-3): 16:47:46 | 28 of 28 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:47:46.948009 (Thread-3): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:47:47.001309 (MainThread): 16:47:47 | 
2020-05-05 23:47:47.001648 (MainThread): 16:47:47 | Finished running 28 view models in 7.04s.
2020-05-05 23:47:47.001892 (MainThread): Connection 'master' was left open.
2020-05-05 23:47:47.002055 (MainThread): Connection 'model.github.issue_projects' was left open.
2020-05-05 23:47:47.002208 (MainThread): Connection 'model.github.issue_blocked_time' was left open.
2020-05-05 23:47:47.002357 (MainThread): Connection 'model.github.issue_open_length' was left open.
2020-05-05 23:47:47.002501 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-05 23:47:47.069575 (MainThread): 
2020-05-05 23:47:47.069733 (MainThread): Completed with 2 errors and 0 warnings:
2020-05-05 23:47:47.069907 (MainThread): 
2020-05-05 23:47:47.070068 (MainThread): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
2020-05-05 23:47:47.070209 (MainThread):   Name id not found inside issue at [70:51]
2020-05-05 23:47:47.070340 (MainThread):   compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:47:47.070478 (MainThread): 
2020-05-05 23:47:47.070671 (MainThread): Database Error in model issue_projects (models/transform/intermediate/issue_projects.sql)
2020-05-05 23:47:47.070822 (MainThread):   Within a standard SQL view, references to tables/views require explicit project IDs, but these references are not project-qualified: "github.project"
2020-05-05 23:47:47.070952 (MainThread):   compiled SQL at target/run/github/transform/intermediate/issue_projects.sql
2020-05-05 23:47:47.071070 (MainThread): 
Done. PASS=26 WARN=0 ERROR=2 SKIP=0 TOTAL=28
2020-05-05 23:47:47.071333 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047f4f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104633110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2f390>]}
2020-05-05 23:47:47.071536 (MainThread): Flushing usage events
2020-05-05 23:50:09.417050 (MainThread): Running with dbt=0.16.1
2020-05-05 23:50:09.560019 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:50:09.561005 (MainThread): Tracking: tracking
2020-05-05 23:50:09.567855 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bebb0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10becad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b988350>]}
2020-05-05 23:50:09.589609 (MainThread): Partial parsing not enabled
2020-05-05 23:50:09.591524 (MainThread): Parsing macros/core.sql
2020-05-05 23:50:09.596131 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:50:09.605079 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:50:09.607014 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:50:09.626113 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:50:09.664088 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:50:09.688084 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:50:09.690291 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:50:09.697207 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:50:09.711020 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:50:09.719417 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:50:09.726296 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:50:09.731641 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:50:09.732666 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:50:09.733858 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:50:09.735635 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:50:09.738080 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:50:09.748942 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:50:09.751077 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:50:09.752273 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:50:09.797707 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:50:09.799006 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:50:09.800018 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:50:09.801359 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:50:09.803905 (MainThread): Parsing macros/etc.sql
2020-05-05 23:50:09.804671 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:50:09.812528 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:50:09.835948 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:50:09.838161 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:50:09.839759 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:50:09.851495 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:50:09.866090 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:50:09.887902 (MainThread): Partial parsing not enabled
2020-05-05 23:50:09.922823 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:50:09.922966 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:50:09.945450 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:50:09.945582 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:09.953289 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:50:09.953420 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:09.967862 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:50:09.967979 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:09.974808 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:50:09.974932 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:09.983036 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:50:09.983166 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:09.989350 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:50:09.989454 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:09.995326 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:50:09.995436 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.002036 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:50:10.002148 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.007921 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:50:10.008027 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.015586 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:50:10.015706 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.022339 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:50:10.022443 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.028337 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:50:10.028451 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.038116 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:50:10.038232 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.044232 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:50:10.044332 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.050903 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:50:10.051024 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.057002 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:50:10.057127 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.064442 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:50:10.064636 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.070906 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:50:10.071026 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.076546 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:50:10.076644 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.083020 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:50:10.083146 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.088954 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:50:10.089067 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.094818 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:50:10.094963 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.100889 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:50:10.101002 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.106500 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:50:10.106594 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.112511 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:50:10.112814 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.119025 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:50:10.119141 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.124819 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:50:10.124921 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.131064 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:50:10.131319 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.264010 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:50:10.513828 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-05 23:50:10.531558 (MainThread): 
2020-05-05 23:50:10.531891 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:50:10.531983 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:50:10.585739 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:50:10.585886 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:50:11.434910 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:50:11.435344 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:50:11.435674 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:50:11.599093 (MainThread): 16:50:11 | Concurrency: 4 threads (target='dev')
2020-05-05 23:50:11.599260 (MainThread): 16:50:11 | 
2020-05-05 23:50:11.601518 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:50:11.601808 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:50:11.602037 (Thread-1): 16:50:11 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:50:11.602141 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:50:11.602394 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:50:11.602630 (Thread-2): 16:50:11 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:50:11.603084 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:50:11.603318 (Thread-3): 16:50:11 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:50:11.603470 (Thread-4): 16:50:11 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:50:11.603741 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:50:11.603860 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:50:11.604123 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:50:11.604380 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:50:11.604478 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:50:11.604588 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:50:11.604672 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:50:11.604755 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:50:11.604843 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:50:11.617307 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:50:11.619664 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:50:11.619798 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:50:11.631720 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:50:11.632413 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:50:11.639441 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:50:11.640348 (Thread-2): finished collecting timing info
2020-05-05 23:50:11.659121 (Thread-1): finished collecting timing info
2020-05-05 23:50:11.659423 (Thread-3): finished collecting timing info
2020-05-05 23:50:11.688291 (Thread-4): finished collecting timing info
2020-05-05 23:50:12.064434 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:50:12.065033 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:50:12.104153 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:50:12.110542 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:50:12.112769 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:50:12.113167 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:50:12.113314 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:50:12.114025 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:50:12.749335 (Thread-1): finished collecting timing info
2020-05-05 23:50:12.751594 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0b91d0>]}
2020-05-05 23:50:12.751940 (Thread-1): 16:50:12 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.15s]
2020-05-05 23:50:12.752118 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:50:12.752289 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:50:12.752459 (Thread-1): 16:50:12 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:50:12.752912 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:50:12.753046 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:50:12.753170 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:50:12.761276 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:50:12.761680 (Thread-1): finished collecting timing info
2020-05-05 23:50:12.766087 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:50:12.766451 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:50:12.918375 (Thread-2): finished collecting timing info
2020-05-05 23:50:12.919173 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c576d90>]}
2020-05-05 23:50:12.919452 (Thread-2): 16:50:12 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.32s]
2020-05-05 23:50:12.919607 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:50:12.919764 (Thread-2): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:50:12.919914 (Thread-2): 16:50:12 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:50:12.920336 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:50:12.920457 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:50:12.920569 (Thread-2): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:50:12.928987 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:50:12.929453 (Thread-2): finished collecting timing info
2020-05-05 23:50:12.934732 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:50:12.935195 (Thread-2): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:50:12.956614 (Thread-4): finished collecting timing info
2020-05-05 23:50:12.957504 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1009d0>]}
2020-05-05 23:50:12.957803 (Thread-4): 16:50:12 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.35s]
2020-05-05 23:50:12.957954 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:50:12.958105 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-05 23:50:12.958251 (Thread-4): 16:50:12 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:50:12.958548 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:50:12.958653 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:50:12.958757 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-05 23:50:12.966746 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:50:12.967188 (Thread-4): finished collecting timing info
2020-05-05 23:50:12.972611 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:50:12.973097 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:50:13.147033 (Thread-3): finished collecting timing info
2020-05-05 23:50:13.148096 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c100110>]}
2020-05-05 23:50:13.148469 (Thread-3): 16:50:13 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.54s]
2020-05-05 23:50:13.148674 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:50:13.148886 (Thread-3): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:50:13.149056 (Thread-3): 16:50:13 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:50:13.149472 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:50:13.149853 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:50:13.150006 (Thread-3): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:50:13.158332 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:50:13.158723 (Thread-3): finished collecting timing info
2020-05-05 23:50:13.163398 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:50:13.163811 (Thread-3): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:50:13.380274 (Thread-1): finished collecting timing info
2020-05-05 23:50:13.381338 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c07df50>]}
2020-05-05 23:50:13.381712 (Thread-1): 16:50:13 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.63s]
2020-05-05 23:50:13.381915 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:50:13.382085 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:50:13.382407 (Thread-1): 16:50:13 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:50:13.382770 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:50:13.382892 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:50:13.383011 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:50:13.391246 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:50:13.391689 (Thread-1): finished collecting timing info
2020-05-05 23:50:13.397316 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:50:13.397731 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:50:13.450750 (Thread-2): finished collecting timing info
2020-05-05 23:50:13.451816 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c565910>]}
2020-05-05 23:50:13.452183 (Thread-2): 16:50:13 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.53s]
2020-05-05 23:50:13.452406 (Thread-2): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:50:13.452577 (Thread-2): Began running node model.github.stg_github_issue_merged
2020-05-05 23:50:13.453021 (Thread-2): 16:50:13 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:50:13.453376 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:50:13.453497 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:50:13.453615 (Thread-2): Compiling model.github.stg_github_issue_merged
2020-05-05 23:50:13.461986 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:50:13.462388 (Thread-2): finished collecting timing info
2020-05-05 23:50:13.466744 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:50:13.467103 (Thread-2): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:50:13.588593 (Thread-4): finished collecting timing info
2020-05-05 23:50:13.589641 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c577c90>]}
2020-05-05 23:50:13.590014 (Thread-4): 16:50:13 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.63s]
2020-05-05 23:50:13.590221 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-05 23:50:13.590431 (Thread-4): Began running node model.github.stg_github_project
2020-05-05 23:50:13.590655 (Thread-4): 16:50:13 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-05 23:50:13.590977 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:50:13.591096 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:50:13.591216 (Thread-4): Compiling model.github.stg_github_project
2020-05-05 23:50:13.599906 (Thread-4): Writing injected SQL for node "model.github.stg_github_project"
2020-05-05 23:50:13.600403 (Thread-4): finished collecting timing info
2020-05-05 23:50:13.605229 (Thread-4): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-05 23:50:13.605596 (Thread-4): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-05 23:50:13.815736 (Thread-3): finished collecting timing info
2020-05-05 23:50:13.817430 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5d0b50>]}
2020-05-05 23:50:13.817817 (Thread-3): 16:50:13 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.67s]
2020-05-05 23:50:13.818008 (Thread-3): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:50:13.818296 (Thread-3): Began running node model.github.stg_github_pull_request
2020-05-05 23:50:13.819151 (Thread-3): 16:50:13 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:50:13.820307 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:50:13.820445 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:50:13.820574 (Thread-3): Compiling model.github.stg_github_pull_request
2020-05-05 23:50:13.828566 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:50:13.829399 (Thread-3): finished collecting timing info
2020-05-05 23:50:13.833927 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:50:13.834699 (Thread-3): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:50:14.091246 (Thread-1): finished collecting timing info
2020-05-05 23:50:14.092267 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c090c10>]}
2020-05-05 23:50:14.092633 (Thread-1): 16:50:14 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.71s]
2020-05-05 23:50:14.092846 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:50:14.093055 (Thread-1): Began running node model.github.stg_github_repository
2020-05-05 23:50:14.093261 (Thread-1): 16:50:14 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:50:14.093786 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:50:14.093927 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:50:14.094054 (Thread-1): Compiling model.github.stg_github_repository
2020-05-05 23:50:14.102946 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:50:14.103408 (Thread-1): finished collecting timing info
2020-05-05 23:50:14.107904 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:50:14.108252 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:50:14.154044 (Thread-2): finished collecting timing info
2020-05-05 23:50:14.154997 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d62a8d0>]}
2020-05-05 23:50:14.155306 (Thread-2): 16:50:14 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.70s]
2020-05-05 23:50:14.155473 (Thread-2): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:50:14.155645 (Thread-2): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:50:14.155812 (Thread-2): 16:50:14 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:50:14.156260 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:50:14.156393 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:50:14.156515 (Thread-2): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:50:14.164759 (Thread-2): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:50:14.165152 (Thread-2): finished collecting timing info
2020-05-05 23:50:14.170769 (Thread-2): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:50:14.171190 (Thread-2): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:50:14.252612 (Thread-4): finished collecting timing info
2020-05-05 23:50:14.253658 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0f2410>]}
2020-05-05 23:50:14.254056 (Thread-4): 16:50:14 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.66s]
2020-05-05 23:50:14.254227 (Thread-4): Finished running node model.github.stg_github_project
2020-05-05 23:50:14.254398 (Thread-4): Began running node model.github.stg_github_milestone
2020-05-05 23:50:14.254566 (Thread-4): 16:50:14 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:50:14.254887 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:50:14.255005 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-05 23:50:14.255123 (Thread-4): Compiling model.github.stg_github_milestone
2020-05-05 23:50:14.263654 (Thread-4): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:50:14.264048 (Thread-4): finished collecting timing info
2020-05-05 23:50:14.268447 (Thread-4): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:50:14.268826 (Thread-4): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:50:14.646097 (Thread-3): finished collecting timing info
2020-05-05 23:50:14.647171 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0b9110>]}
2020-05-05 23:50:14.647546 (Thread-3): 16:50:14 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.83s]
2020-05-05 23:50:14.647753 (Thread-3): Finished running node model.github.stg_github_pull_request
2020-05-05 23:50:14.647963 (Thread-3): Began running node model.github.stg_github_issue_comment
2020-05-05 23:50:14.648185 (Thread-3): 16:50:14 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:50:14.648626 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:50:14.648760 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:50:14.648882 (Thread-3): Compiling model.github.stg_github_issue_comment
2020-05-05 23:50:14.657517 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:50:14.661113 (Thread-1): finished collecting timing info
2020-05-05 23:50:14.661754 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c19c4d0>]}
2020-05-05 23:50:14.661985 (Thread-1): 16:50:14 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.57s]
2020-05-05 23:50:14.662139 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-05 23:50:14.662267 (Thread-1): Began running node model.github.issue_status_windows
2020-05-05 23:50:14.662393 (Thread-1): 16:50:14 | 17 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:50:14.662645 (Thread-1): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:50:14.662735 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:50:14.662824 (Thread-1): Compiling model.github.issue_status_windows
2020-05-05 23:50:14.670807 (Thread-1): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:50:14.671213 (Thread-3): finished collecting timing info
2020-05-05 23:50:14.676105 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:50:14.676461 (Thread-1): finished collecting timing info
2020-05-05 23:50:14.681119 (Thread-1): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:50:14.681453 (Thread-3): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:50:14.682822 (Thread-1): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:50:14.847063 (Thread-4): finished collecting timing info
2020-05-05 23:50:14.848213 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6ebf10>]}
2020-05-05 23:50:14.848598 (Thread-4): 16:50:14 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.59s]
2020-05-05 23:50:14.848773 (Thread-4): Finished running node model.github.stg_github_milestone
2020-05-05 23:50:14.848944 (Thread-4): Began running node model.github.issue_close_stack
2020-05-05 23:50:14.849112 (Thread-4): 16:50:14 | 18 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:50:14.849565 (Thread-4): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:50:14.849700 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:50:14.849820 (Thread-4): Compiling model.github.issue_close_stack
2020-05-05 23:50:14.859274 (Thread-4): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:50:14.859663 (Thread-4): finished collecting timing info
2020-05-05 23:50:14.864149 (Thread-4): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:50:14.864472 (Thread-4): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:50:14.959676 (Thread-2): finished collecting timing info
2020-05-05 23:50:14.961715 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d62e910>]}
2020-05-05 23:50:14.963422 (Thread-2): 16:50:14 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.81s]
2020-05-05 23:50:14.963748 (Thread-2): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:50:14.963946 (Thread-2): Began running node model.github.issue_assignees
2020-05-05 23:50:14.964429 (Thread-2): 16:50:14 | 19 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:50:14.964816 (Thread-2): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:50:14.964943 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:50:14.965066 (Thread-2): Compiling model.github.issue_assignees
2020-05-05 23:50:14.975017 (Thread-2): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:50:14.977131 (Thread-2): finished collecting timing info
2020-05-05 23:50:14.982860 (Thread-2): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:50:14.984003 (Thread-2): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:50:15.206671 (Thread-3): finished collecting timing info
2020-05-05 23:50:15.208846 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6deb50>]}
2020-05-05 23:50:15.209813 (Thread-3): 16:50:15 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.56s]
2020-05-05 23:50:15.210018 (Thread-3): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:50:15.210986 (Thread-3): Began running node model.github.issue_labels
2020-05-05 23:50:15.211442 (Thread-3): 16:50:15 | 20 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:50:15.211945 (Thread-3): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:50:15.212389 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:50:15.212558 (Thread-3): Compiling model.github.issue_labels
2020-05-05 23:50:15.255284 (Thread-3): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:50:15.258466 (Thread-1): finished collecting timing info
2020-05-05 23:50:15.259713 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d767190>]}
2020-05-05 23:50:15.260126 (Thread-1): 16:50:15 | 17 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.60s]
2020-05-05 23:50:15.260305 (Thread-1): Finished running node model.github.issue_status_windows
2020-05-05 23:50:15.260550 (Thread-1): Began running node model.github.pull_request_reviewers
2020-05-05 23:50:15.260728 (Thread-1): 16:50:15 | 21 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:50:15.261132 (Thread-1): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:50:15.261392 (Thread-3): finished collecting timing info
2020-05-05 23:50:15.261639 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:50:15.266987 (Thread-3): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:50:15.267179 (Thread-1): Compiling model.github.pull_request_reviewers
2020-05-05 23:50:15.276006 (Thread-1): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:50:15.276406 (Thread-1): finished collecting timing info
2020-05-05 23:50:15.281137 (Thread-1): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:50:15.281421 (Thread-3): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:50:15.282591 (Thread-1): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:50:15.569573 (Thread-2): finished collecting timing info
2020-05-05 23:50:15.570720 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6e8c50>]}
2020-05-05 23:50:15.571114 (Thread-2): 16:50:15 | 19 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.61s]
2020-05-05 23:50:15.571326 (Thread-2): Finished running node model.github.issue_assignees
2020-05-05 23:50:15.571535 (Thread-2): Began running node model.github.issue_blocked_time
2020-05-05 23:50:15.571740 (Thread-2): 16:50:15 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:50:15.572237 (Thread-2): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:50:15.572374 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:50:15.572496 (Thread-2): Compiling model.github.issue_blocked_time
2020-05-05 23:50:15.580758 (Thread-2): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:50:15.581275 (Thread-2): finished collecting timing info
2020-05-05 23:50:15.586525 (Thread-2): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:50:15.591353 (Thread-4): finished collecting timing info
2020-05-05 23:50:15.591673 (Thread-2): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:50:15.592385 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5cdd50>]}
2020-05-05 23:50:15.594055 (Thread-4): 16:50:15 | 18 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.74s]
2020-05-05 23:50:15.594434 (Thread-4): Finished running node model.github.issue_close_stack
2020-05-05 23:50:15.594580 (Thread-4): Began running node model.github.pull_request_times
2020-05-05 23:50:15.595005 (Thread-4): 16:50:15 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:50:15.595369 (Thread-4): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:50:15.595570 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:50:15.595764 (Thread-4): Compiling model.github.pull_request_times
2020-05-05 23:50:15.607453 (Thread-4): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:50:15.607839 (Thread-4): finished collecting timing info
2020-05-05 23:50:15.612390 (Thread-4): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:50:15.612790 (Thread-4): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:50:15.843737 (Thread-1): finished collecting timing info
2020-05-05 23:50:15.844791 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c274e90>]}
2020-05-05 23:50:15.845308 (Thread-1): 16:50:15 | 21 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.58s]
2020-05-05 23:50:15.845529 (Thread-1): Finished running node model.github.pull_request_reviewers
2020-05-05 23:50:15.845742 (Thread-1): Began running node model.github.issue_inbox_time
2020-05-05 23:50:15.845969 (Thread-1): 16:50:15 | 24 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-05 23:50:15.846425 (Thread-1): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:50:15.846560 (Thread-1): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-05 23:50:15.846683 (Thread-1): Compiling model.github.issue_inbox_time
2020-05-05 23:50:15.854935 (Thread-1): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-05 23:50:15.855380 (Thread-1): finished collecting timing info
2020-05-05 23:50:15.860002 (Thread-1): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-05 23:50:15.860406 (Thread-1): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-05 23:50:15.941989 (Thread-3): finished collecting timing info
2020-05-05 23:50:15.943790 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6deb50>]}
2020-05-05 23:50:15.945023 (Thread-3): 16:50:15 | 20 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.73s]
2020-05-05 23:50:15.945455 (Thread-3): Finished running node model.github.issue_labels
2020-05-05 23:50:15.945695 (Thread-3): Began running node model.github.issue_projects
2020-05-05 23:50:15.945908 (Thread-3): 16:50:15 | 25 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-05 23:50:15.946704 (Thread-3): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:50:15.946845 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:50:15.946972 (Thread-3): Compiling model.github.issue_projects
2020-05-05 23:50:15.956205 (Thread-3): Writing injected SQL for node "model.github.issue_projects"
2020-05-05 23:50:15.956943 (Thread-3): finished collecting timing info
2020-05-05 23:50:15.961332 (Thread-3): Writing runtime SQL for node "model.github.issue_projects"
2020-05-05 23:50:15.961674 (Thread-3): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-05 23:50:16.077523 (Thread-4): finished collecting timing info
2020-05-05 23:50:16.079078 (Thread-4): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside issue at [70:51]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/864bc596-f3bb-499e-959b-a6100df8dc6c?maxResults=0&location=US: Name id not found inside issue at [70:51]

(job ID: 864bc596-f3bb-499e-959b-a6100df8dc6c)

                                                               -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
   5:  OPTIONS()
   6:  as (
   7:    with pull_request_review as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  11:  
  12:), pull_request as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  16:
  17:), requested_reviewer_history as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  21:
  22:), issue as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  26:  
  27:), issue_merged as (
  28:
  29:    select
  30:      issue_id,
  31:      min(merged_at) as merged_at
  32:      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  33:    group by 1
  34:
  35:), first_request_time as (
  36:
  37:    select
  38:      pull_request.issue_id,
  39:      pull_request.id,
  40:      min(requested_reviewer_history.created_at) as time_of_first_request,
  41:      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
  42:      -- Finds the first review that is by the requested reviewer and is not a dismissal
  43:      min(if(
  44:            requested_reviewer_history.requested_id = pull_request_review.user_id
  45:            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
  46:            pull_request_review.submitted_at,
  47:            NULL)) as time_of_first_requested_reviewer_review
  48:    from pull_request
  49:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
  50:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
  51:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
  52:    group by 1, 2
  53:
  54:)
  55:
  56:select
  57:  first_request_time.issue_id,
  58:  merged_at,
  59:  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  60:  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  61:  timestamp_diff(
  62:    least(
  63:    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
  64:    coalesce(issue.closed_at, current_timestamp())
  65:  ),
  66:  time_of_first_request,
  67:  second)/3600 as hours_first_action_post_request,
  68:  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
  69:from first_request_time
  70:join issue on first_request_time.issue_id = issue.id
  71:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  72:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
  Name id not found inside issue at [70:51]
  compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:50:16.084440 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bed01d0>]}
2020-05-05 23:50:16.084752 (Thread-4): 16:50:16 | 23 of 29 ERROR creating view model dbt_erik.pull_request_times....... [ERROR in 0.49s]
2020-05-05 23:50:16.084927 (Thread-4): Finished running node model.github.pull_request_times
2020-05-05 23:50:16.085103 (Thread-4): Began running node model.github.issue_open_length
2020-05-05 23:50:16.085469 (Thread-4): 16:50:16 | 26 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:50:16.085842 (Thread-4): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:50:16.085961 (Thread-4): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-05 23:50:16.086077 (Thread-4): Compiling model.github.issue_open_length
2020-05-05 23:50:16.094163 (Thread-4): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:50:16.094569 (Thread-4): finished collecting timing info
2020-05-05 23:50:16.099138 (Thread-4): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:50:16.099486 (Thread-4): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:50:16.142085 (Thread-2): finished collecting timing info
2020-05-05 23:50:16.143096 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d65a290>]}
2020-05-05 23:50:16.143528 (Thread-2): 16:50:16 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.57s]
2020-05-05 23:50:16.144773 (Thread-2): Finished running node model.github.issue_blocked_time
2020-05-05 23:50:16.410964 (Thread-1): finished collecting timing info
2020-05-05 23:50:16.412216 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5cc850>]}
2020-05-05 23:50:16.412614 (Thread-1): 16:50:16 | 24 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.57s]
2020-05-05 23:50:16.412891 (Thread-1): Finished running node model.github.issue_inbox_time
2020-05-05 23:50:16.730125 (Thread-4): finished collecting timing info
2020-05-05 23:50:16.731158 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5bc3d0>]}
2020-05-05 23:50:16.731520 (Thread-4): 16:50:16 | 26 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.65s]
2020-05-05 23:50:16.731726 (Thread-4): Finished running node model.github.issue_open_length
2020-05-05 23:50:16.732220 (Thread-2): Began running node model.github.github_pull_requests
2020-05-05 23:50:16.732418 (Thread-2): 16:50:16 | 27 of 29 SKIP relation dbt_erik.github_pull_requests................. [SKIP]
2020-05-05 23:50:16.732586 (Thread-2): Finished running node model.github.github_pull_requests
2020-05-05 23:50:16.859974 (Thread-3): finished collecting timing info
2020-05-05 23:50:16.861043 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0de6d0>]}
2020-05-05 23:50:16.861416 (Thread-3): 16:50:16 | 25 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.91s]
2020-05-05 23:50:16.861622 (Thread-3): Finished running node model.github.issue_projects
2020-05-05 23:50:16.862072 (Thread-4): Began running node model.github.github_issues
2020-05-05 23:50:16.862322 (Thread-4): 16:50:16 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-05 23:50:16.862689 (Thread-4): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:50:16.862807 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-05 23:50:16.862923 (Thread-4): Compiling model.github.github_issues
2020-05-05 23:50:16.882331 (Thread-4): Writing injected SQL for node "model.github.github_issues"
2020-05-05 23:50:16.882725 (Thread-4): finished collecting timing info
2020-05-05 23:50:16.886941 (Thread-4): Writing runtime SQL for node "model.github.github_issues"
2020-05-05 23:50:16.887280 (Thread-4): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.id = labels.issue_id
left join issue_projects
  on issue.id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.id = issue_assignees.issue_id
left join issue_open_length
  on issue.id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-05 23:50:17.914199 (Thread-4): finished collecting timing info
2020-05-05 23:50:17.915147 (Thread-4): Database Error in model github_issues (models/github_issues.sql)
  Name id not found inside issue at [85:12]
  compiled SQL at target/run/github/github_issues.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/f860c005-3c9f-463b-91e1-087f9f00989a?maxResults=0&location=US: Name id not found inside issue at [85:12]

(job ID: f860c005-3c9f-463b-91e1-087f9f00989a)

                                                       -----Query Job SQL Follows-----                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_labels as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`issue_labels`
  16:
  17:), issue_projects as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`issue_projects`
  21:
  22:), repository as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  26:
  27:), milestone as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  31:
  32:), issue_assignees as (
  33:
  34:    select *
  35:    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  36:
  37:), issue_open_length as (
  38:
  39:    select *
  40:    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  41:
  42:), issue_blocked_time as (
  43:
  44:    select *
  45:    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  46:
  47:), issue_inbox_time as (
  48:
  49:    select *
  50:    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  51:
  52:), creator as (
  53:
  54:    select *
  55:    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  56:
  57:)
  58:
  59:select
  60:  issue.id,
  61:  issue.body,
  62:  issue.closed_at,
  63:  issue.created_at,
  64:  issue.locked,
  65:  issue.milestone_id,
  66:  issue.number,
  67:  issue.repository_id,
  68:  issue.state,
  69:  issue.title,
  70:  issue.updated_at,
  71:  issue.user_id,
  72:  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  73:  issue_open_length.days_issue_opened,
  74:  labels.labels,
  75:  issue_projects.projects,
  76:  repository.full_name as repository,
  77:  milestone.title as milestone,
  78:  milestone.due_on as milestone_due_on,
  79:  issue_assignees.assignees,
  80:  issue_blocked_time.days_blocked,
  81:  issue_inbox_time.inbox_days,
  82:  creator.login as created_by
  83:from issue
  84:left join issue_labels as labels
  85:  on issue.id = labels.issue_id
  86:left join issue_projects
  87:  on issue.id = issue_projects.issue_id
  88:left join repository
  89:  on issue.repository_id = repository.id
  90:left join milestone
  91:  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
  92:left join issue_assignees
  93:  on issue.id = issue_assignees.issue_id
  94:left join issue_open_length
  95:  on issue.id = issue_open_length.issue_id
  96:left join issue_blocked_time
  97:  on issue.id = issue_blocked_time.issue_id
  98:left join issue_inbox_time
  99:  on issue.id = issue_inbox_time.issue_id
 100:left join creator on issue.user_id = creator.id
 101:where not issue.pull_request
 102:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model github_issues (models/github_issues.sql)
  Name id not found inside issue at [85:12]
  compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:50:17.916730 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d931ad1-935d-4f8d-8375-60b98dae21f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d64d350>]}
2020-05-05 23:50:17.917131 (Thread-4): 16:50:17 | 28 of 29 ERROR creating view model dbt_erik.github_issues............ [ERROR in 1.05s]
2020-05-05 23:50:17.917347 (Thread-4): Finished running node model.github.github_issues
2020-05-05 23:50:17.917835 (Thread-2): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:50:17.918055 (Thread-2): 16:50:17 | 29 of 29 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:50:17.918250 (Thread-2): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:50:17.950967 (MainThread): 16:50:17 | 
2020-05-05 23:50:17.951460 (MainThread): 16:50:17 | Finished running 29 view models in 7.42s.
2020-05-05 23:50:17.951947 (MainThread): Connection 'master' was left open.
2020-05-05 23:50:17.952153 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-05 23:50:17.952316 (MainThread): Connection 'model.github.issue_blocked_time' was left open.
2020-05-05 23:50:17.952493 (MainThread): Connection 'model.github.issue_projects' was left open.
2020-05-05 23:50:17.952647 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-05 23:50:18.024718 (MainThread): 
2020-05-05 23:50:18.024887 (MainThread): Completed with 2 errors and 0 warnings:
2020-05-05 23:50:18.025033 (MainThread): 
2020-05-05 23:50:18.025130 (MainThread): Database Error in model pull_request_times (models/transform/intermediate/pull_request_times.sql)
2020-05-05 23:50:18.025219 (MainThread):   Name id not found inside issue at [70:51]
2020-05-05 23:50:18.025326 (MainThread):   compiled SQL at target/run/github/transform/intermediate/pull_request_times.sql
2020-05-05 23:50:18.025465 (MainThread): 
2020-05-05 23:50:18.025592 (MainThread): Database Error in model github_issues (models/github_issues.sql)
2020-05-05 23:50:18.025676 (MainThread):   Name id not found inside issue at [85:12]
2020-05-05 23:50:18.025779 (MainThread):   compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:50:18.025916 (MainThread): 
Done. PASS=27 WARN=0 ERROR=2 SKIP=0 TOTAL=29
2020-05-05 23:50:18.026086 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c097490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c090310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6954d0>]}
2020-05-05 23:50:18.026254 (MainThread): Flushing usage events
2020-05-05 23:51:19.980874 (MainThread): Running with dbt=0.16.1
2020-05-05 23:51:20.124029 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:51:20.125008 (MainThread): Tracking: tracking
2020-05-05 23:51:20.131706 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046f8a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c2b410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046ebd10>]}
2020-05-05 23:51:20.153662 (MainThread): Partial parsing not enabled
2020-05-05 23:51:20.155621 (MainThread): Parsing macros/core.sql
2020-05-05 23:51:20.160202 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:51:20.168877 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:51:20.171221 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:51:20.189698 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:51:20.225688 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:51:20.249544 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:51:20.251822 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:51:20.258354 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:51:20.273773 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:51:20.281015 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:51:20.287839 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:51:20.293395 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:51:20.294437 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:51:20.295571 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:51:20.297313 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:51:20.300437 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:51:20.311119 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:51:20.313463 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:51:20.314650 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:51:20.360181 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:51:20.361486 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:51:20.362454 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:51:20.363582 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:51:20.365987 (MainThread): Parsing macros/etc.sql
2020-05-05 23:51:20.366758 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:51:20.375250 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:51:20.397944 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:51:20.400194 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:51:20.401928 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:51:20.413913 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:51:20.427607 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:51:20.448069 (MainThread): Partial parsing not enabled
2020-05-05 23:51:20.483171 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:51:20.483311 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:51:20.506675 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:51:20.506808 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.513437 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:51:20.513539 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.528770 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:51:20.528900 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.535432 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:51:20.535535 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.543242 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:51:20.543366 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.549476 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:51:20.549593 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.555317 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:51:20.555421 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.562270 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:51:20.562390 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.567732 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:51:20.567825 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.575164 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:51:20.575289 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.582054 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:51:20.582171 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.587806 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:51:20.587910 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.598870 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:51:20.599006 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.605927 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:51:20.606055 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.611638 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:51:20.611736 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.617433 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:51:20.617545 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.624204 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:51:20.624404 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.630037 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:51:20.630146 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.636058 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:51:20.636371 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.642170 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:51:20.642274 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.648271 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:51:20.648388 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.654022 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:51:20.654183 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.659789 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:51:20.659898 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.665498 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:51:20.665725 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.672362 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:51:20.672490 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.678541 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:51:20.678657 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.684174 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:51:20.684269 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.690041 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:51:20.690153 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:20.824662 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:51:21.071648 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-05 23:51:21.089218 (MainThread): 
2020-05-05 23:51:21.089561 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:51:21.089659 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:51:21.142429 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:51:21.142571 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:51:21.940412 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:51:21.940811 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:51:21.941136 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:51:22.111971 (MainThread): 16:51:22 | Concurrency: 4 threads (target='dev')
2020-05-05 23:51:22.112228 (MainThread): 16:51:22 | 
2020-05-05 23:51:22.113983 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:51:22.114147 (Thread-1): 16:51:22 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:51:22.114335 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:51:22.114658 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:51:22.114751 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:51:22.114857 (Thread-2): 16:51:22 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:51:22.114932 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:51:22.115037 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:51:22.115181 (Thread-3): 16:51:22 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:51:22.115640 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:51:22.115747 (Thread-4): 16:51:22 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:51:22.115865 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:51:22.116369 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:51:22.116485 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:51:22.123157 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:51:22.130775 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:51:22.130909 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:51:22.131067 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:51:22.131152 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:51:22.131422 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:51:22.138756 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:51:22.138986 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:51:22.144999 (Thread-1): finished collecting timing info
2020-05-05 23:51:22.146232 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:51:22.159764 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:51:22.197371 (Thread-2): finished collecting timing info
2020-05-05 23:51:22.197709 (Thread-3): finished collecting timing info
2020-05-05 23:51:22.251569 (Thread-4): finished collecting timing info
2020-05-05 23:51:22.529105 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:51:22.559450 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:51:22.575072 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:51:22.583739 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:51:22.584264 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:51:22.586795 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:51:22.587700 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:51:22.588423 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:51:23.121003 (Thread-1): finished collecting timing info
2020-05-05 23:51:23.122075 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f0d250>]}
2020-05-05 23:51:23.122456 (Thread-1): 16:51:23 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.01s]
2020-05-05 23:51:23.122670 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:51:23.122882 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:51:23.123059 (Thread-1): 16:51:23 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:51:23.123390 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:51:23.123515 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:51:23.123637 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:51:23.132081 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:51:23.132514 (Thread-1): finished collecting timing info
2020-05-05 23:51:23.137480 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:51:23.137889 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:51:23.287851 (Thread-3): finished collecting timing info
2020-05-05 23:51:23.288876 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea3d90>]}
2020-05-05 23:51:23.289243 (Thread-3): 16:51:23 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.17s]
2020-05-05 23:51:23.289512 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:51:23.289812 (Thread-3): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:51:23.290208 (Thread-3): 16:51:23 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:51:23.290832 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:51:23.290998 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:51:23.291152 (Thread-3): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:51:23.301258 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:51:23.301718 (Thread-3): finished collecting timing info
2020-05-05 23:51:23.306772 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:51:23.307189 (Thread-3): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:51:23.532216 (Thread-4): finished collecting timing info
2020-05-05 23:51:23.533226 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea3e10>]}
2020-05-05 23:51:23.533590 (Thread-4): 16:51:23 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.41s]
2020-05-05 23:51:23.533798 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:51:23.534008 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-05 23:51:23.534221 (Thread-4): 16:51:23 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:51:23.534727 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:51:23.534983 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:51:23.535138 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-05 23:51:23.543600 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:51:23.544023 (Thread-4): finished collecting timing info
2020-05-05 23:51:23.548847 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:51:23.549263 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:51:23.586619 (Thread-2): finished collecting timing info
2020-05-05 23:51:23.588621 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f0df10>]}
2020-05-05 23:51:23.588906 (Thread-2): 16:51:23 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.47s]
2020-05-05 23:51:23.589064 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:51:23.589213 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:51:23.590068 (Thread-2): 16:51:23 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:51:23.591081 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:51:23.591254 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:51:23.591365 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:51:23.598926 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:51:23.599971 (Thread-2): finished collecting timing info
2020-05-05 23:51:23.604631 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:51:23.605060 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:51:23.871896 (Thread-3): finished collecting timing info
2020-05-05 23:51:23.872953 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eb3590>]}
2020-05-05 23:51:23.873326 (Thread-3): 16:51:23 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.58s]
2020-05-05 23:51:23.873537 (Thread-3): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:51:23.873769 (Thread-3): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:51:23.873984 (Thread-3): 16:51:23 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:51:23.874358 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:51:23.874480 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:51:23.874601 (Thread-3): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:51:23.883225 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:51:23.883662 (Thread-3): finished collecting timing info
2020-05-05 23:51:23.888587 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:51:23.891708 (Thread-1): finished collecting timing info
2020-05-05 23:51:23.892315 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052fe690>]}
2020-05-05 23:51:23.892528 (Thread-1): 16:51:23 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.77s]
2020-05-05 23:51:23.892717 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:51:23.892872 (Thread-1): Began running node model.github.stg_github_issue_merged
2020-05-05 23:51:23.893006 (Thread-1): 16:51:23 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:51:23.893166 (Thread-3): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:51:23.894771 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:51:23.895157 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:51:23.895550 (Thread-1): Compiling model.github.stg_github_issue_merged
2020-05-05 23:51:23.903260 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:51:23.904124 (Thread-1): finished collecting timing info
2020-05-05 23:51:23.908720 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:51:23.909214 (Thread-1): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:51:24.235437 (Thread-2): finished collecting timing info
2020-05-05 23:51:24.236650 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053190d0>]}
2020-05-05 23:51:24.237035 (Thread-2): 16:51:24 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.65s]
2020-05-05 23:51:24.237248 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:51:24.237466 (Thread-2): Began running node model.github.stg_github_project
2020-05-05 23:51:24.237664 (Thread-2): 16:51:24 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-05 23:51:24.238000 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:51:24.238123 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:51:24.238246 (Thread-2): Compiling model.github.stg_github_project
2020-05-05 23:51:24.247821 (Thread-2): Writing injected SQL for node "model.github.stg_github_project"
2020-05-05 23:51:24.248426 (Thread-2): finished collecting timing info
2020-05-05 23:51:24.253538 (Thread-2): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-05 23:51:24.253959 (Thread-2): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-05 23:51:24.275417 (Thread-4): finished collecting timing info
2020-05-05 23:51:24.277568 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea3f90>]}
2020-05-05 23:51:24.279161 (Thread-4): 16:51:24 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.74s]
2020-05-05 23:51:24.279492 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-05 23:51:24.279691 (Thread-4): Began running node model.github.stg_github_pull_request
2020-05-05 23:51:24.280129 (Thread-4): 16:51:24 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:51:24.280848 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:51:24.281343 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:51:24.281564 (Thread-4): Compiling model.github.stg_github_pull_request
2020-05-05 23:51:24.289565 (Thread-4): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:51:24.290106 (Thread-4): finished collecting timing info
2020-05-05 23:51:24.294613 (Thread-4): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:51:24.295004 (Thread-4): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:51:24.540342 (Thread-3): finished collecting timing info
2020-05-05 23:51:24.541406 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104febbd0>]}
2020-05-05 23:51:24.541777 (Thread-3): 16:51:24 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.67s]
2020-05-05 23:51:24.541987 (Thread-3): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:51:24.542158 (Thread-3): Began running node model.github.stg_github_repository
2020-05-05 23:51:24.542331 (Thread-3): 16:51:24 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:51:24.542684 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:51:24.542813 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:51:24.542935 (Thread-3): Compiling model.github.stg_github_repository
2020-05-05 23:51:24.551118 (Thread-3): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:51:24.553135 (Thread-3): finished collecting timing info
2020-05-05 23:51:24.558233 (Thread-3): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:51:24.560089 (Thread-3): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:51:24.797002 (Thread-4): finished collecting timing info
2020-05-05 23:51:24.798097 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105320710>]}
2020-05-05 23:51:24.798478 (Thread-4): 16:51:24 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.52s]
2020-05-05 23:51:24.798687 (Thread-4): Finished running node model.github.stg_github_pull_request
2020-05-05 23:51:24.798896 (Thread-4): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:51:24.799109 (Thread-4): 16:51:24 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:51:24.799487 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:51:24.799608 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:51:24.799731 (Thread-4): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:51:24.808708 (Thread-4): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:51:24.811977 (Thread-2): finished collecting timing info
2020-05-05 23:51:24.812587 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10538fd90>]}
2020-05-05 23:51:24.812818 (Thread-2): 16:51:24 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.57s]
2020-05-05 23:51:24.812944 (Thread-2): Finished running node model.github.stg_github_project
2020-05-05 23:51:24.813117 (Thread-2): Began running node model.github.stg_github_milestone
2020-05-05 23:51:24.813287 (Thread-2): 16:51:24 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:51:24.813569 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:51:24.813674 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-05 23:51:24.813770 (Thread-2): Compiling model.github.stg_github_milestone
2020-05-05 23:51:24.820301 (Thread-4): finished collecting timing info
2020-05-05 23:51:24.820870 (Thread-2): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:51:24.825619 (Thread-4): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:51:24.826162 (Thread-4): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:51:24.827049 (Thread-2): finished collecting timing info
2020-05-05 23:51:24.831505 (Thread-2): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:51:24.831869 (Thread-2): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:51:24.967477 (Thread-1): finished collecting timing info
2020-05-05 23:51:24.968500 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105334590>]}
2020-05-05 23:51:24.968872 (Thread-1): 16:51:24 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 1.07s]
2020-05-05 23:51:24.969078 (Thread-1): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:51:24.969286 (Thread-1): Began running node model.github.stg_github_issue_comment
2020-05-05 23:51:24.969528 (Thread-1): 16:51:24 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:51:24.970057 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:51:24.970202 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:51:24.970431 (Thread-1): Compiling model.github.stg_github_issue_comment
2020-05-05 23:51:24.980263 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:51:24.980693 (Thread-1): finished collecting timing info
2020-05-05 23:51:24.985233 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:51:24.985608 (Thread-1): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:51:25.108714 (Thread-3): finished collecting timing info
2020-05-05 23:51:25.109534 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104def7d0>]}
2020-05-05 23:51:25.109788 (Thread-3): 16:51:25 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.57s]
2020-05-05 23:51:25.109933 (Thread-3): Finished running node model.github.stg_github_repository
2020-05-05 23:51:25.110075 (Thread-3): Began running node model.github.issue_close_stack
2020-05-05 23:51:25.110218 (Thread-3): 16:51:25 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:51:25.110604 (Thread-3): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:51:25.110724 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:51:25.110827 (Thread-3): Compiling model.github.issue_close_stack
2020-05-05 23:51:25.119145 (Thread-3): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:51:25.119534 (Thread-3): finished collecting timing info
2020-05-05 23:51:25.123686 (Thread-3): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:51:25.124003 (Thread-3): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:51:25.329521 (Thread-2): finished collecting timing info
2020-05-05 23:51:25.330559 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dcd890>]}
2020-05-05 23:51:25.330931 (Thread-2): 16:51:25 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.52s]
2020-05-05 23:51:25.331135 (Thread-2): Finished running node model.github.stg_github_milestone
2020-05-05 23:51:25.331342 (Thread-2): Began running node model.github.issue_status_windows
2020-05-05 23:51:25.331544 (Thread-2): 16:51:25 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:51:25.332007 (Thread-2): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:51:25.332141 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:51:25.332263 (Thread-2): Compiling model.github.issue_status_windows
2020-05-05 23:51:25.341908 (Thread-2): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:51:25.342329 (Thread-2): finished collecting timing info
2020-05-05 23:51:25.346823 (Thread-2): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:51:25.347184 (Thread-2): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:51:25.500699 (Thread-1): finished collecting timing info
2020-05-05 23:51:25.503334 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f08fd0>]}
2020-05-05 23:51:25.503792 (Thread-1): 16:51:25 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.53s]
2020-05-05 23:51:25.503985 (Thread-1): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:51:25.504163 (Thread-1): Began running node model.github.issue_assignees
2020-05-05 23:51:25.504338 (Thread-1): 16:51:25 | 19 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:51:25.504986 (Thread-1): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:51:25.505123 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:51:25.505250 (Thread-1): Compiling model.github.issue_assignees
2020-05-05 23:51:25.515348 (Thread-1): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:51:25.516133 (Thread-1): finished collecting timing info
2020-05-05 23:51:25.520758 (Thread-1): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:51:25.521195 (Thread-1): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:51:25.638442 (Thread-4): finished collecting timing info
2020-05-05 23:51:25.639483 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea30d0>]}
2020-05-05 23:51:25.639849 (Thread-4): 16:51:25 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.84s]
2020-05-05 23:51:25.640096 (Thread-4): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:51:25.640349 (Thread-4): Began running node model.github.pull_request_reviewers
2020-05-05 23:51:25.640533 (Thread-4): 16:51:25 | 20 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:51:25.641013 (Thread-4): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:51:25.641154 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:51:25.641283 (Thread-4): Compiling model.github.pull_request_reviewers
2020-05-05 23:51:25.650642 (Thread-4): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:51:25.651067 (Thread-4): finished collecting timing info
2020-05-05 23:51:25.655526 (Thread-4): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:51:25.655901 (Thread-4): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:51:25.708098 (Thread-3): finished collecting timing info
2020-05-05 23:51:25.708701 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10539d8d0>]}
2020-05-05 23:51:25.708922 (Thread-3): 16:51:25 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.60s]
2020-05-05 23:51:25.709037 (Thread-3): Finished running node model.github.issue_close_stack
2020-05-05 23:51:25.709198 (Thread-3): Began running node model.github.issue_labels
2020-05-05 23:51:25.709314 (Thread-3): 16:51:25 | 21 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:51:25.709528 (Thread-3): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:51:25.709607 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:51:25.709687 (Thread-3): Compiling model.github.issue_labels
2020-05-05 23:51:25.717408 (Thread-3): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:51:25.718753 (Thread-3): finished collecting timing info
2020-05-05 23:51:25.755879 (Thread-3): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:51:25.756414 (Thread-3): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:51:26.007756 (Thread-2): finished collecting timing info
2020-05-05 23:51:26.008470 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f77a10>]}
2020-05-05 23:51:26.008696 (Thread-2): 16:51:26 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.68s]
2020-05-05 23:51:26.008825 (Thread-2): Finished running node model.github.issue_status_windows
2020-05-05 23:51:26.008950 (Thread-2): Began running node model.github.issue_blocked_time
2020-05-05 23:51:26.009282 (Thread-2): 16:51:26 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:51:26.009564 (Thread-2): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:51:26.009654 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:51:26.009744 (Thread-2): Compiling model.github.issue_blocked_time
2020-05-05 23:51:26.016221 (Thread-2): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:51:26.016567 (Thread-2): finished collecting timing info
2020-05-05 23:51:26.021087 (Thread-2): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:51:26.021482 (Thread-2): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:51:26.029827 (Thread-1): finished collecting timing info
2020-05-05 23:51:26.030465 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064fdbd0>]}
2020-05-05 23:51:26.030725 (Thread-1): 16:51:26 | 19 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.53s]
2020-05-05 23:51:26.030869 (Thread-1): Finished running node model.github.issue_assignees
2020-05-05 23:51:26.030999 (Thread-1): Began running node model.github.pull_request_times
2020-05-05 23:51:26.031211 (Thread-1): 16:51:26 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:51:26.031477 (Thread-1): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:51:26.031566 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:51:26.031651 (Thread-1): Compiling model.github.pull_request_times
2020-05-05 23:51:26.042538 (Thread-1): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:51:26.042921 (Thread-1): finished collecting timing info
2020-05-05 23:51:26.047653 (Thread-1): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:51:26.048196 (Thread-1): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:51:26.251540 (Thread-4): finished collecting timing info
2020-05-05 23:51:26.252542 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f93150>]}
2020-05-05 23:51:26.252899 (Thread-4): 16:51:26 | 20 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.61s]
2020-05-05 23:51:26.253101 (Thread-4): Finished running node model.github.pull_request_reviewers
2020-05-05 23:51:26.253306 (Thread-4): Began running node model.github.issue_open_length
2020-05-05 23:51:26.253513 (Thread-4): 16:51:26 | 24 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:51:26.253903 (Thread-4): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:51:26.254053 (Thread-4): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-05 23:51:26.254168 (Thread-4): Compiling model.github.issue_open_length
2020-05-05 23:51:26.262545 (Thread-4): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:51:26.262967 (Thread-4): finished collecting timing info
2020-05-05 23:51:26.268817 (Thread-4): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:51:26.269358 (Thread-4): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:51:26.528530 (Thread-3): finished collecting timing info
2020-05-05 23:51:26.529546 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c09d0>]}
2020-05-05 23:51:26.529907 (Thread-3): 16:51:26 | 21 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.82s]
2020-05-05 23:51:26.530109 (Thread-3): Finished running node model.github.issue_labels
2020-05-05 23:51:26.530314 (Thread-3): Began running node model.github.issue_inbox_time
2020-05-05 23:51:26.530523 (Thread-3): 16:51:26 | 25 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-05 23:51:26.530996 (Thread-3): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:51:26.531130 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:51:26.531251 (Thread-3): Compiling model.github.issue_inbox_time
2020-05-05 23:51:26.539872 (Thread-3): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-05 23:51:26.540339 (Thread-3): finished collecting timing info
2020-05-05 23:51:26.545286 (Thread-3): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-05 23:51:26.545683 (Thread-3): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-05 23:51:26.822058 (Thread-2): finished collecting timing info
2020-05-05 23:51:26.823475 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10535e150>]}
2020-05-05 23:51:26.823793 (Thread-2): 16:51:26 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.81s]
2020-05-05 23:51:26.823970 (Thread-2): Finished running node model.github.issue_blocked_time
2020-05-05 23:51:26.824142 (Thread-2): Began running node model.github.issue_projects
2020-05-05 23:51:26.824318 (Thread-2): 16:51:26 | 26 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-05 23:51:26.824641 (Thread-2): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:51:26.824762 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-05 23:51:26.824881 (Thread-2): Compiling model.github.issue_projects
2020-05-05 23:51:26.834244 (Thread-2): Writing injected SQL for node "model.github.issue_projects"
2020-05-05 23:51:26.835283 (Thread-2): finished collecting timing info
2020-05-05 23:51:26.839989 (Thread-2): Writing runtime SQL for node "model.github.issue_projects"
2020-05-05 23:51:26.840371 (Thread-2): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-05 23:51:26.984627 (Thread-1): finished collecting timing info
2020-05-05 23:51:26.985699 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f03590>]}
2020-05-05 23:51:26.986069 (Thread-1): 16:51:26 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.95s]
2020-05-05 23:51:26.986275 (Thread-1): Finished running node model.github.pull_request_times
2020-05-05 23:51:27.090758 (Thread-3): finished collecting timing info
2020-05-05 23:51:27.091605 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106478490>]}
2020-05-05 23:51:27.091937 (Thread-3): 16:51:27 | 25 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.56s]
2020-05-05 23:51:27.092165 (Thread-3): Finished running node model.github.issue_inbox_time
2020-05-05 23:51:27.648572 (Thread-4): finished collecting timing info
2020-05-05 23:51:27.649572 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106520550>]}
2020-05-05 23:51:27.649926 (Thread-4): 16:51:27 | 24 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 1.40s]
2020-05-05 23:51:27.650130 (Thread-4): Finished running node model.github.issue_open_length
2020-05-05 23:51:27.650613 (Thread-1): Began running node model.github.github_pull_requests
2020-05-05 23:51:27.650887 (Thread-1): 16:51:27 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-05 23:51:27.651256 (Thread-1): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:51:27.651373 (Thread-1): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-05 23:51:27.651487 (Thread-1): Compiling model.github.github_pull_requests
2020-05-05 23:51:27.666507 (Thread-1): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-05 23:51:27.666904 (Thread-1): finished collecting timing info
2020-05-05 23:51:27.671875 (Thread-1): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-05 23:51:27.672275 (Thread-1): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

)

select
  issue.id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.id = issue_assignees.issue_id
left join issue_open_length
  on issue.id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.id = pull_request.issue_id
left join pull_request_times
  on issue.id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-05 23:51:27.677096 (Thread-2): finished collecting timing info
2020-05-05 23:51:27.677886 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105364390>]}
2020-05-05 23:51:27.678427 (Thread-2): 16:51:27 | 26 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.85s]
2020-05-05 23:51:27.678867 (Thread-2): Finished running node model.github.issue_projects
2020-05-05 23:51:27.679421 (Thread-4): Began running node model.github.github_issues
2020-05-05 23:51:27.679641 (Thread-4): 16:51:27 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-05 23:51:27.680019 (Thread-4): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:51:27.680215 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-05 23:51:27.680346 (Thread-4): Compiling model.github.github_issues
2020-05-05 23:51:27.698200 (Thread-4): Writing injected SQL for node "model.github.github_issues"
2020-05-05 23:51:27.698590 (Thread-4): finished collecting timing info
2020-05-05 23:51:27.703095 (Thread-4): Writing runtime SQL for node "model.github.github_issues"
2020-05-05 23:51:27.703450 (Thread-4): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.id = labels.issue_id
left join issue_projects
  on issue.id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.id = issue_assignees.issue_id
left join issue_open_length
  on issue.id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-05 23:51:27.971307 (Thread-1): finished collecting timing info
2020-05-05 23:51:27.972646 (Thread-1): Database Error in model github_pull_requests (models/github_pull_requests.sql)
  Table name "pull_request" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/github/github_pull_requests.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Table name "pull_request" missing dataset while no default dataset is set in the request.

(job ID: 96e82d1d-a948-4c41-82a8-e8ce63aaf600)

                                                          -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_labels as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`issue_labels`
  16:
  17:), repository as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  21:
  22:), issue_assignees as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  26:
  27:), issue_open_length as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  31:
  32:), creator as (
  33:
  34:    select *
  35:    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  36:
  37:), pull_request_times as (
  38:
  39:    select *
  40:    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  41:
  42:)
  43:
  44:select
  45:  issue.id,
  46:  issue.body,
  47:  issue.closed_at,
  48:  issue.created_at,
  49:  issue.locked,
  50:  issue.number,
  51:  issue.repository_id,
  52:  issue.state,
  53:  issue.title,
  54:  issue.updated_at,
  55:  issue.user_id,
  56:  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  57:  issue_open_length.days_issue_opened,
  58:  labels.labels,
  59:  repository.full_name as repository,
  60:  issue_assignees.assignees,
  61:  creator.login as created_by,
  62:  hours_first_review_post_request,
  63:  hours_first_action_post_request,
  64:  hours_request_review_to_merge,
  65:  merged_at
  66:from issue
  67:left join issue_labels as labels
  68:  on issue.id = labels.issue_id
  69:left join repository
  70:  on issue.repository_id = repository.id
  71:left join issue_assignees
  72:  on issue.id = issue_assignees.issue_id
  73:left join issue_open_length
  74:  on issue.id = issue_open_length.issue_id
  75:left join creator 
  76:  on issue.user_id = creator.id
  77:left join pull_request
  78:  on issue.id = pull_request.issue_id
  79:left join pull_request_times
  80:  on issue.id = pull_request_times.issue_id
  81:where issue.pull_request
  82:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model github_pull_requests (models/github_pull_requests.sql)
  Table name "pull_request" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/github/github_pull_requests.sql
2020-05-05 23:51:27.977321 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eff110>]}
2020-05-05 23:51:27.977670 (Thread-1): 16:51:27 | 27 of 29 ERROR creating view model dbt_erik.github_pull_requests..... [ERROR in 0.33s]
2020-05-05 23:51:27.977873 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-05 23:51:28.328861 (Thread-4): finished collecting timing info
2020-05-05 23:51:28.329800 (Thread-4): Database Error in model github_issues (models/github_issues.sql)
  Name id not found inside issue at [85:12]
  compiled SQL at target/run/github/github_issues.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/e267c6b0-1769-4b53-8dc7-e0ae684773f4?maxResults=0&location=US: Name id not found inside issue at [85:12]

(job ID: e267c6b0-1769-4b53-8dc7-e0ae684773f4)

                                                       -----Query Job SQL Follows-----                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_labels as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`issue_labels`
  16:
  17:), issue_projects as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`issue_projects`
  21:
  22:), repository as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  26:
  27:), milestone as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  31:
  32:), issue_assignees as (
  33:
  34:    select *
  35:    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  36:
  37:), issue_open_length as (
  38:
  39:    select *
  40:    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  41:
  42:), issue_blocked_time as (
  43:
  44:    select *
  45:    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  46:
  47:), issue_inbox_time as (
  48:
  49:    select *
  50:    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  51:
  52:), creator as (
  53:
  54:    select *
  55:    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  56:
  57:)
  58:
  59:select
  60:  issue.issue_id,
  61:  issue.body,
  62:  issue.closed_at,
  63:  issue.created_at,
  64:  issue.locked,
  65:  issue.milestone_id,
  66:  issue.number,
  67:  issue.repository_id,
  68:  issue.state,
  69:  issue.title,
  70:  issue.updated_at,
  71:  issue.user_id,
  72:  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  73:  issue_open_length.days_issue_opened,
  74:  labels.labels,
  75:  issue_projects.projects,
  76:  repository.full_name as repository,
  77:  milestone.title as milestone,
  78:  milestone.due_on as milestone_due_on,
  79:  issue_assignees.assignees,
  80:  issue_blocked_time.days_blocked,
  81:  issue_inbox_time.inbox_days,
  82:  creator.login as created_by
  83:from issue
  84:left join issue_labels as labels
  85:  on issue.id = labels.issue_id
  86:left join issue_projects
  87:  on issue.id = issue_projects.issue_id
  88:left join repository
  89:  on issue.repository_id = repository.id
  90:left join milestone
  91:  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
  92:left join issue_assignees
  93:  on issue.id = issue_assignees.issue_id
  94:left join issue_open_length
  95:  on issue.id = issue_open_length.issue_id
  96:left join issue_blocked_time
  97:  on issue.id = issue_blocked_time.issue_id
  98:left join issue_inbox_time
  99:  on issue.id = issue_inbox_time.issue_id
 100:left join creator on issue.user_id = creator.id
 101:where not issue.pull_request
 102:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model github_issues (models/github_issues.sql)
  Name id not found inside issue at [85:12]
  compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:51:28.332384 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b351ef38-b5a8-4e7f-80af-99a074dd6c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106459ad0>]}
2020-05-05 23:51:28.332729 (Thread-4): 16:51:28 | 28 of 29 ERROR creating view model dbt_erik.github_issues............ [ERROR in 0.65s]
2020-05-05 23:51:28.332928 (Thread-4): Finished running node model.github.github_issues
2020-05-05 23:51:28.333410 (Thread-2): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:51:28.333627 (Thread-2): 16:51:28 | 29 of 29 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:51:28.333818 (Thread-2): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:51:28.346114 (MainThread): 16:51:28 | 
2020-05-05 23:51:28.346582 (MainThread): 16:51:28 | Finished running 29 view models in 7.26s.
2020-05-05 23:51:28.346865 (MainThread): Connection 'master' was left open.
2020-05-05 23:51:28.347029 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-05 23:51:28.347180 (MainThread): Connection 'model.github.issue_projects' was left open.
2020-05-05 23:51:28.347326 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-05 23:51:28.347469 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-05 23:51:28.416764 (MainThread): 
2020-05-05 23:51:28.416929 (MainThread): Completed with 2 errors and 0 warnings:
2020-05-05 23:51:28.417069 (MainThread): 
2020-05-05 23:51:28.417167 (MainThread): Database Error in model github_pull_requests (models/github_pull_requests.sql)
2020-05-05 23:51:28.417255 (MainThread):   Table name "pull_request" missing dataset while no default dataset is set in the request.
2020-05-05 23:51:28.417363 (MainThread):   compiled SQL at target/run/github/github_pull_requests.sql
2020-05-05 23:51:28.417500 (MainThread): 
2020-05-05 23:51:28.417652 (MainThread): Database Error in model github_issues (models/github_issues.sql)
2020-05-05 23:51:28.417790 (MainThread):   Name id not found inside issue at [85:12]
2020-05-05 23:51:28.417869 (MainThread):   compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:51:28.418010 (MainThread): 
Done. PASS=27 WARN=0 ERROR=2 SKIP=0 TOTAL=29
2020-05-05 23:51:28.418166 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c62fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10644a610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c53790>]}
2020-05-05 23:51:29.033909 (MainThread): Flushing usage events
2020-05-05 23:53:22.782601 (MainThread): Running with dbt=0.16.1
2020-05-05 23:53:22.932355 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:53:22.933310 (MainThread): Tracking: tracking
2020-05-05 23:53:22.941096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8ff950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f90fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f90fdd0>]}
2020-05-05 23:53:22.962979 (MainThread): Partial parsing not enabled
2020-05-05 23:53:22.965040 (MainThread): Parsing macros/core.sql
2020-05-05 23:53:22.969729 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:53:22.978265 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:53:22.980603 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:53:23.000357 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:53:23.038143 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:53:23.061972 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:53:23.064209 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:53:23.071869 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:53:23.085677 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:53:23.094444 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:53:23.101774 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:53:23.107771 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:53:23.108916 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:53:23.110230 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:53:23.112014 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:53:23.114303 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:53:23.124675 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:53:23.126886 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:53:23.128030 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:53:23.173636 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:53:23.174907 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:53:23.175861 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:53:23.176984 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:53:23.179611 (MainThread): Parsing macros/etc.sql
2020-05-05 23:53:23.180300 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:53:23.188186 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:53:23.212171 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:53:23.214550 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:53:23.216098 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:53:23.227772 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:53:23.241737 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:53:23.264318 (MainThread): Partial parsing not enabled
2020-05-05 23:53:23.300150 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:53:23.300295 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:53:23.325762 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:53:23.325897 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.333320 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:53:23.333444 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.348335 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:53:23.348463 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.355539 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:53:23.355722 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.362911 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:53:23.363042 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.369274 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:53:23.369385 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.374978 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:53:23.375085 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.381845 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:53:23.381950 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.388402 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:53:23.388545 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.396653 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:53:23.396785 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.403606 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:53:23.403710 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.409408 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:53:23.409523 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.419144 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:53:23.419255 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.426536 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:53:23.426661 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.432511 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:53:23.432619 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.438421 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:53:23.438531 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.444768 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:53:23.444872 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.450615 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:53:23.450722 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.456778 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:53:23.456946 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.464282 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:53:23.464410 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.470201 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:53:23.470316 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.476122 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:53:23.476235 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.482246 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:53:23.482360 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.487982 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:53:23.488077 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.494383 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:53:23.494509 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.500704 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:53:23.500827 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.507112 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:53:23.507226 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.513698 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:53:23.513831 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.651972 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:53:23.908774 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-05 23:53:23.934544 (MainThread): 
2020-05-05 23:53:23.934907 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:53:23.935007 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:53:23.988822 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:53:23.989146 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:53:24.871692 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:53:24.872099 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:53:24.872434 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:53:25.070712 (MainThread): 16:53:25 | Concurrency: 4 threads (target='dev')
2020-05-05 23:53:25.070894 (MainThread): 16:53:25 | 
2020-05-05 23:53:25.072735 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:53:25.072905 (Thread-1): 16:53:25 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:53:25.073096 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:53:25.073357 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:53:25.073448 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:53:25.073625 (Thread-2): 16:53:25 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:53:25.073705 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:53:25.073806 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:53:25.073938 (Thread-3): 16:53:25 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:53:25.074393 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:53:25.074537 (Thread-4): 16:53:25 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:53:25.074664 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:53:25.074923 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:53:25.075031 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:53:25.075341 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:53:25.080731 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:53:25.089868 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:53:25.090018 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:53:25.090117 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:53:25.090282 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:53:25.097329 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:53:25.097472 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:53:25.104145 (Thread-1): finished collecting timing info
2020-05-05 23:53:25.104355 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:53:25.112572 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:53:25.137638 (Thread-2): finished collecting timing info
2020-05-05 23:53:25.151808 (Thread-3): finished collecting timing info
2020-05-05 23:53:25.233862 (Thread-4): finished collecting timing info
2020-05-05 23:53:25.520730 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:53:25.527646 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:53:25.537344 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:53:25.560582 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:53:25.561307 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:53:25.562234 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:53:25.562477 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:53:25.562685 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:53:26.381969 (Thread-4): finished collecting timing info
2020-05-05 23:53:26.383870 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe9c50>]}
2020-05-05 23:53:26.387072 (Thread-2): finished collecting timing info
2020-05-05 23:53:26.387522 (Thread-4): 16:53:26 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.31s]
2020-05-05 23:53:26.388270 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fae4590>]}
2020-05-05 23:53:26.388477 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:53:26.388825 (Thread-2): 16:53:26 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.31s]
2020-05-05 23:53:26.388997 (Thread-4): Began running node model.github.stg_github_user
2020-05-05 23:53:26.389365 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:53:26.389585 (Thread-4): 16:53:26 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:53:26.389793 (Thread-2): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:53:26.390385 (Thread-2): 16:53:26 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:53:26.390758 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:53:26.390885 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:53:26.391003 (Thread-4): Compiling model.github.stg_github_user
2020-05-05 23:53:26.399222 (Thread-4): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:53:26.399574 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:53:26.399820 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:53:26.399950 (Thread-2): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:53:26.408755 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:53:26.409177 (Thread-4): finished collecting timing info
2020-05-05 23:53:26.414419 (Thread-4): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:53:26.414617 (Thread-2): finished collecting timing info
2020-05-05 23:53:26.420507 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:53:26.421578 (Thread-4): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:53:26.427164 (Thread-3): finished collecting timing info
2020-05-05 23:53:26.428064 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb43bd0>]}
2020-05-05 23:53:26.428602 (Thread-3): 16:53:26 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.35s]
2020-05-05 23:53:26.428811 (Thread-2): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:53:26.429589 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:53:26.429761 (Thread-3): Began running node model.github.stg_github_issue_label
2020-05-05 23:53:26.430495 (Thread-3): 16:53:26 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:53:26.431269 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:53:26.431817 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:53:26.432307 (Thread-3): Compiling model.github.stg_github_issue_label
2020-05-05 23:53:26.439926 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:53:26.440699 (Thread-3): finished collecting timing info
2020-05-05 23:53:26.445567 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:53:26.446112 (Thread-3): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:53:26.653931 (Thread-1): finished collecting timing info
2020-05-05 23:53:26.654976 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffca690>]}
2020-05-05 23:53:26.655410 (Thread-1): 16:53:26 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.58s]
2020-05-05 23:53:26.655644 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:53:26.655883 (Thread-1): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:53:26.656336 (Thread-1): 16:53:26 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:53:26.656798 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:53:26.657008 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:53:26.657152 (Thread-1): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:53:26.665805 (Thread-1): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:53:26.666188 (Thread-1): finished collecting timing info
2020-05-05 23:53:26.670691 (Thread-1): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:53:26.671078 (Thread-1): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:53:27.026618 (Thread-3): finished collecting timing info
2020-05-05 23:53:27.027695 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111036310>]}
2020-05-05 23:53:27.028079 (Thread-3): 16:53:27 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.60s]
2020-05-05 23:53:27.028297 (Thread-3): Finished running node model.github.stg_github_issue_label
2020-05-05 23:53:27.028540 (Thread-3): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:53:27.028723 (Thread-3): 16:53:27 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:53:27.029066 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:53:27.029191 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:53:27.029316 (Thread-3): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:53:27.038769 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:53:27.041747 (Thread-3): finished collecting timing info
2020-05-05 23:53:27.046488 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:53:27.046955 (Thread-3): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:53:27.083120 (Thread-2): finished collecting timing info
2020-05-05 23:53:27.084148 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe9c50>]}
2020-05-05 23:53:27.084527 (Thread-2): 16:53:27 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.68s]
2020-05-05 23:53:27.084701 (Thread-2): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:53:27.084874 (Thread-2): Began running node model.github.stg_github_issue_merged
2020-05-05 23:53:27.085162 (Thread-2): 16:53:27 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:53:27.085525 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:53:27.085654 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:53:27.085779 (Thread-2): Compiling model.github.stg_github_issue_merged
2020-05-05 23:53:27.094501 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:53:27.094967 (Thread-2): finished collecting timing info
2020-05-05 23:53:27.100495 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:53:27.100886 (Thread-2): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:53:27.301052 (Thread-4): finished collecting timing info
2020-05-05 23:53:27.302166 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9a8190>]}
2020-05-05 23:53:27.302552 (Thread-4): 16:53:27 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.91s]
2020-05-05 23:53:27.302767 (Thread-4): Finished running node model.github.stg_github_user
2020-05-05 23:53:27.302982 (Thread-4): Began running node model.github.stg_github_project
2020-05-05 23:53:27.303195 (Thread-4): 16:53:27 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-05 23:53:27.303544 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:53:27.303668 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:53:27.303793 (Thread-4): Compiling model.github.stg_github_project
2020-05-05 23:53:27.313268 (Thread-4): Writing injected SQL for node "model.github.stg_github_project"
2020-05-05 23:53:27.316208 (Thread-1): finished collecting timing info
2020-05-05 23:53:27.316862 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111111190>]}
2020-05-05 23:53:27.317104 (Thread-1): 16:53:27 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.66s]
2020-05-05 23:53:27.317315 (Thread-1): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:53:27.317552 (Thread-1): Began running node model.github.stg_github_pull_request
2020-05-05 23:53:27.317711 (Thread-1): 16:53:27 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:53:27.318028 (Thread-4): finished collecting timing info
2020-05-05 23:53:27.322921 (Thread-4): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-05 23:53:27.323234 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:53:27.323463 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:53:27.323572 (Thread-1): Compiling model.github.stg_github_pull_request
2020-05-05 23:53:27.330056 (Thread-1): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:53:27.330432 (Thread-4): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-05 23:53:27.331331 (Thread-1): finished collecting timing info
2020-05-05 23:53:27.335674 (Thread-1): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:53:27.336092 (Thread-1): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:53:27.644453 (Thread-2): finished collecting timing info
2020-05-05 23:53:27.645495 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111063050>]}
2020-05-05 23:53:27.645864 (Thread-2): 16:53:27 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.56s]
2020-05-05 23:53:27.646078 (Thread-2): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:53:27.646292 (Thread-2): Began running node model.github.stg_github_repository
2020-05-05 23:53:27.646506 (Thread-2): 16:53:27 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:53:27.646905 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:53:27.647028 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:53:27.647151 (Thread-2): Compiling model.github.stg_github_repository
2020-05-05 23:53:27.655725 (Thread-2): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:53:27.656153 (Thread-2): finished collecting timing info
2020-05-05 23:53:27.660909 (Thread-2): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:53:27.661321 (Thread-2): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:53:27.719606 (Thread-3): finished collecting timing info
2020-05-05 23:53:27.720653 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb39e10>]}
2020-05-05 23:53:27.721029 (Thread-3): 16:53:27 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.69s]
2020-05-05 23:53:27.721243 (Thread-3): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:53:27.721459 (Thread-3): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:53:27.722012 (Thread-3): 16:53:27 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:53:27.722431 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:53:27.722603 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:53:27.722802 (Thread-3): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:53:27.731660 (Thread-3): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:53:27.732076 (Thread-3): finished collecting timing info
2020-05-05 23:53:27.736486 (Thread-3): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:53:27.736878 (Thread-3): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:53:27.877038 (Thread-4): finished collecting timing info
2020-05-05 23:53:27.878110 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9a8190>]}
2020-05-05 23:53:27.879447 (Thread-4): 16:53:27 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.57s]
2020-05-05 23:53:27.882854 (Thread-1): finished collecting timing info
2020-05-05 23:53:27.883260 (Thread-4): Finished running node model.github.stg_github_project
2020-05-05 23:53:27.883859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f965790>]}
2020-05-05 23:53:27.884036 (Thread-4): Began running node model.github.stg_github_milestone
2020-05-05 23:53:27.884409 (Thread-1): 16:53:27 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.56s]
2020-05-05 23:53:27.884569 (Thread-4): 16:53:27 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:53:27.884718 (Thread-1): Finished running node model.github.stg_github_pull_request
2020-05-05 23:53:27.885017 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:53:27.885167 (Thread-1): Began running node model.github.stg_github_issue_comment
2020-05-05 23:53:27.885293 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-05 23:53:27.885480 (Thread-1): 16:53:27 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:53:27.885599 (Thread-4): Compiling model.github.stg_github_milestone
2020-05-05 23:53:27.885977 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:53:27.894981 (Thread-4): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:53:27.895091 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:53:27.895311 (Thread-1): Compiling model.github.stg_github_issue_comment
2020-05-05 23:53:27.901844 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:53:27.902174 (Thread-1): finished collecting timing info
2020-05-05 23:53:27.906660 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:53:27.906785 (Thread-4): finished collecting timing info
2020-05-05 23:53:27.911640 (Thread-4): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:53:27.912050 (Thread-1): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:53:27.912379 (Thread-4): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:53:28.239951 (Thread-2): finished collecting timing info
2020-05-05 23:53:28.240993 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fac7410>]}
2020-05-05 23:53:28.241304 (Thread-2): 16:53:28 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.59s]
2020-05-05 23:53:28.241479 (Thread-2): Finished running node model.github.stg_github_repository
2020-05-05 23:53:28.241653 (Thread-2): Began running node model.github.issue_status_windows
2020-05-05 23:53:28.241824 (Thread-2): 16:53:28 | 17 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:53:28.242158 (Thread-2): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:53:28.242281 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:53:28.242570 (Thread-2): Compiling model.github.issue_status_windows
2020-05-05 23:53:28.251706 (Thread-2): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:53:28.252104 (Thread-2): finished collecting timing info
2020-05-05 23:53:28.256976 (Thread-2): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:53:28.257441 (Thread-2): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:53:28.331083 (Thread-3): finished collecting timing info
2020-05-05 23:53:28.332129 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc48910>]}
2020-05-05 23:53:28.332465 (Thread-3): 16:53:28 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.61s]
2020-05-05 23:53:28.332641 (Thread-3): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:53:28.332816 (Thread-3): Began running node model.github.issue_close_stack
2020-05-05 23:53:28.332990 (Thread-3): 16:53:28 | 18 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:53:28.333315 (Thread-3): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:53:28.333439 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:53:28.333568 (Thread-3): Compiling model.github.issue_close_stack
2020-05-05 23:53:28.343290 (Thread-3): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:53:28.343730 (Thread-3): finished collecting timing info
2020-05-05 23:53:28.348576 (Thread-3): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:53:28.348999 (Thread-3): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:53:28.485628 (Thread-4): finished collecting timing info
2020-05-05 23:53:28.486687 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11116e7d0>]}
2020-05-05 23:53:28.487060 (Thread-4): 16:53:28 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.60s]
2020-05-05 23:53:28.487273 (Thread-4): Finished running node model.github.stg_github_milestone
2020-05-05 23:53:28.487488 (Thread-4): Began running node model.github.issue_labels
2020-05-05 23:53:28.487824 (Thread-4): 16:53:28 | 19 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:53:28.488184 (Thread-4): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:53:28.488321 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:53:28.488515 (Thread-4): Compiling model.github.issue_labels
2020-05-05 23:53:28.496846 (Thread-4): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:53:28.497327 (Thread-4): finished collecting timing info
2020-05-05 23:53:28.502322 (Thread-4): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:53:28.502733 (Thread-4): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:53:28.555950 (Thread-1): finished collecting timing info
2020-05-05 23:53:28.556851 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110fb0d0>]}
2020-05-05 23:53:28.557150 (Thread-1): 16:53:28 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.67s]
2020-05-05 23:53:28.557306 (Thread-1): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:53:28.557459 (Thread-1): Began running node model.github.issue_assignees
2020-05-05 23:53:28.557608 (Thread-1): 16:53:28 | 20 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:53:28.558087 (Thread-1): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:53:28.558212 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:53:28.558323 (Thread-1): Compiling model.github.issue_assignees
2020-05-05 23:53:28.567503 (Thread-1): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:53:28.567917 (Thread-1): finished collecting timing info
2020-05-05 23:53:28.603189 (Thread-1): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:53:28.603722 (Thread-1): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:53:28.954072 (Thread-2): finished collecting timing info
2020-05-05 23:53:28.956097 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fab7190>]}
2020-05-05 23:53:28.959857 (Thread-3): finished collecting timing info
2020-05-05 23:53:28.960394 (Thread-2): 16:53:28 | 17 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.71s]
2020-05-05 23:53:28.961025 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111287e10>]}
2020-05-05 23:53:28.961235 (Thread-2): Finished running node model.github.issue_status_windows
2020-05-05 23:53:28.961536 (Thread-3): 16:53:28 | 18 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.63s]
2020-05-05 23:53:28.961691 (Thread-2): Began running node model.github.pull_request_reviewers
2020-05-05 23:53:28.961851 (Thread-3): Finished running node model.github.issue_close_stack
2020-05-05 23:53:28.962216 (Thread-2): 16:53:28 | 21 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:53:28.962388 (Thread-3): Began running node model.github.issue_blocked_time
2020-05-05 23:53:28.962706 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:53:28.962854 (Thread-3): 16:53:28 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:53:28.963113 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:53:28.963821 (Thread-3): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:53:28.963944 (Thread-2): Compiling model.github.pull_request_reviewers
2020-05-05 23:53:28.964073 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:53:28.969416 (Thread-3): Compiling model.github.issue_blocked_time
2020-05-05 23:53:28.975738 (Thread-3): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:53:28.978464 (Thread-2): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:53:28.978912 (Thread-2): finished collecting timing info
2020-05-05 23:53:28.983066 (Thread-2): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:53:28.983329 (Thread-3): finished collecting timing info
2020-05-05 23:53:28.987974 (Thread-3): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:53:28.988275 (Thread-2): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:53:28.989746 (Thread-3): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:53:29.004414 (Thread-4): finished collecting timing info
2020-05-05 23:53:29.005044 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110d6d50>]}
2020-05-05 23:53:29.005266 (Thread-4): 16:53:29 | 19 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.52s]
2020-05-05 23:53:29.005467 (Thread-4): Finished running node model.github.issue_labels
2020-05-05 23:53:29.005619 (Thread-4): Began running node model.github.pull_request_times
2020-05-05 23:53:29.005754 (Thread-4): 16:53:29 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:53:29.006500 (Thread-4): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:53:29.006656 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:53:29.006880 (Thread-4): Compiling model.github.pull_request_times
2020-05-05 23:53:29.018162 (Thread-4): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:53:29.018543 (Thread-4): finished collecting timing info
2020-05-05 23:53:29.023906 (Thread-4): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:53:29.024299 (Thread-4): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:53:29.367028 (Thread-1): finished collecting timing info
2020-05-05 23:53:29.367886 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11103cfd0>]}
2020-05-05 23:53:29.368197 (Thread-1): 16:53:29 | 20 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.81s]
2020-05-05 23:53:29.368371 (Thread-1): Finished running node model.github.issue_assignees
2020-05-05 23:53:29.368616 (Thread-1): Began running node model.github.issue_inbox_time
2020-05-05 23:53:29.368824 (Thread-1): 16:53:29 | 24 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-05 23:53:29.369168 (Thread-1): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:53:29.369293 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:53:29.369418 (Thread-1): Compiling model.github.issue_inbox_time
2020-05-05 23:53:29.376880 (Thread-1): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-05 23:53:29.377278 (Thread-1): finished collecting timing info
2020-05-05 23:53:29.381932 (Thread-1): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-05 23:53:29.382326 (Thread-1): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-05 23:53:29.574146 (Thread-2): finished collecting timing info
2020-05-05 23:53:29.575024 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbb5cd0>]}
2020-05-05 23:53:29.575308 (Thread-2): 16:53:29 | 21 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.61s]
2020-05-05 23:53:29.575522 (Thread-2): Finished running node model.github.pull_request_reviewers
2020-05-05 23:53:29.575699 (Thread-2): Began running node model.github.issue_projects
2020-05-05 23:53:29.575942 (Thread-2): 16:53:29 | 25 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-05 23:53:29.576304 (Thread-2): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:53:29.576411 (Thread-2): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-05 23:53:29.576515 (Thread-2): Compiling model.github.issue_projects
2020-05-05 23:53:29.586325 (Thread-2): Writing injected SQL for node "model.github.issue_projects"
2020-05-05 23:53:29.588824 (Thread-3): finished collecting timing info
2020-05-05 23:53:29.589518 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111114310>]}
2020-05-05 23:53:29.589747 (Thread-3): 16:53:29 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.63s]
2020-05-05 23:53:29.589962 (Thread-3): Finished running node model.github.issue_blocked_time
2020-05-05 23:53:29.590238 (Thread-3): Began running node model.github.issue_open_length
2020-05-05 23:53:29.590381 (Thread-3): 16:53:29 | 26 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:53:29.590642 (Thread-3): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:53:29.590753 (Thread-2): finished collecting timing info
2020-05-05 23:53:29.590953 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-05 23:53:29.595519 (Thread-2): Writing runtime SQL for node "model.github.issue_projects"
2020-05-05 23:53:29.595685 (Thread-3): Compiling model.github.issue_open_length
2020-05-05 23:53:29.602280 (Thread-3): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:53:29.602633 (Thread-2): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-05 23:53:29.603546 (Thread-3): finished collecting timing info
2020-05-05 23:53:29.607958 (Thread-3): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:53:29.608439 (Thread-3): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:53:29.872224 (Thread-4): finished collecting timing info
2020-05-05 23:53:29.873933 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11128ef90>]}
2020-05-05 23:53:29.874346 (Thread-4): 16:53:29 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.87s]
2020-05-05 23:53:29.874539 (Thread-4): Finished running node model.github.pull_request_times
2020-05-05 23:53:29.978744 (Thread-1): finished collecting timing info
2020-05-05 23:53:29.979814 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11117c7d0>]}
2020-05-05 23:53:29.980265 (Thread-1): 16:53:29 | 24 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.61s]
2020-05-05 23:53:29.980499 (Thread-1): Finished running node model.github.issue_inbox_time
2020-05-05 23:53:30.272494 (Thread-2): finished collecting timing info
2020-05-05 23:53:30.273525 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112a8410>]}
2020-05-05 23:53:30.273887 (Thread-2): 16:53:30 | 25 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.70s]
2020-05-05 23:53:30.274090 (Thread-2): Finished running node model.github.issue_projects
2020-05-05 23:53:30.528499 (Thread-3): finished collecting timing info
2020-05-05 23:53:30.529532 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffb3f50>]}
2020-05-05 23:53:30.529893 (Thread-3): 16:53:30 | 26 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.94s]
2020-05-05 23:53:30.530108 (Thread-3): Finished running node model.github.issue_open_length
2020-05-05 23:53:30.530580 (Thread-4): Began running node model.github.github_issues
2020-05-05 23:53:30.530769 (Thread-4): 16:53:30 | 27 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-05 23:53:30.531111 (Thread-4): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:53:30.531356 (Thread-1): Began running node model.github.github_pull_requests
2020-05-05 23:53:30.531496 (Thread-4): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-05 23:53:30.531679 (Thread-1): 16:53:30 | 28 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-05 23:53:30.531826 (Thread-4): Compiling model.github.github_issues
2020-05-05 23:53:30.532162 (Thread-1): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:53:30.544979 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_inbox_time).
2020-05-05 23:53:30.552058 (Thread-4): Writing injected SQL for node "model.github.github_issues"
2020-05-05 23:53:30.552181 (Thread-1): Compiling model.github.github_pull_requests
2020-05-05 23:53:30.571331 (Thread-1): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-05 23:53:30.571532 (Thread-4): finished collecting timing info
2020-05-05 23:53:30.577186 (Thread-4): Writing runtime SQL for node "model.github.github_issues"
2020-05-05 23:53:30.577593 (Thread-1): finished collecting timing info
2020-05-05 23:53:30.582343 (Thread-1): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-05 23:53:30.582573 (Thread-4): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-05 23:53:30.583858 (Thread-1): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.id = issue_assignees.issue_id
left join issue_open_length
  on issue.id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.id = pull_request.issue_id
left join pull_request_times
  on issue.id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-05 23:53:31.158217 (Thread-4): finished collecting timing info
2020-05-05 23:53:31.159078 (Thread-4): Database Error in model github_issues (models/github_issues.sql)
  Name days_blocked not found inside issue_blocked_time at [80:22]
  compiled SQL at target/run/github/github_issues.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/b69a2f1d-0c10-4021-ba00-0e6fe47df5b5?maxResults=0&location=US: Name days_blocked not found inside issue_blocked_time at [80:22]

(job ID: b69a2f1d-0c10-4021-ba00-0e6fe47df5b5)

                                                       -----Query Job SQL Follows-----                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_labels as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`issue_labels`
  16:
  17:), issue_projects as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`issue_projects`
  21:
  22:), repository as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  26:
  27:), milestone as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  31:
  32:), issue_assignees as (
  33:
  34:    select *
  35:    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  36:
  37:), issue_open_length as (
  38:
  39:    select *
  40:    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  41:
  42:), issue_blocked_time as (
  43:
  44:    select *
  45:    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  46:
  47:), issue_inbox_time as (
  48:
  49:    select *
  50:    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  51:
  52:), creator as (
  53:
  54:    select *
  55:    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  56:
  57:)
  58:
  59:select
  60:  issue.issue_id,
  61:  issue.body,
  62:  issue.closed_at,
  63:  issue.created_at,
  64:  issue.locked,
  65:  issue.milestone_id,
  66:  issue.number,
  67:  issue.repository_id,
  68:  issue.state,
  69:  issue.title,
  70:  issue.updated_at,
  71:  issue.user_id,
  72:  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  73:  issue_open_length.days_issue_opened,
  74:  labels.labels,
  75:  issue_projects.projects,
  76:  repository.full_name as repository,
  77:  milestone.title as milestone,
  78:  milestone.due_on as milestone_due_on,
  79:  issue_assignees.assignees,
  80:  issue_blocked_time.days_blocked,
  81:  issue_inbox_time.inbox_days,
  82:  creator.login as created_by
  83:from issue
  84:left join issue_labels as labels
  85:  on issue.issue_id = labels.issue_id
  86:left join issue_projects
  87:  on issue.issue_id = issue_projects.issue_id
  88:left join repository
  89:  on issue.repository_id = repository.id
  90:left join milestone
  91:  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
  92:left join issue_assignees
  93:  on issue.issue_id = issue_assignees.issue_id
  94:left join issue_open_length
  95:  on issue.issue_id = issue_open_length.issue_id
  96:left join issue_blocked_time
  97:  on issue.issue_id = issue_blocked_time.issue_id
  98:left join issue_inbox_time
  99:  on issue.issue_id = issue_inbox_time.issue_id
 100:left join creator on issue.user_id = creator.id
 101:where not issue.pull_request
 102:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model github_issues (models/github_issues.sql)
  Name days_blocked not found inside issue_blocked_time at [80:22]
  compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:53:31.164244 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbbd0d0>]}
2020-05-05 23:53:31.164529 (Thread-4): 16:53:31 | 27 of 29 ERROR creating view model dbt_erik.github_issues............ [ERROR in 0.63s]
2020-05-05 23:53:31.164702 (Thread-4): Finished running node model.github.github_issues
2020-05-05 23:53:31.172657 (Thread-1): finished collecting timing info
2020-05-05 23:53:31.173183 (Thread-1): Database Error in model github_pull_requests (models/github_pull_requests.sql)
  Name id not found inside issue at [73:12]
  compiled SQL at target/run/github/github_pull_requests.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/7fa7cb2d-8613-4ff5-80b0-710a6ba4654b?maxResults=0&location=US: Name id not found inside issue at [73:12]

(job ID: 7fa7cb2d-8613-4ff5-80b0-710a6ba4654b)

                                                          -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_labels as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`issue_labels`
  16:
  17:), repository as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  21:
  22:), issue_assignees as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  26:
  27:), issue_open_length as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  31:
  32:), creator as (
  33:
  34:    select *
  35:    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  36:
  37:), pull_request_times as (
  38:
  39:    select *
  40:    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  41:
  42:), pull_request as (
  43:
  44:    select *
  45:    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  46:
  47:)
  48:
  49:select
  50:  issue.id,
  51:  issue.body,
  52:  issue.closed_at,
  53:  issue.created_at,
  54:  issue.locked,
  55:  issue.number,
  56:  issue.repository_id,
  57:  issue.state,
  58:  issue.title,
  59:  issue.updated_at,
  60:  issue.user_id,
  61:  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  62:  issue_open_length.days_issue_opened,
  63:  labels.labels,
  64:  repository.full_name as repository,
  65:  issue_assignees.assignees,
  66:  creator.login as created_by,
  67:  hours_first_review_post_request,
  68:  hours_first_action_post_request,
  69:  hours_request_review_to_merge,
  70:  merged_at
  71:from issue
  72:left join issue_labels as labels
  73:  on issue.id = labels.issue_id
  74:left join repository
  75:  on issue.repository_id = repository.id
  76:left join issue_assignees
  77:  on issue.id = issue_assignees.issue_id
  78:left join issue_open_length
  79:  on issue.id = issue_open_length.issue_id
  80:left join creator 
  81:  on issue.user_id = creator.id
  82:left join pull_request
  83:  on issue.id = pull_request.issue_id
  84:left join pull_request_times
  85:  on issue.id = pull_request_times.issue_id
  86:where issue.pull_request
  87:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model github_pull_requests (models/github_pull_requests.sql)
  Name id not found inside issue at [73:12]
  compiled SQL at target/run/github/github_pull_requests.sql
2020-05-05 23:53:31.174021 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639f80c4-d079-4c77-b291-f4b79fe9505d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb0cc10>]}
2020-05-05 23:53:31.174245 (Thread-1): 16:53:31 | 28 of 29 ERROR creating view model dbt_erik.github_pull_requests..... [ERROR in 0.64s]
2020-05-05 23:53:31.174380 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-05 23:53:31.174709 (Thread-3): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:53:31.174856 (Thread-3): 16:53:31 | 29 of 29 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:53:31.174977 (Thread-3): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:53:31.217088 (MainThread): 16:53:31 | 
2020-05-05 23:53:31.217439 (MainThread): 16:53:31 | Finished running 29 view models in 7.28s.
2020-05-05 23:53:31.217670 (MainThread): Connection 'master' was left open.
2020-05-05 23:53:31.217838 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-05 23:53:31.217994 (MainThread): Connection 'model.github.issue_projects' was left open.
2020-05-05 23:53:31.218146 (MainThread): Connection 'model.github.issue_open_length' was left open.
2020-05-05 23:53:31.218295 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-05 23:53:31.290936 (MainThread): 
2020-05-05 23:53:31.291221 (MainThread): Completed with 2 errors and 0 warnings:
2020-05-05 23:53:31.291338 (MainThread): 
2020-05-05 23:53:31.291445 (MainThread): Database Error in model github_issues (models/github_issues.sql)
2020-05-05 23:53:31.291539 (MainThread):   Name days_blocked not found inside issue_blocked_time at [80:22]
2020-05-05 23:53:31.291663 (MainThread):   compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:53:31.291780 (MainThread): 
2020-05-05 23:53:31.292052 (MainThread): Database Error in model github_pull_requests (models/github_pull_requests.sql)
2020-05-05 23:53:31.292251 (MainThread):   Name id not found inside issue at [73:12]
2020-05-05 23:53:31.292341 (MainThread):   compiled SQL at target/run/github/github_pull_requests.sql
2020-05-05 23:53:31.292495 (MainThread): 
Done. PASS=27 WARN=0 ERROR=2 SKIP=0 TOTAL=29
2020-05-05 23:53:31.292663 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffb2910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3c1e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111048090>]}
2020-05-05 23:53:31.944393 (MainThread): Flushing usage events
2020-05-05 23:55:54.464537 (MainThread): Running with dbt=0.16.1
2020-05-05 23:55:54.610340 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:55:54.611396 (MainThread): Tracking: tracking
2020-05-05 23:55:54.617967 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcd0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcd00d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1bd4d0>]}
2020-05-05 23:55:54.640304 (MainThread): Partial parsing not enabled
2020-05-05 23:55:54.642887 (MainThread): Parsing macros/core.sql
2020-05-05 23:55:54.647492 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:55:54.656203 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:55:54.658306 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:55:54.677817 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:55:54.716364 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:55:54.739870 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:55:54.742136 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:55:54.749474 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:55:54.764316 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:55:54.771904 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:55:54.779562 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:55:54.785518 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:55:54.786597 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:55:54.787749 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:55:54.789523 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:55:54.792374 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:55:54.802900 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:55:54.805194 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:55:54.806345 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:55:54.852821 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:55:54.854150 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:55:54.855473 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:55:54.856655 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:55:54.859232 (MainThread): Parsing macros/etc.sql
2020-05-05 23:55:54.859935 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:55:54.867689 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:55:54.891710 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:55:54.893915 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:55:54.895478 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:55:54.906573 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:55:54.921429 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:55:54.942324 (MainThread): Partial parsing not enabled
2020-05-05 23:55:54.977904 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:55:54.978047 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:55:55.002040 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:55:55.002168 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.010723 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:55:55.010855 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.025219 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:55:55.025340 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.032493 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:55:55.032614 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.039204 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:55:55.039316 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.046456 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:55:55.046582 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.052476 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:55:55.052598 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.059569 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:55:55.059687 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.065254 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:55:55.065355 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.072461 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:55:55.072622 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.080422 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:55:55.080553 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.086264 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:55:55.086365 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.096230 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:55:55.096356 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.102092 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:55:55.102210 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.108013 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:55:55.108115 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.114609 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:55:55.114748 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.121670 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:55:55.121795 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.127462 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:55:55.127566 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.133247 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:55:55.133371 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.139072 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:55:55.139175 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.145817 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:55:55.145945 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.151742 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:55:55.151863 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.158362 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:55:55.158490 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.164270 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:55:55.164383 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.170145 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:55:55.170254 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.176421 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:55:55.176550 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.182172 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:55:55.182271 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.187992 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:55:55.188104 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.323830 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:55:55.578628 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-05 23:55:55.597031 (MainThread): 
2020-05-05 23:55:55.597377 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:55:55.597473 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:55:55.651648 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:55:55.651800 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:55:56.502249 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:55:56.502649 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:55:56.502975 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:55:56.691114 (MainThread): 16:55:56 | Concurrency: 4 threads (target='dev')
2020-05-05 23:55:56.691292 (MainThread): 16:55:56 | 
2020-05-05 23:55:56.693001 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:55:56.693169 (Thread-1): 16:55:56 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:55:56.693369 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:55:56.693517 (Thread-2): 16:55:56 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:55:56.693686 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:55:56.693903 (Thread-3): 16:55:56 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:55:56.694022 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:55:56.694147 (Thread-4): 16:55:56 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:55:56.694490 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:55:56.694581 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:55:56.694675 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:55:56.707137 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:55:56.709810 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:55:56.709908 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:55:56.710190 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:55:56.710504 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:55:56.710694 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:55:56.710888 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:55:56.711209 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:55:56.718268 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:55:56.718413 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:55:56.718534 (Thread-1): finished collecting timing info
2020-05-05 23:55:56.718761 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:55:56.726362 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:55:56.732188 (Thread-2): finished collecting timing info
2020-05-05 23:55:56.755936 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:55:56.843101 (Thread-3): finished collecting timing info
2020-05-05 23:55:56.922098 (Thread-4): finished collecting timing info
2020-05-05 23:55:57.063001 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:55:57.063807 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:55:57.075011 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:55:57.082108 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:55:57.083453 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:55:57.084891 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:55:57.086100 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:55:57.087207 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:55:57.710913 (Thread-1): finished collecting timing info
2020-05-05 23:55:57.711807 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e49e210>]}
2020-05-05 23:55:57.712116 (Thread-1): 16:55:57 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.02s]
2020-05-05 23:55:57.712293 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:55:57.712466 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:55:57.712638 (Thread-1): 16:55:57 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:55:57.712954 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:55:57.713077 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:55:57.713200 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:55:57.722159 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:55:57.723556 (Thread-1): finished collecting timing info
2020-05-05 23:55:57.728410 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:55:57.729225 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:55:57.858503 (Thread-3): finished collecting timing info
2020-05-05 23:55:57.859526 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e458490>]}
2020-05-05 23:55:57.859897 (Thread-3): 16:55:57 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.15s]
2020-05-05 23:55:57.860110 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:55:57.860321 (Thread-3): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:55:57.860533 (Thread-3): 16:55:57 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:55:57.860913 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:55:57.861036 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:55:57.861164 (Thread-3): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:55:57.870112 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:55:57.870671 (Thread-3): finished collecting timing info
2020-05-05 23:55:57.875569 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:55:57.876001 (Thread-3): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:55:57.896324 (Thread-4): finished collecting timing info
2020-05-05 23:55:57.897391 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e39ed50>]}
2020-05-05 23:55:57.897761 (Thread-4): 16:55:57 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.19s]
2020-05-05 23:55:57.897967 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:55:57.898263 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-05 23:55:57.898687 (Thread-4): 16:55:57 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:55:57.899055 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:55:57.899179 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:55:57.899299 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-05 23:55:57.908669 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:55:57.909063 (Thread-4): finished collecting timing info
2020-05-05 23:55:57.913680 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:55:57.914078 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:55:57.928271 (Thread-2): finished collecting timing info
2020-05-05 23:55:57.928993 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e49e890>]}
2020-05-05 23:55:57.929255 (Thread-2): 16:55:57 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.22s]
2020-05-05 23:55:57.929408 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:55:57.929534 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:55:57.929660 (Thread-2): 16:55:57 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:55:57.929896 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:55:57.929985 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:55:57.930075 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:55:57.937365 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:55:57.937929 (Thread-2): finished collecting timing info
2020-05-05 23:55:57.942652 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:55:57.943059 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:55:58.282366 (Thread-1): finished collecting timing info
2020-05-05 23:55:58.283329 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9d3450>]}
2020-05-05 23:55:58.283640 (Thread-1): 16:55:58 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.57s]
2020-05-05 23:55:58.283879 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:55:58.284087 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:55:58.284270 (Thread-1): 16:55:58 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:55:58.284603 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:55:58.284728 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:55:58.284852 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:55:58.293267 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:55:58.293675 (Thread-1): finished collecting timing info
2020-05-05 23:55:58.298184 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:55:58.298548 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:55:58.579032 (Thread-4): finished collecting timing info
2020-05-05 23:55:58.580039 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8b8b50>]}
2020-05-05 23:55:58.580340 (Thread-4): 16:55:58 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.68s]
2020-05-05 23:55:58.580513 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-05 23:55:58.580685 (Thread-4): Began running node model.github.stg_github_issue_merged
2020-05-05 23:55:58.580855 (Thread-4): 16:55:58 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:55:58.581177 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:55:58.581299 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:55:58.581421 (Thread-4): Compiling model.github.stg_github_issue_merged
2020-05-05 23:55:58.589987 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:55:58.590523 (Thread-4): finished collecting timing info
2020-05-05 23:55:58.595063 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:55:58.595501 (Thread-4): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:55:58.609562 (Thread-2): finished collecting timing info
2020-05-05 23:55:58.610187 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8a6c50>]}
2020-05-05 23:55:58.610410 (Thread-2): 16:55:58 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.68s]
2020-05-05 23:55:58.610532 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:55:58.610739 (Thread-2): Began running node model.github.stg_github_project
2020-05-05 23:55:58.611157 (Thread-2): 16:55:58 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-05 23:55:58.611434 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:55:58.611519 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:55:58.611602 (Thread-2): Compiling model.github.stg_github_project
2020-05-05 23:55:58.618590 (Thread-2): Writing injected SQL for node "model.github.stg_github_project"
2020-05-05 23:55:58.619175 (Thread-2): finished collecting timing info
2020-05-05 23:55:58.624499 (Thread-2): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-05 23:55:58.624934 (Thread-2): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-05 23:55:58.986038 (Thread-3): finished collecting timing info
2020-05-05 23:55:58.987090 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e933a50>]}
2020-05-05 23:55:58.987462 (Thread-3): 16:55:58 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 1.13s]
2020-05-05 23:55:58.987675 (Thread-3): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:55:58.987887 (Thread-3): Began running node model.github.stg_github_pull_request
2020-05-05 23:55:58.988273 (Thread-3): 16:55:58 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:55:58.988800 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:55:58.988934 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:55:58.989062 (Thread-3): Compiling model.github.stg_github_pull_request
2020-05-05 23:55:58.998661 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:55:58.999090 (Thread-3): finished collecting timing info
2020-05-05 23:55:59.004086 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:55:59.006069 (Thread-3): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:55:59.041398 (Thread-1): finished collecting timing info
2020-05-05 23:55:59.042420 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3b5790>]}
2020-05-05 23:55:59.042788 (Thread-1): 16:55:59 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.76s]
2020-05-05 23:55:59.043092 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:55:59.043331 (Thread-1): Began running node model.github.stg_github_repository
2020-05-05 23:55:59.043720 (Thread-1): 16:55:59 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:55:59.044158 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:55:59.044305 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:55:59.044445 (Thread-1): Compiling model.github.stg_github_repository
2020-05-05 23:55:59.053051 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:55:59.053455 (Thread-1): finished collecting timing info
2020-05-05 23:55:59.057938 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:55:59.058322 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:55:59.199299 (Thread-4): finished collecting timing info
2020-05-05 23:55:59.200505 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4300d0>]}
2020-05-05 23:55:59.201239 (Thread-4): 16:55:59 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.62s]
2020-05-05 23:55:59.201828 (Thread-4): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:55:59.202036 (Thread-4): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:55:59.202220 (Thread-4): 16:55:59 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:55:59.202573 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:55:59.202695 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:55:59.202816 (Thread-4): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:55:59.211758 (Thread-4): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:55:59.212527 (Thread-4): finished collecting timing info
2020-05-05 23:55:59.217072 (Thread-4): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:55:59.217502 (Thread-4): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:55:59.322185 (Thread-2): finished collecting timing info
2020-05-05 23:55:59.323203 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e458e90>]}
2020-05-05 23:55:59.323565 (Thread-2): 16:55:59 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.71s]
2020-05-05 23:55:59.323769 (Thread-2): Finished running node model.github.stg_github_project
2020-05-05 23:55:59.323979 (Thread-2): Began running node model.github.stg_github_milestone
2020-05-05 23:55:59.324397 (Thread-2): 16:55:59 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:55:59.324764 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:55:59.324887 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-05 23:55:59.325002 (Thread-2): Compiling model.github.stg_github_milestone
2020-05-05 23:55:59.333413 (Thread-2): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:55:59.333833 (Thread-2): finished collecting timing info
2020-05-05 23:55:59.338556 (Thread-2): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:55:59.338957 (Thread-2): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:55:59.560445 (Thread-3): finished collecting timing info
2020-05-05 23:55:59.561480 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea1ad90>]}
2020-05-05 23:55:59.561845 (Thread-3): 16:55:59 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.57s]
2020-05-05 23:55:59.562047 (Thread-3): Finished running node model.github.stg_github_pull_request
2020-05-05 23:55:59.562253 (Thread-3): Began running node model.github.stg_github_issue_comment
2020-05-05 23:55:59.562457 (Thread-3): 16:55:59 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:55:59.562861 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:55:59.562977 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:55:59.563093 (Thread-3): Compiling model.github.stg_github_issue_comment
2020-05-05 23:55:59.572348 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:55:59.572821 (Thread-3): finished collecting timing info
2020-05-05 23:55:59.578265 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:55:59.578715 (Thread-3): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:55:59.605515 (Thread-1): finished collecting timing info
2020-05-05 23:55:59.606139 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3f5950>]}
2020-05-05 23:55:59.606370 (Thread-1): 16:55:59 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.56s]
2020-05-05 23:55:59.606505 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-05 23:55:59.606629 (Thread-1): Began running node model.github.issue_close_stack
2020-05-05 23:55:59.606750 (Thread-1): 16:55:59 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:55:59.607076 (Thread-1): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:55:59.607182 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:55:59.607272 (Thread-1): Compiling model.github.issue_close_stack
2020-05-05 23:55:59.616080 (Thread-1): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:55:59.616471 (Thread-1): finished collecting timing info
2020-05-05 23:55:59.620664 (Thread-1): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:55:59.620990 (Thread-1): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:55:59.770492 (Thread-4): finished collecting timing info
2020-05-05 23:55:59.771499 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8cdc90>]}
2020-05-05 23:55:59.771865 (Thread-4): 16:55:59 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.57s]
2020-05-05 23:55:59.772139 (Thread-4): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:55:59.772424 (Thread-4): Began running node model.github.issue_status_windows
2020-05-05 23:55:59.772611 (Thread-4): 16:55:59 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:55:59.773141 (Thread-4): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:55:59.773308 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:55:59.773438 (Thread-4): Compiling model.github.issue_status_windows
2020-05-05 23:55:59.784219 (Thread-4): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:55:59.784643 (Thread-4): finished collecting timing info
2020-05-05 23:55:59.789131 (Thread-4): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:55:59.789457 (Thread-4): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:56:00.139723 (Thread-2): finished collecting timing info
2020-05-05 23:56:00.140596 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9117d0>]}
2020-05-05 23:56:00.140902 (Thread-2): 16:56:00 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.82s]
2020-05-05 23:56:00.141079 (Thread-2): Finished running node model.github.stg_github_milestone
2020-05-05 23:56:00.142084 (Thread-2): Began running node model.github.issue_labels
2020-05-05 23:56:00.142799 (Thread-2): 16:56:00 | 19 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:56:00.143529 (Thread-2): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:56:00.143645 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:56:00.143751 (Thread-2): Compiling model.github.issue_labels
2020-05-05 23:56:00.151218 (Thread-2): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:56:00.151617 (Thread-2): finished collecting timing info
2020-05-05 23:56:00.156523 (Thread-2): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:56:00.156957 (Thread-2): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:56:00.271180 (Thread-1): finished collecting timing info
2020-05-05 23:56:00.273274 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4c29d0>]}
2020-05-05 23:56:00.277063 (Thread-3): finished collecting timing info
2020-05-05 23:56:00.277995 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9926d0>]}
2020-05-05 23:56:00.278315 (Thread-3): 16:56:00 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.72s]
2020-05-05 23:56:00.278568 (Thread-1): 16:56:00 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.67s]
2020-05-05 23:56:00.278691 (Thread-3): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:56:00.278842 (Thread-1): Finished running node model.github.issue_close_stack
2020-05-05 23:56:00.278991 (Thread-3): Began running node model.github.pull_request_reviewers
2020-05-05 23:56:00.279135 (Thread-1): Began running node model.github.issue_assignees
2020-05-05 23:56:00.279464 (Thread-3): 16:56:00 | 20 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:56:00.279599 (Thread-1): 16:56:00 | 21 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:56:00.279946 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:56:00.280238 (Thread-1): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:56:00.280335 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:56:00.280457 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:56:00.280572 (Thread-3): Compiling model.github.pull_request_reviewers
2020-05-05 23:56:00.280675 (Thread-1): Compiling model.github.issue_assignees
2020-05-05 23:56:00.288985 (Thread-3): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:56:00.296177 (Thread-1): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:56:00.296678 (Thread-1): finished collecting timing info
2020-05-05 23:56:00.300939 (Thread-1): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:56:00.301137 (Thread-3): finished collecting timing info
2020-05-05 23:56:00.305528 (Thread-3): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:56:00.305958 (Thread-3): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:56:00.308499 (Thread-1): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:56:00.335932 (Thread-4): finished collecting timing info
2020-05-05 23:56:00.336814 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9bdf90>]}
2020-05-05 23:56:00.337108 (Thread-4): 16:56:00 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.56s]
2020-05-05 23:56:00.337276 (Thread-4): Finished running node model.github.issue_status_windows
2020-05-05 23:56:00.337443 (Thread-4): Began running node model.github.issue_blocked_time
2020-05-05 23:56:00.337788 (Thread-4): 16:56:00 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:56:00.338274 (Thread-4): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:56:00.338401 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:56:00.338520 (Thread-4): Compiling model.github.issue_blocked_time
2020-05-05 23:56:00.380002 (Thread-4): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:56:00.380539 (Thread-4): finished collecting timing info
2020-05-05 23:56:00.386070 (Thread-4): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:56:00.386511 (Thread-4): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked_by_support
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:56:00.850134 (Thread-2): finished collecting timing info
2020-05-05 23:56:00.851303 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea2bdd0>]}
2020-05-05 23:56:00.851624 (Thread-2): 16:56:00 | 19 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.71s]
2020-05-05 23:56:00.851928 (Thread-2): Finished running node model.github.issue_labels
2020-05-05 23:56:00.852469 (Thread-2): Began running node model.github.pull_request_times
2020-05-05 23:56:00.852677 (Thread-2): 16:56:00 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:56:00.853029 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:56:00.853152 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:56:00.853276 (Thread-2): Compiling model.github.pull_request_times
2020-05-05 23:56:00.866566 (Thread-2): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:56:00.867131 (Thread-2): finished collecting timing info
2020-05-05 23:56:00.871835 (Thread-2): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:56:00.872258 (Thread-2): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:56:00.889670 (Thread-1): finished collecting timing info
2020-05-05 23:56:00.890329 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa0b10>]}
2020-05-05 23:56:00.890558 (Thread-1): 16:56:00 | 21 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.61s]
2020-05-05 23:56:00.890682 (Thread-1): Finished running node model.github.issue_assignees
2020-05-05 23:56:00.890805 (Thread-1): Began running node model.github.issue_open_length
2020-05-05 23:56:00.890924 (Thread-1): 16:56:00 | 24 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:56:00.891159 (Thread-1): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:56:00.891243 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:56:00.891327 (Thread-1): Compiling model.github.issue_open_length
2020-05-05 23:56:00.897829 (Thread-1): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:56:00.898173 (Thread-1): finished collecting timing info
2020-05-05 23:56:00.902693 (Thread-1): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:56:00.905821 (Thread-4): finished collecting timing info
2020-05-05 23:56:00.906486 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e58a1d0>]}
2020-05-05 23:56:00.906709 (Thread-4): 16:56:00 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.57s]
2020-05-05 23:56:00.906965 (Thread-4): Finished running node model.github.issue_blocked_time
2020-05-05 23:56:00.907102 (Thread-4): Began running node model.github.issue_inbox_time
2020-05-05 23:56:00.907496 (Thread-1): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:56:00.907646 (Thread-4): 16:56:00 | 25 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-05 23:56:00.908977 (Thread-4): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:56:00.909279 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-05 23:56:00.909518 (Thread-4): Compiling model.github.issue_inbox_time
2020-05-05 23:56:00.917287 (Thread-4): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-05 23:56:00.918227 (Thread-4): finished collecting timing info
2020-05-05 23:56:00.922511 (Thread-4): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-05 23:56:00.922865 (Thread-4): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-05 23:56:00.977022 (Thread-3): finished collecting timing info
2020-05-05 23:56:00.978283 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9aaa10>]}
2020-05-05 23:56:00.978683 (Thread-3): 16:56:00 | 20 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.70s]
2020-05-05 23:56:00.978861 (Thread-3): Finished running node model.github.pull_request_reviewers
2020-05-05 23:56:00.979130 (Thread-3): Began running node model.github.issue_projects
2020-05-05 23:56:00.979320 (Thread-3): 16:56:00 | 26 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-05 23:56:00.979684 (Thread-3): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:56:00.979806 (Thread-3): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-05 23:56:00.979928 (Thread-3): Compiling model.github.issue_projects
2020-05-05 23:56:00.989468 (Thread-3): Writing injected SQL for node "model.github.issue_projects"
2020-05-05 23:56:00.989855 (Thread-3): finished collecting timing info
2020-05-05 23:56:00.994430 (Thread-3): Writing runtime SQL for node "model.github.issue_projects"
2020-05-05 23:56:00.994855 (Thread-3): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-05 23:56:01.526905 (Thread-1): finished collecting timing info
2020-05-05 23:56:01.527929 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa0c10>]}
2020-05-05 23:56:01.528298 (Thread-1): 16:56:01 | 24 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.64s]
2020-05-05 23:56:01.528503 (Thread-1): Finished running node model.github.issue_open_length
2020-05-05 23:56:01.608105 (Thread-4): finished collecting timing info
2020-05-05 23:56:01.609451 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e98e890>]}
2020-05-05 23:56:01.610633 (Thread-4): 16:56:01 | 25 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.70s]
2020-05-05 23:56:01.610828 (Thread-4): Finished running node model.github.issue_inbox_time
2020-05-05 23:56:01.738619 (Thread-2): finished collecting timing info
2020-05-05 23:56:01.739755 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaba950>]}
2020-05-05 23:56:01.740142 (Thread-2): 16:56:01 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.89s]
2020-05-05 23:56:01.740353 (Thread-2): Finished running node model.github.pull_request_times
2020-05-05 23:56:01.740871 (Thread-1): Began running node model.github.github_pull_requests
2020-05-05 23:56:01.741103 (Thread-1): 16:56:01 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-05 23:56:01.741692 (Thread-1): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:56:01.741847 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-05 23:56:01.741975 (Thread-1): Compiling model.github.github_pull_requests
2020-05-05 23:56:01.758026 (Thread-1): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-05 23:56:01.758406 (Thread-1): finished collecting timing info
2020-05-05 23:56:01.762597 (Thread-1): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-05 23:56:01.762918 (Thread-1): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-05 23:56:01.835002 (Thread-3): finished collecting timing info
2020-05-05 23:56:01.836270 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaaec90>]}
2020-05-05 23:56:01.836680 (Thread-3): 16:56:01 | 26 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.86s]
2020-05-05 23:56:01.836900 (Thread-3): Finished running node model.github.issue_projects
2020-05-05 23:56:01.837425 (Thread-2): Began running node model.github.github_issues
2020-05-05 23:56:01.837650 (Thread-2): 16:56:01 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-05 23:56:01.838002 (Thread-2): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:56:01.838124 (Thread-2): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-05 23:56:01.838244 (Thread-2): Compiling model.github.github_issues
2020-05-05 23:56:01.856641 (Thread-2): Writing injected SQL for node "model.github.github_issues"
2020-05-05 23:56:01.857030 (Thread-2): finished collecting timing info
2020-05-05 23:56:01.861279 (Thread-2): Writing runtime SQL for node "model.github.github_issues"
2020-05-05 23:56:01.861602 (Thread-2): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-05 23:56:02.431136 (Thread-1): finished collecting timing info
2020-05-05 23:56:02.432309 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8e7d50>]}
2020-05-05 23:56:02.432687 (Thread-1): 16:56:02 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 0.69s]
2020-05-05 23:56:02.432893 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-05 23:56:02.579956 (Thread-2): finished collecting timing info
2020-05-05 23:56:02.580894 (Thread-2): Database Error in model github_issues (models/github_issues.sql)
  Name days_blocked not found inside issue_blocked_time at [80:22]
  compiled SQL at target/run/github/github_issues.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/dd1d6ca7-ce20-44f6-876d-e3839bef4f15?maxResults=0&location=US: Name days_blocked not found inside issue_blocked_time at [80:22]

(job ID: dd1d6ca7-ce20-44f6-876d-e3839bef4f15)

                                                       -----Query Job SQL Follows-----                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
   5:  OPTIONS()
   6:  as (
   7:    with issue as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  11:  
  12:), issue_labels as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`issue_labels`
  16:
  17:), issue_projects as (
  18:
  19:    select *
  20:    from `digital-arbor-400`.`dbt_erik`.`issue_projects`
  21:
  22:), repository as (
  23:
  24:    select *
  25:    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  26:
  27:), milestone as (
  28:
  29:    select *
  30:    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  31:
  32:), issue_assignees as (
  33:
  34:    select *
  35:    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  36:
  37:), issue_open_length as (
  38:
  39:    select *
  40:    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  41:
  42:), issue_blocked_time as (
  43:
  44:    select *
  45:    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  46:
  47:), issue_inbox_time as (
  48:
  49:    select *
  50:    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  51:
  52:), creator as (
  53:
  54:    select *
  55:    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  56:
  57:)
  58:
  59:select
  60:  issue.issue_id,
  61:  issue.body,
  62:  issue.closed_at,
  63:  issue.created_at,
  64:  issue.locked,
  65:  issue.milestone_id,
  66:  issue.number,
  67:  issue.repository_id,
  68:  issue.state,
  69:  issue.title,
  70:  issue.updated_at,
  71:  issue.user_id,
  72:  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  73:  issue_open_length.days_issue_opened,
  74:  labels.labels,
  75:  issue_projects.projects,
  76:  repository.full_name as repository,
  77:  milestone.title as milestone,
  78:  milestone.due_on as milestone_due_on,
  79:  issue_assignees.assignees,
  80:  issue_blocked_time.days_blocked,
  81:  issue_inbox_time.inbox_days,
  82:  creator.login as created_by
  83:from issue
  84:left join issue_labels as labels
  85:  on issue.issue_id = labels.issue_id
  86:left join issue_projects
  87:  on issue.issue_id = issue_projects.issue_id
  88:left join repository
  89:  on issue.repository_id = repository.id
  90:left join milestone
  91:  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
  92:left join issue_assignees
  93:  on issue.issue_id = issue_assignees.issue_id
  94:left join issue_open_length
  95:  on issue.issue_id = issue_open_length.issue_id
  96:left join issue_blocked_time
  97:  on issue.issue_id = issue_blocked_time.issue_id
  98:left join issue_inbox_time
  99:  on issue.issue_id = issue_inbox_time.issue_id
 100:left join creator on issue.user_id = creator.id
 101:where not issue.pull_request
 102:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model github_issues (models/github_issues.sql)
  Name days_blocked not found inside issue_blocked_time at [80:22]
  compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:56:02.587980 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91f3084a-9f9d-4b71-9bbb-014ab951777a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8dd610>]}
2020-05-05 23:56:02.588344 (Thread-2): 16:56:02 | 28 of 29 ERROR creating view model dbt_erik.github_issues............ [ERROR in 0.75s]
2020-05-05 23:56:02.588532 (Thread-2): Finished running node model.github.github_issues
2020-05-05 23:56:02.588949 (Thread-3): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:56:02.589135 (Thread-3): 16:56:02 | 29 of 29 SKIP relation dbt_erik.issues_and_prs_per_month............. [SKIP]
2020-05-05 23:56:02.589306 (Thread-3): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:56:02.692121 (MainThread): 16:56:02 | 
2020-05-05 23:56:02.692603 (MainThread): 16:56:02 | Finished running 29 view models in 7.09s.
2020-05-05 23:56:02.692941 (MainThread): Connection 'master' was left open.
2020-05-05 23:56:02.693106 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-05 23:56:02.693258 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-05 23:56:02.693403 (MainThread): Connection 'model.github.issue_projects' was left open.
2020-05-05 23:56:02.693545 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-05 23:56:02.766058 (MainThread): 
2020-05-05 23:56:02.766217 (MainThread): Completed with 1 error and 0 warnings:
2020-05-05 23:56:02.766388 (MainThread): 
2020-05-05 23:56:02.766538 (MainThread): Database Error in model github_issues (models/github_issues.sql)
2020-05-05 23:56:02.766694 (MainThread):   Name days_blocked not found inside issue_blocked_time at [80:22]
2020-05-05 23:56:02.766824 (MainThread):   compiled SQL at target/run/github/github_issues.sql
2020-05-05 23:56:02.766992 (MainThread): 
Done. PASS=28 WARN=0 ERROR=1 SKIP=0 TOTAL=29
2020-05-05 23:56:02.767322 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea99290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea4cd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4963d0>]}
2020-05-05 23:56:03.451308 (MainThread): Flushing usage events
2020-05-05 23:56:52.733424 (MainThread): Running with dbt=0.16.1
2020-05-05 23:56:52.876539 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-05 23:56:52.877487 (MainThread): Tracking: tracking
2020-05-05 23:56:52.885058 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db25f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e057b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e06a790>]}
2020-05-05 23:56:52.906837 (MainThread): Partial parsing not enabled
2020-05-05 23:56:52.908742 (MainThread): Parsing macros/core.sql
2020-05-05 23:56:52.913369 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-05 23:56:52.921937 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-05 23:56:52.923943 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-05 23:56:52.942919 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-05 23:56:52.979092 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-05 23:56:53.002174 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-05 23:56:53.004524 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-05 23:56:53.011501 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-05 23:56:53.025463 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-05 23:56:53.032441 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-05 23:56:53.040408 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-05 23:56:53.046091 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-05 23:56:53.047135 (MainThread): Parsing macros/etc/query.sql
2020-05-05 23:56:53.048275 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-05 23:56:53.050028 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-05 23:56:53.052240 (MainThread): Parsing macros/etc/datetime.sql
2020-05-05 23:56:53.062075 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-05 23:56:53.064157 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-05 23:56:53.065260 (MainThread): Parsing macros/adapters/common.sql
2020-05-05 23:56:53.113242 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-05 23:56:53.114576 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-05 23:56:53.115606 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-05 23:56:53.117108 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-05 23:56:53.120304 (MainThread): Parsing macros/etc.sql
2020-05-05 23:56:53.121190 (MainThread): Parsing macros/catalog.sql
2020-05-05 23:56:53.129176 (MainThread): Parsing macros/adapters.sql
2020-05-05 23:56:53.152170 (MainThread): Parsing macros/materializations/seed.sql
2020-05-05 23:56:53.154293 (MainThread): Parsing macros/materializations/view.sql
2020-05-05 23:56:53.155809 (MainThread): Parsing macros/materializations/table.sql
2020-05-05 23:56:53.167063 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-05 23:56:53.182131 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-05 23:56:53.202601 (MainThread): Partial parsing not enabled
2020-05-05 23:56:53.237279 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:56:53.237421 (MainThread): Opening a new connection, currently in state init
2020-05-05 23:56:53.260721 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:56:53.260852 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.267596 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:56:53.267786 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.283141 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:56:53.283272 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.290341 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:56:53.290472 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.297070 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:56:53.297181 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.305813 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:56:53.305942 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.312041 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:56:53.312164 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.318649 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:56:53.318755 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.324434 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:56:53.324552 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.330932 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:56:53.331033 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.338937 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:56:53.339067 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.344826 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:56:53.344944 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.354532 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:56:53.354659 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.360576 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:56:53.360691 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.367240 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:56:53.367370 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.373692 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:56:53.373822 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.380305 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:56:53.380421 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.386124 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:56:53.386233 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.391680 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:56:53.391782 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.397903 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:56:53.398022 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.404816 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:56:53.404953 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.410820 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:56:53.410939 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.416651 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:56:53.416756 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.422613 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:56:53.422727 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.428361 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:56:53.428492 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.434098 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:56:53.434276 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.441144 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:56:53.441270 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.447119 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:56:53.447220 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.579789 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-05 23:56:53.830243 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-05 23:56:53.848635 (MainThread): 
2020-05-05 23:56:53.848976 (MainThread): Acquiring new bigquery connection "master".
2020-05-05 23:56:53.849065 (MainThread): Opening a new connection, currently in state closed
2020-05-05 23:56:53.902750 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-05 23:56:53.902900 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-05 23:56:54.707115 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-05 23:56:54.707500 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-05 23:56:54.708076 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-05 23:56:54.890021 (MainThread): 16:56:54 | Concurrency: 4 threads (target='dev')
2020-05-05 23:56:54.890193 (MainThread): 16:56:54 | 
2020-05-05 23:56:54.892013 (Thread-1): Began running node model.github.stg_github_issue
2020-05-05 23:56:54.892179 (Thread-1): 16:56:54 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-05 23:56:54.892362 (Thread-2): Began running node model.github.stg_github_card
2020-05-05 23:56:54.892507 (Thread-2): 16:56:54 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-05 23:56:54.892724 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-05 23:56:54.893133 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-05 23:56:54.893400 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-05 23:56:54.893525 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-05 23:56:54.893643 (Thread-3): 16:56:54 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-05 23:56:54.893738 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-05 23:56:54.893893 (Thread-2): Opening a new connection, currently in state init
2020-05-05 23:56:54.894042 (Thread-4): 16:56:54 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-05 23:56:54.894409 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-05 23:56:54.894530 (Thread-1): Compiling model.github.stg_github_issue
2020-05-05 23:56:54.894645 (Thread-2): Compiling model.github.stg_github_card
2020-05-05 23:56:54.894963 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-05 23:56:54.895041 (Thread-3): Opening a new connection, currently in state init
2020-05-05 23:56:54.913090 (Thread-4): Opening a new connection, currently in state init
2020-05-05 23:56:54.916207 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-05 23:56:54.916666 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-05 23:56:54.916780 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-05 23:56:54.916869 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-05 23:56:54.923454 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:56:54.929115 (Thread-2): finished collecting timing info
2020-05-05 23:56:54.930958 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:56:54.936966 (Thread-1): finished collecting timing info
2020-05-05 23:56:55.004876 (Thread-4): finished collecting timing info
2020-05-05 23:56:55.011580 (Thread-3): finished collecting timing info
2020-05-05 23:56:55.350851 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-05 23:56:55.355114 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-05 23:56:55.377282 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-05 23:56:55.387704 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-05 23:56:55.388912 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-05 23:56:55.390338 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-05 23:56:55.391727 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-05 23:56:55.392989 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-05 23:56:55.955815 (Thread-1): finished collecting timing info
2020-05-05 23:56:55.956864 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e293450>]}
2020-05-05 23:56:55.957256 (Thread-1): 16:56:55 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.06s]
2020-05-05 23:56:55.957464 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-05 23:56:55.957685 (Thread-1): Began running node model.github.stg_github_user
2020-05-05 23:56:55.958127 (Thread-1): 16:56:55 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-05 23:56:55.958487 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-05 23:56:55.958606 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-05 23:56:55.958726 (Thread-1): Compiling model.github.stg_github_user
2020-05-05 23:56:55.967319 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-05 23:56:55.967878 (Thread-1): finished collecting timing info
2020-05-05 23:56:55.972454 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-05 23:56:55.972852 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-05 23:56:56.190299 (Thread-3): finished collecting timing info
2020-05-05 23:56:56.191331 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d9390>]}
2020-05-05 23:56:56.191703 (Thread-3): 16:56:56 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.30s]
2020-05-05 23:56:56.191908 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-05 23:56:56.192117 (Thread-3): Began running node model.github.stg_github_issue_assignee
2020-05-05 23:56:56.192327 (Thread-3): 16:56:56 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-05 23:56:56.192732 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-05 23:56:56.192879 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-05 23:56:56.192996 (Thread-3): Compiling model.github.stg_github_issue_assignee
2020-05-05 23:56:56.201600 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:56:56.202070 (Thread-3): finished collecting timing info
2020-05-05 23:56:56.207815 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-05 23:56:56.208215 (Thread-3): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-05 23:56:56.590790 (Thread-4): finished collecting timing info
2020-05-05 23:56:56.591631 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e212c90>]}
2020-05-05 23:56:56.591928 (Thread-4): 16:56:56 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.70s]
2020-05-05 23:56:56.592094 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-05 23:56:56.592262 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-05 23:56:56.592429 (Thread-4): 16:56:56 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-05 23:56:56.592883 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-05 23:56:56.593016 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-05 23:56:56.593137 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-05 23:56:56.601391 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:56:56.601817 (Thread-4): finished collecting timing info
2020-05-05 23:56:56.606898 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-05 23:56:56.607335 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-05 23:56:56.700231 (Thread-2): finished collecting timing info
2020-05-05 23:56:56.701257 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e729850>]}
2020-05-05 23:56:56.701638 (Thread-2): 16:56:56 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.81s]
2020-05-05 23:56:56.701844 (Thread-2): Finished running node model.github.stg_github_card
2020-05-05 23:56:56.702062 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-05 23:56:56.702288 (Thread-2): 16:56:56 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-05 23:56:56.702614 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-05 23:56:56.702730 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-05 23:56:56.702848 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-05 23:56:56.711784 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:56:56.712296 (Thread-2): finished collecting timing info
2020-05-05 23:56:56.717063 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-05 23:56:56.717443 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-05 23:56:56.783125 (Thread-1): finished collecting timing info
2020-05-05 23:56:56.784170 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e310810>]}
2020-05-05 23:56:56.784534 (Thread-1): 16:56:56 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.83s]
2020-05-05 23:56:56.784742 (Thread-1): Finished running node model.github.stg_github_user
2020-05-05 23:56:56.784953 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-05 23:56:56.785161 (Thread-1): 16:56:56 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-05 23:56:56.785559 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-05 23:56:56.785678 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-05 23:56:56.785797 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-05 23:56:56.795315 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:56:56.797884 (Thread-3): finished collecting timing info
2020-05-05 23:56:56.798479 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f894a90>]}
2020-05-05 23:56:56.798699 (Thread-3): 16:56:56 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.61s]
2020-05-05 23:56:56.798889 (Thread-3): Finished running node model.github.stg_github_issue_assignee
2020-05-05 23:56:56.799116 (Thread-3): Began running node model.github.stg_github_issue_merged
2020-05-05 23:56:56.799266 (Thread-3): 16:56:56 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-05 23:56:56.799516 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-05 23:56:56.799606 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-05 23:56:56.799694 (Thread-3): Compiling model.github.stg_github_issue_merged
2020-05-05 23:56:56.806244 (Thread-1): finished collecting timing info
2020-05-05 23:56:56.807613 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:56:56.811754 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-05 23:56:56.812321 (Thread-3): finished collecting timing info
2020-05-05 23:56:56.816446 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-05 23:56:56.816676 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-05 23:56:56.817806 (Thread-3): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-05 23:56:57.214275 (Thread-4): finished collecting timing info
2020-05-05 23:56:57.215436 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d9510>]}
2020-05-05 23:56:57.215832 (Thread-4): 16:56:57 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.62s]
2020-05-05 23:56:57.216041 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-05 23:56:57.216252 (Thread-4): Began running node model.github.stg_github_project
2020-05-05 23:56:57.216463 (Thread-4): 16:56:57 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-05 23:56:57.216850 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-05 23:56:57.216967 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-05 23:56:57.217085 (Thread-4): Compiling model.github.stg_github_project
2020-05-05 23:56:57.226706 (Thread-4): Writing injected SQL for node "model.github.stg_github_project"
2020-05-05 23:56:57.227118 (Thread-4): finished collecting timing info
2020-05-05 23:56:57.231644 (Thread-4): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-05 23:56:57.231989 (Thread-4): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-05 23:56:57.315521 (Thread-2): finished collecting timing info
2020-05-05 23:56:57.316528 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b7b10>]}
2020-05-05 23:56:57.316889 (Thread-2): 16:56:57 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.61s]
2020-05-05 23:56:57.317091 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-05 23:56:57.317355 (Thread-2): Began running node model.github.stg_github_pull_request
2020-05-05 23:56:57.317552 (Thread-2): 16:56:57 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-05 23:56:57.318023 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-05 23:56:57.318160 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-05 23:56:57.318284 (Thread-2): Compiling model.github.stg_github_pull_request
2020-05-05 23:56:57.326872 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:56:57.327267 (Thread-2): finished collecting timing info
2020-05-05 23:56:57.331683 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-05 23:56:57.332036 (Thread-2): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-05 23:56:57.414975 (Thread-3): finished collecting timing info
2020-05-05 23:56:57.416000 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e310d50>]}
2020-05-05 23:56:57.417171 (Thread-3): 16:56:57 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.62s]
2020-05-05 23:56:57.417412 (Thread-3): Finished running node model.github.stg_github_issue_merged
2020-05-05 23:56:57.417686 (Thread-3): Began running node model.github.stg_github_repository
2020-05-05 23:56:57.418113 (Thread-3): 16:56:57 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-05 23:56:57.418976 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-05 23:56:57.419132 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-05 23:56:57.419284 (Thread-3): Compiling model.github.stg_github_repository
2020-05-05 23:56:57.427667 (Thread-1): finished collecting timing info
2020-05-05 23:56:57.428366 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f894710>]}
2020-05-05 23:56:57.431389 (Thread-3): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-05 23:56:57.431599 (Thread-1): 16:56:57 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.64s]
2020-05-05 23:56:57.431854 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-05 23:56:57.432002 (Thread-1): Began running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:56:57.432134 (Thread-1): 16:56:57 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-05 23:56:57.432391 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-05 23:56:57.432478 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-05 23:56:57.432566 (Thread-1): Compiling model.github.stg_github_requested_reviewer_history
2020-05-05 23:56:57.439682 (Thread-1): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:56:57.440073 (Thread-3): finished collecting timing info
2020-05-05 23:56:57.445003 (Thread-3): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-05 23:56:57.445244 (Thread-1): finished collecting timing info
2020-05-05 23:56:57.449369 (Thread-1): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-05 23:56:57.449733 (Thread-3): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-05 23:56:57.450014 (Thread-1): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-05 23:56:57.839700 (Thread-2): finished collecting timing info
2020-05-05 23:56:57.840731 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e21c210>]}
2020-05-05 23:56:57.841101 (Thread-2): 16:56:57 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.52s]
2020-05-05 23:56:57.841304 (Thread-2): Finished running node model.github.stg_github_pull_request
2020-05-05 23:56:57.841509 (Thread-2): Began running node model.github.stg_github_milestone
2020-05-05 23:56:57.841846 (Thread-2): 16:56:57 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-05 23:56:57.842194 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-05 23:56:57.842312 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-05 23:56:57.842430 (Thread-2): Compiling model.github.stg_github_milestone
2020-05-05 23:56:57.851041 (Thread-2): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-05 23:56:57.851489 (Thread-2): finished collecting timing info
2020-05-05 23:56:57.856549 (Thread-2): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-05 23:56:57.856979 (Thread-2): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-05 23:56:58.194162 (Thread-3): finished collecting timing info
2020-05-05 23:56:58.195242 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e734250>]}
2020-05-05 23:56:58.195571 (Thread-3): 16:56:58 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.78s]
2020-05-05 23:56:58.196025 (Thread-3): Finished running node model.github.stg_github_repository
2020-05-05 23:56:58.196273 (Thread-3): Began running node model.github.stg_github_issue_comment
2020-05-05 23:56:58.198966 (Thread-3): 16:56:58 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-05 23:56:58.200118 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-05 23:56:58.200464 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-05 23:56:58.200852 (Thread-3): Compiling model.github.stg_github_issue_comment
2020-05-05 23:56:58.209614 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:56:58.210264 (Thread-3): finished collecting timing info
2020-05-05 23:56:58.214699 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-05 23:56:58.215031 (Thread-3): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-05 23:56:58.315456 (Thread-4): finished collecting timing info
2020-05-05 23:56:58.316492 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e341550>]}
2020-05-05 23:56:58.316810 (Thread-4): 16:56:58 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 1.10s]
2020-05-05 23:56:58.316979 (Thread-4): Finished running node model.github.stg_github_project
2020-05-05 23:56:58.317148 (Thread-4): Began running node model.github.issue_close_stack
2020-05-05 23:56:58.317473 (Thread-4): 16:56:58 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-05 23:56:58.317836 (Thread-4): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-05 23:56:58.317955 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-05 23:56:58.318072 (Thread-4): Compiling model.github.issue_close_stack
2020-05-05 23:56:58.327814 (Thread-4): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-05 23:56:58.328228 (Thread-4): finished collecting timing info
2020-05-05 23:56:58.332700 (Thread-4): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-05 23:56:58.333026 (Thread-4): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-05 23:56:58.527510 (Thread-1): finished collecting timing info
2020-05-05 23:56:58.528545 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f831d10>]}
2020-05-05 23:56:58.528912 (Thread-1): 16:56:58 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 1.10s]
2020-05-05 23:56:58.529118 (Thread-1): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-05 23:56:58.529324 (Thread-1): Began running node model.github.issue_status_windows
2020-05-05 23:56:58.529532 (Thread-1): 16:56:58 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-05 23:56:58.529893 (Thread-1): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-05 23:56:58.530009 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-05 23:56:58.530125 (Thread-1): Compiling model.github.issue_status_windows
2020-05-05 23:56:58.539874 (Thread-1): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-05 23:56:58.540332 (Thread-1): finished collecting timing info
2020-05-05 23:56:58.544830 (Thread-1): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-05 23:56:58.545188 (Thread-1): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-05 23:56:58.725072 (Thread-2): finished collecting timing info
2020-05-05 23:56:58.726376 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e768590>]}
2020-05-05 23:56:58.726862 (Thread-2): 16:56:58 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.88s]
2020-05-05 23:56:58.727102 (Thread-2): Finished running node model.github.stg_github_milestone
2020-05-05 23:56:58.727411 (Thread-2): Began running node model.github.issue_assignees
2020-05-05 23:56:58.727779 (Thread-2): 16:56:58 | 19 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-05 23:56:58.728189 (Thread-2): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-05 23:56:58.728319 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-05 23:56:58.728440 (Thread-2): Compiling model.github.issue_assignees
2020-05-05 23:56:58.738247 (Thread-2): Writing injected SQL for node "model.github.issue_assignees"
2020-05-05 23:56:58.738670 (Thread-2): finished collecting timing info
2020-05-05 23:56:58.743199 (Thread-2): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-05 23:56:58.743566 (Thread-2): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-05 23:56:58.887467 (Thread-3): finished collecting timing info
2020-05-05 23:56:58.889350 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8c4ad0>]}
2020-05-05 23:56:58.890854 (Thread-3): 16:56:58 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.69s]
2020-05-05 23:56:58.891185 (Thread-3): Finished running node model.github.stg_github_issue_comment
2020-05-05 23:56:58.891384 (Thread-3): Began running node model.github.issue_labels
2020-05-05 23:56:58.891944 (Thread-3): 16:56:58 | 20 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-05 23:56:58.892712 (Thread-3): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-05 23:56:58.892869 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-05 23:56:58.893218 (Thread-3): Compiling model.github.issue_labels
2020-05-05 23:56:58.901131 (Thread-3): Writing injected SQL for node "model.github.issue_labels"
2020-05-05 23:56:58.901602 (Thread-3): finished collecting timing info
2020-05-05 23:56:58.906873 (Thread-3): Writing runtime SQL for node "model.github.issue_labels"
2020-05-05 23:56:58.907295 (Thread-3): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-05 23:56:59.170334 (Thread-1): finished collecting timing info
2020-05-05 23:56:59.171217 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f899d10>]}
2020-05-05 23:56:59.171525 (Thread-1): 16:56:59 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.64s]
2020-05-05 23:56:59.171691 (Thread-1): Finished running node model.github.issue_status_windows
2020-05-05 23:56:59.171860 (Thread-1): Began running node model.github.pull_request_reviewers
2020-05-05 23:56:59.172026 (Thread-1): 16:56:59 | 21 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-05 23:56:59.172345 (Thread-1): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-05 23:56:59.172460 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-05 23:56:59.172579 (Thread-1): Compiling model.github.pull_request_reviewers
2020-05-05 23:56:59.183704 (Thread-1): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:56:59.185324 (Thread-1): finished collecting timing info
2020-05-05 23:56:59.222929 (Thread-1): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-05 23:56:59.226624 (Thread-1): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-05 23:56:59.336802 (Thread-4): finished collecting timing info
2020-05-05 23:56:59.338890 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db01710>]}
2020-05-05 23:56:59.339238 (Thread-4): 16:56:59 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 1.02s]
2020-05-05 23:56:59.340054 (Thread-4): Finished running node model.github.issue_close_stack
2020-05-05 23:56:59.340264 (Thread-4): Began running node model.github.issue_blocked_time
2020-05-05 23:56:59.340450 (Thread-4): 16:56:59 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-05 23:56:59.342077 (Thread-4): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-05 23:56:59.345359 (Thread-2): finished collecting timing info
2020-05-05 23:56:59.345577 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-05 23:56:59.346335 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f92f050>]}
2020-05-05 23:56:59.346710 (Thread-4): Compiling model.github.issue_blocked_time
2020-05-05 23:56:59.347278 (Thread-2): 16:56:59 | 19 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.62s]
2020-05-05 23:56:59.355375 (Thread-4): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-05 23:56:59.355641 (Thread-2): Finished running node model.github.issue_assignees
2020-05-05 23:56:59.355937 (Thread-2): Began running node model.github.pull_request_times
2020-05-05 23:56:59.356096 (Thread-2): 16:56:59 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-05 23:56:59.356374 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-05 23:56:59.356466 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-05 23:56:59.356555 (Thread-2): Compiling model.github.pull_request_times
2020-05-05 23:56:59.367245 (Thread-2): Writing injected SQL for node "model.github.pull_request_times"
2020-05-05 23:56:59.367966 (Thread-4): finished collecting timing info
2020-05-05 23:56:59.373538 (Thread-4): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-05 23:56:59.373694 (Thread-2): finished collecting timing info
2020-05-05 23:56:59.378503 (Thread-2): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-05 23:56:59.378936 (Thread-4): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-05 23:56:59.379792 (Thread-2): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-05 23:56:59.465408 (Thread-3): finished collecting timing info
2020-05-05 23:56:59.466444 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e78ab10>]}
2020-05-05 23:56:59.466816 (Thread-3): 16:56:59 | 20 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.57s]
2020-05-05 23:56:59.467031 (Thread-3): Finished running node model.github.issue_labels
2020-05-05 23:56:59.467315 (Thread-3): Began running node model.github.issue_inbox_time
2020-05-05 23:56:59.467557 (Thread-3): 16:56:59 | 24 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-05 23:56:59.468157 (Thread-3): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-05 23:56:59.468293 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-05 23:56:59.468414 (Thread-3): Compiling model.github.issue_inbox_time
2020-05-05 23:56:59.476921 (Thread-3): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-05 23:56:59.477364 (Thread-3): finished collecting timing info
2020-05-05 23:56:59.482574 (Thread-3): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-05 23:56:59.482937 (Thread-3): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-05 23:56:59.977514 (Thread-4): finished collecting timing info
2020-05-05 23:56:59.978630 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e270250>]}
2020-05-05 23:56:59.978999 (Thread-4): 16:56:59 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.64s]
2020-05-05 23:56:59.979203 (Thread-4): Finished running node model.github.issue_blocked_time
2020-05-05 23:56:59.979412 (Thread-4): Began running node model.github.issue_projects
2020-05-05 23:56:59.979603 (Thread-4): 16:56:59 | 25 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-05 23:56:59.980045 (Thread-4): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-05 23:56:59.980178 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-05 23:56:59.980299 (Thread-4): Compiling model.github.issue_projects
2020-05-05 23:56:59.989609 (Thread-4): Writing injected SQL for node "model.github.issue_projects"
2020-05-05 23:56:59.990006 (Thread-4): finished collecting timing info
2020-05-05 23:56:59.994738 (Thread-4): Writing runtime SQL for node "model.github.issue_projects"
2020-05-05 23:56:59.996445 (Thread-4): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-05 23:57:00.099826 (Thread-1): finished collecting timing info
2020-05-05 23:57:00.100847 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f951b50>]}
2020-05-05 23:57:00.101213 (Thread-1): 16:57:00 | 21 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.93s]
2020-05-05 23:57:00.101416 (Thread-1): Finished running node model.github.pull_request_reviewers
2020-05-05 23:57:00.101622 (Thread-1): Began running node model.github.issue_open_length
2020-05-05 23:57:00.101826 (Thread-1): 16:57:00 | 26 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-05 23:57:00.102431 (Thread-1): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-05 23:57:00.102593 (Thread-1): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-05 23:57:00.102768 (Thread-1): Compiling model.github.issue_open_length
2020-05-05 23:57:00.111017 (Thread-1): Writing injected SQL for node "model.github.issue_open_length"
2020-05-05 23:57:00.111440 (Thread-1): finished collecting timing info
2020-05-05 23:57:00.116178 (Thread-1): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-05 23:57:00.116595 (Thread-1): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-05 23:57:00.375508 (Thread-3): finished collecting timing info
2020-05-05 23:57:00.376540 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e74b050>]}
2020-05-05 23:57:00.376867 (Thread-3): 16:57:00 | 24 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.91s]
2020-05-05 23:57:00.377032 (Thread-3): Finished running node model.github.issue_inbox_time
2020-05-05 23:57:00.461167 (Thread-2): finished collecting timing info
2020-05-05 23:57:00.462204 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9332d0>]}
2020-05-05 23:57:00.462565 (Thread-2): 16:57:00 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 1.11s]
2020-05-05 23:57:00.462765 (Thread-2): Finished running node model.github.pull_request_times
2020-05-05 23:57:00.719017 (Thread-1): finished collecting timing info
2020-05-05 23:57:00.720033 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f939350>]}
2020-05-05 23:57:00.720389 (Thread-1): 16:57:00 | 26 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.62s]
2020-05-05 23:57:00.720590 (Thread-1): Finished running node model.github.issue_open_length
2020-05-05 23:57:00.721150 (Thread-3): Began running node model.github.github_pull_requests
2020-05-05 23:57:00.721349 (Thread-3): 16:57:00 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-05 23:57:00.721684 (Thread-3): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-05 23:57:00.721805 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_inbox_time).
2020-05-05 23:57:00.721925 (Thread-3): Compiling model.github.github_pull_requests
2020-05-05 23:57:00.738032 (Thread-3): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-05 23:57:00.738435 (Thread-3): finished collecting timing info
2020-05-05 23:57:00.742760 (Thread-3): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-05 23:57:00.743094 (Thread-3): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-05 23:57:00.858147 (Thread-4): finished collecting timing info
2020-05-05 23:57:00.859162 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e746a90>]}
2020-05-05 23:57:00.859527 (Thread-4): 16:57:00 | 25 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.88s]
2020-05-05 23:57:00.859731 (Thread-4): Finished running node model.github.issue_projects
2020-05-05 23:57:00.860257 (Thread-1): Began running node model.github.github_issues
2020-05-05 23:57:00.860497 (Thread-1): 16:57:00 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-05 23:57:00.860933 (Thread-1): Acquiring new bigquery connection "model.github.github_issues".
2020-05-05 23:57:00.861072 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-05 23:57:00.861195 (Thread-1): Compiling model.github.github_issues
2020-05-05 23:57:00.880190 (Thread-1): Writing injected SQL for node "model.github.github_issues"
2020-05-05 23:57:00.880567 (Thread-1): finished collecting timing info
2020-05-05 23:57:00.885135 (Thread-1): Writing runtime SQL for node "model.github.github_issues"
2020-05-05 23:57:00.885517 (Thread-1): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-05 23:57:01.584200 (Thread-3): finished collecting timing info
2020-05-05 23:57:01.585235 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db25b50>]}
2020-05-05 23:57:01.585607 (Thread-3): 16:57:01 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 0.86s]
2020-05-05 23:57:01.585810 (Thread-3): Finished running node model.github.github_pull_requests
2020-05-05 23:57:02.030067 (Thread-1): finished collecting timing info
2020-05-05 23:57:02.031102 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0e6890>]}
2020-05-05 23:57:02.031472 (Thread-1): 16:57:02 | 28 of 29 OK created view model dbt_erik.github_issues................ [CREATE VIEW in 1.17s]
2020-05-05 23:57:02.031675 (Thread-1): Finished running node model.github.github_issues
2020-05-05 23:57:02.032138 (Thread-4): Began running node model.github.issues_and_prs_per_month
2020-05-05 23:57:02.032392 (Thread-4): 16:57:02 | 29 of 29 START view model dbt_erik.issues_and_prs_per_month.......... [RUN]
2020-05-05 23:57:02.032752 (Thread-4): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-05 23:57:02.032870 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_projects).
2020-05-05 23:57:02.032986 (Thread-4): Compiling model.github.issues_and_prs_per_month
2020-05-05 23:57:02.043106 (Thread-4): Writing injected SQL for node "model.github.issues_and_prs_per_month"
2020-05-05 23:57:02.043547 (Thread-4): finished collecting timing info
2020-05-05 23:57:02.048237 (Thread-4): Writing runtime SQL for node "model.github.issues_and_prs_per_month"
2020-05-05 23:57:02.048627 (Thread-4): On model.github.issues_and_prs_per_month: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month.month 
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month.month 
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month.month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-05 23:57:02.387801 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month.month 
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month.month 
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month.month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-05 23:57:02.388149 (Thread-4): 404 Not found: Dataset digital-arbor-400:issues_opened_per_month was not found in location US

(job ID: 5096af28-a0a9-493a-88f3-1bb810e65d94)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month.month 
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month.month 
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month.month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-05 23:57:02.388552 (Thread-4): finished collecting timing info
2020-05-05 23:57:02.389500 (Thread-4): Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  404 Not found: Dataset digital-arbor-400:issues_opened_per_month was not found in location US
  
  (job ID: 5096af28-a0a9-493a-88f3-1bb810e65d94)
  
                                                              -----Query Job SQL Follows-----                                                             
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
     2:
     3:
     4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
     5:  OPTIONS()
     6:  as (
     7:    with github_issues as (
     8:
     9:    select *
    10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
    11:
    12:), pull_requests as (
    13:
    14:    select *
    15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
    16:
    17:), issues_opened_per_month as (
    18:
    19:   select 
    20:      date_trunc(date(created_at), month) as month, 
    21:      count(*) as number_issues_opened,
    22:      avg(days_issue_opened) as average_length_issue_open,
    23:      max(days_issue_opened) as longest_length_issue_open
    24:    from github_issues
    25:    group by 1
    26:
    27:), issues_closed_per_month as (
    28:
    29:   select 
    30:      date_trunc(date(closed_at), month) as month, 
    31:      count(*) as number_issues_closed
    32:    from github_issues
    33:    where closed_at is not null
    34:    group by 1
    35:
    36:), prs_opened_per_month as (
    37:
    38:   select 
    39:      date_trunc(date(created_at), month) as month, 
    40:      count(*) as number_prs_opened,
    41:      avg(days_issue_opened) as average_length_pr_open,
    42:      max(days_issue_opened) as longest_length_pr_open
    43:    from pull_requests
    44:    group by 1
    45:
    46:), prs_merged_per_month as (
    47:
    48:   select 
    49:      date_trunc(date(merged_at), month) as month, 
    50:      count(*) as number_prs_merged
    51:    from github_issues
    52:    group by 1
    53:
    54:), issues_per_month as (
    55:
    56:    select 
    57:      coalesce(issues_opened_per_month.month, 
    58:        issues_closed_per_month.month
    59:      ) as month,
    60:      number_issues_opened,
    61:      number_issues_closed,      
    62:      average_length_issue_open,
    63:      longest_length_issue_open
    64:    from issues_opened_per_month.month 
    65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
    66:
    67:), prs_per_month as (
    68:
    69:    select 
    70:      coalesce(prs_opened_per_month.month, 
    71:        prs_merged_per_month.month
    72:      ) as month,
    73:      number_prs_opened,
    74:      number_prs_merged,
    75:      average_length_pr_open,
    76:      longest_length_pr_open
    77:    from prs_opened_per_month.month 
    78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    79:
    80:)
    81:
    82:select 
    83:  coalesce(issues_per_month.month, 
    84:    prs_per_month.month
    85:  ) as month,
    86:  coalesce(number_issues_opened, 0) as number_issues_opened,
    87:  coalesce(number_issues_closed, 0) as number_issues_closed,
    88:  average_length_issue_open,
    89:  longest_length_issue_open,
    90:  coalesce(number_prs_opened, 0) as number_prs_opened,
    91:  coalesce(number_prs_merged, 0) as number_prs_merged,
    92:  average_length_pr_open,
    93:  longest_length_pr_open
    94:from prs_opened_per_month.month 
    95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    96:  );
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset digital-arbor-400:issues_opened_per_month was not found in location US

(job ID: 5096af28-a0a9-493a-88f3-1bb810e65d94)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month.month 
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month.month 
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month.month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  404 Not found: Dataset digital-arbor-400:issues_opened_per_month was not found in location US
  
  (job ID: 5096af28-a0a9-493a-88f3-1bb810e65d94)
  
                                                              -----Query Job SQL Follows-----                                                             
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
     2:
     3:
     4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
     5:  OPTIONS()
     6:  as (
     7:    with github_issues as (
     8:
     9:    select *
    10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
    11:
    12:), pull_requests as (
    13:
    14:    select *
    15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
    16:
    17:), issues_opened_per_month as (
    18:
    19:   select 
    20:      date_trunc(date(created_at), month) as month, 
    21:      count(*) as number_issues_opened,
    22:      avg(days_issue_opened) as average_length_issue_open,
    23:      max(days_issue_opened) as longest_length_issue_open
    24:    from github_issues
    25:    group by 1
    26:
    27:), issues_closed_per_month as (
    28:
    29:   select 
    30:      date_trunc(date(closed_at), month) as month, 
    31:      count(*) as number_issues_closed
    32:    from github_issues
    33:    where closed_at is not null
    34:    group by 1
    35:
    36:), prs_opened_per_month as (
    37:
    38:   select 
    39:      date_trunc(date(created_at), month) as month, 
    40:      count(*) as number_prs_opened,
    41:      avg(days_issue_opened) as average_length_pr_open,
    42:      max(days_issue_opened) as longest_length_pr_open
    43:    from pull_requests
    44:    group by 1
    45:
    46:), prs_merged_per_month as (
    47:
    48:   select 
    49:      date_trunc(date(merged_at), month) as month, 
    50:      count(*) as number_prs_merged
    51:    from github_issues
    52:    group by 1
    53:
    54:), issues_per_month as (
    55:
    56:    select 
    57:      coalesce(issues_opened_per_month.month, 
    58:        issues_closed_per_month.month
    59:      ) as month,
    60:      number_issues_opened,
    61:      number_issues_closed,      
    62:      average_length_issue_open,
    63:      longest_length_issue_open
    64:    from issues_opened_per_month.month 
    65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
    66:
    67:), prs_per_month as (
    68:
    69:    select 
    70:      coalesce(prs_opened_per_month.month, 
    71:        prs_merged_per_month.month
    72:      ) as month,
    73:      number_prs_opened,
    74:      number_prs_merged,
    75:      average_length_pr_open,
    76:      longest_length_pr_open
    77:    from prs_opened_per_month.month 
    78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    79:
    80:)
    81:
    82:select 
    83:  coalesce(issues_per_month.month, 
    84:    prs_per_month.month
    85:  ) as month,
    86:  coalesce(number_issues_opened, 0) as number_issues_opened,
    87:  coalesce(number_issues_closed, 0) as number_issues_closed,
    88:  average_length_issue_open,
    89:  longest_length_issue_open,
    90:  coalesce(number_prs_opened, 0) as number_prs_opened,
    91:  coalesce(number_prs_merged, 0) as number_prs_merged,
    92:  average_length_pr_open,
    93:  longest_length_pr_open
    94:from prs_opened_per_month.month 
    95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    96:  );
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-05 23:57:02.394315 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618625e5-e019-4c71-8329-b23aa0609404', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f85ba50>]}
2020-05-05 23:57:02.993370 (Thread-4): 16:57:02 | 29 of 29 ERROR creating view model dbt_erik.issues_and_prs_per_month. [ERROR in 0.36s]
2020-05-05 23:57:02.993717 (Thread-4): Finished running node model.github.issues_and_prs_per_month
2020-05-05 23:57:03.079198 (MainThread): 16:57:03 | 
2020-05-05 23:57:03.079649 (MainThread): 16:57:03 | Finished running 29 view models in 9.23s.
2020-05-05 23:57:03.079877 (MainThread): Connection 'master' was left open.
2020-05-05 23:57:03.080039 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-05 23:57:03.080191 (MainThread): Connection 'model.github.pull_request_times' was left open.
2020-05-05 23:57:03.080336 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-05 23:57:03.080477 (MainThread): Connection 'model.github.issues_and_prs_per_month' was left open.
2020-05-05 23:57:03.151988 (MainThread): 
2020-05-05 23:57:03.152153 (MainThread): Completed with 1 error and 0 warnings:
2020-05-05 23:57:03.152298 (MainThread): 
2020-05-05 23:57:03.152402 (MainThread): Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
2020-05-05 23:57:03.152490 (MainThread):   404 Not found: Dataset digital-arbor-400:issues_opened_per_month was not found in location US
2020-05-05 23:57:03.152597 (MainThread):   
2020-05-05 23:57:03.152727 (MainThread):   (job ID: 5096af28-a0a9-493a-88f3-1bb810e65d94)
2020-05-05 23:57:03.152832 (MainThread):   
2020-05-05 23:57:03.152961 (MainThread):                                                               -----Query Job SQL Follows-----                                                             
2020-05-05 23:57:03.153038 (MainThread):   
2020-05-05 23:57:03.153113 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-05 23:57:03.153208 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
2020-05-05 23:57:03.153300 (MainThread):      2:
2020-05-05 23:57:03.153397 (MainThread):      3:
2020-05-05 23:57:03.153489 (MainThread):      4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
2020-05-05 23:57:03.153582 (MainThread):      5:  OPTIONS()
2020-05-05 23:57:03.153673 (MainThread):      6:  as (
2020-05-05 23:57:03.153747 (MainThread):      7:    with github_issues as (
2020-05-05 23:57:03.153821 (MainThread):      8:
2020-05-05 23:57:03.153895 (MainThread):      9:    select *
2020-05-05 23:57:03.153969 (MainThread):     10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
2020-05-05 23:57:03.154043 (MainThread):     11:
2020-05-05 23:57:03.154117 (MainThread):     12:), pull_requests as (
2020-05-05 23:57:03.154191 (MainThread):     13:
2020-05-05 23:57:03.154265 (MainThread):     14:    select *
2020-05-05 23:57:03.154339 (MainThread):     15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
2020-05-05 23:57:03.154412 (MainThread):     16:
2020-05-05 23:57:03.154486 (MainThread):     17:), issues_opened_per_month as (
2020-05-05 23:57:03.154560 (MainThread):     18:
2020-05-05 23:57:03.154633 (MainThread):     19:   select 
2020-05-05 23:57:03.154706 (MainThread):     20:      date_trunc(date(created_at), month) as month, 
2020-05-05 23:57:03.154780 (MainThread):     21:      count(*) as number_issues_opened,
2020-05-05 23:57:03.154854 (MainThread):     22:      avg(days_issue_opened) as average_length_issue_open,
2020-05-05 23:57:03.154928 (MainThread):     23:      max(days_issue_opened) as longest_length_issue_open
2020-05-05 23:57:03.155004 (MainThread):     24:    from github_issues
2020-05-05 23:57:03.155078 (MainThread):     25:    group by 1
2020-05-05 23:57:03.155152 (MainThread):     26:
2020-05-05 23:57:03.155225 (MainThread):     27:), issues_closed_per_month as (
2020-05-05 23:57:03.155334 (MainThread):     28:
2020-05-05 23:57:03.155407 (MainThread):     29:   select 
2020-05-05 23:57:03.155481 (MainThread):     30:      date_trunc(date(closed_at), month) as month, 
2020-05-05 23:57:03.155555 (MainThread):     31:      count(*) as number_issues_closed
2020-05-05 23:57:03.155629 (MainThread):     32:    from github_issues
2020-05-05 23:57:03.155702 (MainThread):     33:    where closed_at is not null
2020-05-05 23:57:03.155785 (MainThread):     34:    group by 1
2020-05-05 23:57:03.155860 (MainThread):     35:
2020-05-05 23:57:03.155934 (MainThread):     36:), prs_opened_per_month as (
2020-05-05 23:57:03.156007 (MainThread):     37:
2020-05-05 23:57:03.156081 (MainThread):     38:   select 
2020-05-05 23:57:03.156154 (MainThread):     39:      date_trunc(date(created_at), month) as month, 
2020-05-05 23:57:03.156264 (MainThread):     40:      count(*) as number_prs_opened,
2020-05-05 23:57:03.156369 (MainThread):     41:      avg(days_issue_opened) as average_length_pr_open,
2020-05-05 23:57:03.156462 (MainThread):     42:      max(days_issue_opened) as longest_length_pr_open
2020-05-05 23:57:03.156572 (MainThread):     43:    from pull_requests
2020-05-05 23:57:03.156682 (MainThread):     44:    group by 1
2020-05-05 23:57:03.156795 (MainThread):     45:
2020-05-05 23:57:03.156869 (MainThread):     46:), prs_merged_per_month as (
2020-05-05 23:57:03.156942 (MainThread):     47:
2020-05-05 23:57:03.157016 (MainThread):     48:   select 
2020-05-05 23:57:03.157090 (MainThread):     49:      date_trunc(date(merged_at), month) as month, 
2020-05-05 23:57:03.157163 (MainThread):     50:      count(*) as number_prs_merged
2020-05-05 23:57:03.157237 (MainThread):     51:    from github_issues
2020-05-05 23:57:03.157311 (MainThread):     52:    group by 1
2020-05-05 23:57:03.157385 (MainThread):     53:
2020-05-05 23:57:03.157458 (MainThread):     54:), issues_per_month as (
2020-05-05 23:57:03.157532 (MainThread):     55:
2020-05-05 23:57:03.157605 (MainThread):     56:    select 
2020-05-05 23:57:03.157678 (MainThread):     57:      coalesce(issues_opened_per_month.month, 
2020-05-05 23:57:03.157751 (MainThread):     58:        issues_closed_per_month.month
2020-05-05 23:57:03.157824 (MainThread):     59:      ) as month,
2020-05-05 23:57:03.157898 (MainThread):     60:      number_issues_opened,
2020-05-05 23:57:03.157971 (MainThread):     61:      number_issues_closed,      
2020-05-05 23:57:03.158045 (MainThread):     62:      average_length_issue_open,
2020-05-05 23:57:03.158119 (MainThread):     63:      longest_length_issue_open
2020-05-05 23:57:03.158192 (MainThread):     64:    from issues_opened_per_month.month 
2020-05-05 23:57:03.158265 (MainThread):     65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
2020-05-05 23:57:03.158340 (MainThread):     66:
2020-05-05 23:57:03.158413 (MainThread):     67:), prs_per_month as (
2020-05-05 23:57:03.158487 (MainThread):     68:
2020-05-05 23:57:03.158560 (MainThread):     69:    select 
2020-05-05 23:57:03.158633 (MainThread):     70:      coalesce(prs_opened_per_month.month, 
2020-05-05 23:57:03.158707 (MainThread):     71:        prs_merged_per_month.month
2020-05-05 23:57:03.158781 (MainThread):     72:      ) as month,
2020-05-05 23:57:03.158854 (MainThread):     73:      number_prs_opened,
2020-05-05 23:57:03.158928 (MainThread):     74:      number_prs_merged,
2020-05-05 23:57:03.159002 (MainThread):     75:      average_length_pr_open,
2020-05-05 23:57:03.159075 (MainThread):     76:      longest_length_pr_open
2020-05-05 23:57:03.159148 (MainThread):     77:    from prs_opened_per_month.month 
2020-05-05 23:57:03.159222 (MainThread):     78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
2020-05-05 23:57:03.159296 (MainThread):     79:
2020-05-05 23:57:03.159369 (MainThread):     80:)
2020-05-05 23:57:03.159442 (MainThread):     81:
2020-05-05 23:57:03.159515 (MainThread):     82:select 
2020-05-05 23:57:03.159588 (MainThread):     83:  coalesce(issues_per_month.month, 
2020-05-05 23:57:03.159662 (MainThread):     84:    prs_per_month.month
2020-05-05 23:57:03.159736 (MainThread):     85:  ) as month,
2020-05-05 23:57:03.159809 (MainThread):     86:  coalesce(number_issues_opened, 0) as number_issues_opened,
2020-05-05 23:57:03.159883 (MainThread):     87:  coalesce(number_issues_closed, 0) as number_issues_closed,
2020-05-05 23:57:03.159957 (MainThread):     88:  average_length_issue_open,
2020-05-05 23:57:03.160059 (MainThread):     89:  longest_length_issue_open,
2020-05-05 23:57:03.160171 (MainThread):     90:  coalesce(number_prs_opened, 0) as number_prs_opened,
2020-05-05 23:57:03.160299 (MainThread):     91:  coalesce(number_prs_merged, 0) as number_prs_merged,
2020-05-05 23:57:03.160373 (MainThread):     92:  average_length_pr_open,
2020-05-05 23:57:03.160446 (MainThread):     93:  longest_length_pr_open
2020-05-05 23:57:03.160520 (MainThread):     94:from prs_opened_per_month.month 
2020-05-05 23:57:03.160594 (MainThread):     95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
2020-05-05 23:57:03.160669 (MainThread):     96:  );
2020-05-05 23:57:03.160742 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-05 23:57:03.160848 (MainThread): 
Done. PASS=28 WARN=0 ERROR=1 SKIP=0 TOTAL=29
2020-05-05 23:57:03.161002 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e102f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f951f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e232ed0>]}
2020-05-05 23:57:03.161175 (MainThread): Flushing usage events
2020-05-06 00:20:33.798428 (MainThread): Running with dbt=0.16.1
2020-05-06 00:20:33.994431 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-06 00:20:33.995856 (MainThread): Tracking: tracking
2020-05-06 00:20:34.004441 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103be0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104130bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103bec350>]}
2020-05-06 00:20:34.027000 (MainThread): Partial parsing not enabled
2020-05-06 00:20:34.030182 (MainThread): Parsing macros/core.sql
2020-05-06 00:20:34.035029 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-06 00:20:34.044300 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-06 00:20:34.046656 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-06 00:20:34.066052 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-06 00:20:34.102941 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-06 00:20:34.127277 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-06 00:20:34.130012 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-06 00:20:34.137451 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-06 00:20:34.151479 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-06 00:20:34.159292 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-06 00:20:34.170887 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-06 00:20:34.178266 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-06 00:20:34.180155 (MainThread): Parsing macros/etc/query.sql
2020-05-06 00:20:34.181850 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-06 00:20:34.183967 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-06 00:20:34.186606 (MainThread): Parsing macros/etc/datetime.sql
2020-05-06 00:20:34.197903 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-06 00:20:34.200462 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-06 00:20:34.202338 (MainThread): Parsing macros/adapters/common.sql
2020-05-06 00:20:34.247691 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-06 00:20:34.249698 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-06 00:20:34.251386 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-06 00:20:34.253198 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-06 00:20:34.256524 (MainThread): Parsing macros/etc.sql
2020-05-06 00:20:34.257629 (MainThread): Parsing macros/catalog.sql
2020-05-06 00:20:34.266245 (MainThread): Parsing macros/adapters.sql
2020-05-06 00:20:34.297377 (MainThread): Parsing macros/materializations/seed.sql
2020-05-06 00:20:34.300713 (MainThread): Parsing macros/materializations/view.sql
2020-05-06 00:20:34.302806 (MainThread): Parsing macros/materializations/table.sql
2020-05-06 00:20:34.314133 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-06 00:20:34.329074 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-06 00:20:34.351509 (MainThread): Partial parsing not enabled
2020-05-06 00:20:34.387665 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:20:34.387808 (MainThread): Opening a new connection, currently in state init
2020-05-06 00:20:34.412006 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:20:34.412137 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.420321 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:20:34.420461 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.436492 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:20:34.436626 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.444371 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:20:34.444508 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.452388 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:20:34.452537 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.459786 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:20:34.459923 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.466893 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:20:34.467032 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.474968 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:20:34.475092 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.481409 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:20:34.481548 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.489765 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:20:34.489910 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.500283 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:20:34.500437 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.508133 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:20:34.508276 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.518961 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:20:34.519096 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.528062 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:20:34.528200 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.535543 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:20:34.535696 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.542764 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:20:34.542900 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.550719 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:20:34.550864 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.557862 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:20:34.558036 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.565332 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:20:34.565466 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.572623 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:20:34.572760 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.580229 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:20:34.580372 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.587125 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:20:34.587267 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.594816 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:20:34.594964 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.602209 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:20:34.602351 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.609095 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:20:34.609256 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.618907 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:20:34.619096 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.628029 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:20:34.628190 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.635774 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:20:34.635921 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:34.774974 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-06 00:20:35.027276 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-06 00:20:35.045216 (MainThread): 
2020-05-06 00:20:35.045592 (MainThread): Acquiring new bigquery connection "master".
2020-05-06 00:20:35.045686 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:20:35.100002 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-06 00:20:35.100283 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-06 00:20:36.050888 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-06 00:20:36.051283 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-06 00:20:36.051602 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-06 00:20:36.244259 (MainThread): 17:20:36 | Concurrency: 4 threads (target='dev')
2020-05-06 00:20:36.244491 (MainThread): 17:20:36 | 
2020-05-06 00:20:36.247053 (Thread-1): Began running node model.github.stg_github_issue
2020-05-06 00:20:36.247212 (Thread-1): 17:20:36 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-06 00:20:36.247549 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:20:36.247635 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-06 00:20:36.247726 (Thread-1): Compiling model.github.stg_github_issue
2020-05-06 00:20:36.253327 (Thread-2): Began running node model.github.stg_github_card
2020-05-06 00:20:36.258719 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-06 00:20:36.258865 (Thread-2): 17:20:36 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-06 00:20:36.263338 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-06 00:20:36.263438 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-06 00:20:36.263600 (Thread-3): 17:20:36 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-06 00:20:36.264099 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:20:36.264277 (Thread-4): 17:20:36 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-06 00:20:36.264633 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:20:36.264800 (Thread-2): Opening a new connection, currently in state init
2020-05-06 00:20:36.265116 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:20:36.265289 (Thread-1): finished collecting timing info
2020-05-06 00:20:36.265547 (Thread-3): Opening a new connection, currently in state init
2020-05-06 00:20:36.265655 (Thread-2): Compiling model.github.stg_github_card
2020-05-06 00:20:36.265764 (Thread-4): Opening a new connection, currently in state init
2020-05-06 00:20:36.284793 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-06 00:20:36.319628 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-06 00:20:36.319751 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-06 00:20:36.352097 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:20:36.371719 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:20:36.394055 (Thread-2): finished collecting timing info
2020-05-06 00:20:36.394596 (Thread-3): finished collecting timing info
2020-05-06 00:20:36.442301 (Thread-4): finished collecting timing info
2020-05-06 00:20:36.472788 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-06 00:20:36.504225 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-06 00:20:36.526391 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-06 00:20:36.531512 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:20:36.545280 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:20:36.546395 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-06 00:20:36.548367 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-06 00:20:36.548550 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-06 00:20:37.244640 (Thread-1): finished collecting timing info
2020-05-06 00:20:37.245668 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041cb150>]}
2020-05-06 00:20:37.246041 (Thread-1): 17:20:37 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.00s]
2020-05-06 00:20:37.246252 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-06 00:20:37.246461 (Thread-1): Began running node model.github.stg_github_user
2020-05-06 00:20:37.246849 (Thread-1): 17:20:37 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-06 00:20:37.247209 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:20:37.247331 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-06 00:20:37.247451 (Thread-1): Compiling model.github.stg_github_user
2020-05-06 00:20:37.255790 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-06 00:20:37.258087 (Thread-1): finished collecting timing info
2020-05-06 00:20:37.263248 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-06 00:20:37.264069 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-06 00:20:37.412783 (Thread-3): finished collecting timing info
2020-05-06 00:20:37.413797 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105884cd0>]}
2020-05-06 00:20:37.414156 (Thread-3): 17:20:37 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.15s]
2020-05-06 00:20:37.414369 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-06 00:20:37.414577 (Thread-3): Began running node model.github.stg_github_issue_assignee
2020-05-06 00:20:37.414785 (Thread-3): 17:20:37 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-06 00:20:37.415175 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:20:37.415315 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-06 00:20:37.415436 (Thread-3): Compiling model.github.stg_github_issue_assignee
2020-05-06 00:20:37.424543 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:20:37.425115 (Thread-3): finished collecting timing info
2020-05-06 00:20:37.429970 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:20:37.433136 (Thread-4): finished collecting timing info
2020-05-06 00:20:37.433704 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105821210>]}
2020-05-06 00:20:37.433947 (Thread-4): 17:20:37 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.17s]
2020-05-06 00:20:37.434167 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-06 00:20:37.434309 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-06 00:20:37.434473 (Thread-4): 17:20:37 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-06 00:20:37.434869 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:20:37.434974 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-06 00:20:37.435236 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-06 00:20:37.440599 (Thread-3): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-06 00:20:37.442595 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:20:37.443737 (Thread-4): finished collecting timing info
2020-05-06 00:20:37.448663 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:20:37.449704 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-06 00:20:37.525547 (Thread-2): finished collecting timing info
2020-05-06 00:20:37.526628 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043e0f90>]}
2020-05-06 00:20:37.527030 (Thread-2): 17:20:37 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.26s]
2020-05-06 00:20:37.527209 (Thread-2): Finished running node model.github.stg_github_card
2020-05-06 00:20:37.527384 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-06 00:20:37.527557 (Thread-2): 17:20:37 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-06 00:20:37.527888 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:20:37.528009 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-06 00:20:37.528130 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-06 00:20:37.536830 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:20:37.537333 (Thread-2): finished collecting timing info
2020-05-06 00:20:37.541881 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:20:37.542306 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-06 00:20:37.904686 (Thread-1): finished collecting timing info
2020-05-06 00:20:37.905709 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10436e490>]}
2020-05-06 00:20:37.906076 (Thread-1): 17:20:37 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.66s]
2020-05-06 00:20:37.906285 (Thread-1): Finished running node model.github.stg_github_user
2020-05-06 00:20:37.906575 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-06 00:20:37.906960 (Thread-1): 17:20:37 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-06 00:20:37.907382 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:20:37.907515 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-06 00:20:37.907640 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-06 00:20:37.917081 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:20:37.917514 (Thread-1): finished collecting timing info
2020-05-06 00:20:37.922056 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:20:37.922468 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-06 00:20:38.038404 (Thread-3): finished collecting timing info
2020-05-06 00:20:38.039432 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10590d890>]}
2020-05-06 00:20:38.039803 (Thread-3): 17:20:38 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.62s]
2020-05-06 00:20:38.040014 (Thread-3): Finished running node model.github.stg_github_issue_assignee
2020-05-06 00:20:38.040224 (Thread-3): Began running node model.github.stg_github_issue_merged
2020-05-06 00:20:38.040611 (Thread-3): 17:20:38 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-06 00:20:38.041170 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:20:38.041299 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-06 00:20:38.041420 (Thread-3): Compiling model.github.stg_github_issue_merged
2020-05-06 00:20:38.049992 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:20:38.050443 (Thread-3): finished collecting timing info
2020-05-06 00:20:38.054921 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:20:38.055289 (Thread-3): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-06 00:20:38.135698 (Thread-2): finished collecting timing info
2020-05-06 00:20:38.136708 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105823d10>]}
2020-05-06 00:20:38.137130 (Thread-2): 17:20:38 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.61s]
2020-05-06 00:20:38.137360 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-06 00:20:38.137571 (Thread-2): Began running node model.github.stg_github_project
2020-05-06 00:20:38.137771 (Thread-2): 17:20:38 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-06 00:20:38.138226 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:20:38.138361 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-06 00:20:38.138485 (Thread-2): Compiling model.github.stg_github_project
2020-05-06 00:20:38.147088 (Thread-2): Writing injected SQL for node "model.github.stg_github_project"
2020-05-06 00:20:38.147492 (Thread-2): finished collecting timing info
2020-05-06 00:20:38.151902 (Thread-2): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-06 00:20:38.152244 (Thread-2): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-06 00:20:38.380325 (Thread-4): finished collecting timing info
2020-05-06 00:20:38.381680 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104384ad0>]}
2020-05-06 00:20:38.381990 (Thread-4): 17:20:38 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.95s]
2020-05-06 00:20:38.382170 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-06 00:20:38.382694 (Thread-4): Began running node model.github.stg_github_pull_request
2020-05-06 00:20:38.382893 (Thread-4): 17:20:38 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-06 00:20:38.383403 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:20:38.383871 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-06 00:20:38.384021 (Thread-4): Compiling model.github.stg_github_pull_request
2020-05-06 00:20:38.392647 (Thread-4): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:20:38.394606 (Thread-4): finished collecting timing info
2020-05-06 00:20:38.399525 (Thread-4): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:20:38.400263 (Thread-4): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-06 00:20:38.518247 (Thread-1): finished collecting timing info
2020-05-06 00:20:38.519262 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058a9250>]}
2020-05-06 00:20:38.519634 (Thread-1): 17:20:38 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.61s]
2020-05-06 00:20:38.519844 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-06 00:20:38.520049 (Thread-1): Began running node model.github.stg_github_repository
2020-05-06 00:20:38.520252 (Thread-1): 17:20:38 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-06 00:20:38.520676 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:20:38.520795 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-06 00:20:38.520913 (Thread-1): Compiling model.github.stg_github_repository
2020-05-06 00:20:38.530148 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-06 00:20:38.530622 (Thread-1): finished collecting timing info
2020-05-06 00:20:38.535140 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-06 00:20:38.535477 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-06 00:20:38.670986 (Thread-3): finished collecting timing info
2020-05-06 00:20:38.672982 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043a8490>]}
2020-05-06 00:20:38.674046 (Thread-3): 17:20:38 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.63s]
2020-05-06 00:20:38.674279 (Thread-3): Finished running node model.github.stg_github_issue_merged
2020-05-06 00:20:38.674489 (Thread-3): Began running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:20:38.674699 (Thread-3): 17:20:38 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-06 00:20:38.676029 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:20:38.676297 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-06 00:20:38.676452 (Thread-3): Compiling model.github.stg_github_requested_reviewer_history
2020-05-06 00:20:38.686087 (Thread-3): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:20:38.687056 (Thread-3): finished collecting timing info
2020-05-06 00:20:38.692003 (Thread-3): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:20:38.692404 (Thread-3): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-06 00:20:39.067501 (Thread-2): finished collecting timing info
2020-05-06 00:20:39.068449 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105863050>]}
2020-05-06 00:20:39.068750 (Thread-2): 17:20:39 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.93s]
2020-05-06 00:20:39.068919 (Thread-2): Finished running node model.github.stg_github_project
2020-05-06 00:20:39.069089 (Thread-2): Began running node model.github.stg_github_milestone
2020-05-06 00:20:39.069253 (Thread-2): 17:20:39 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-06 00:20:39.069707 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:20:39.069841 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-06 00:20:39.069963 (Thread-2): Compiling model.github.stg_github_milestone
2020-05-06 00:20:39.078173 (Thread-2): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-06 00:20:39.078577 (Thread-2): finished collecting timing info
2020-05-06 00:20:39.083255 (Thread-2): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-06 00:20:39.084179 (Thread-2): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-06 00:20:39.166776 (Thread-1): finished collecting timing info
2020-05-06 00:20:39.168764 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043e0950>]}
2020-05-06 00:20:39.172347 (Thread-4): finished collecting timing info
2020-05-06 00:20:39.173197 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043e1090>]}
2020-05-06 00:20:39.173494 (Thread-4): 17:20:39 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.79s]
2020-05-06 00:20:39.173668 (Thread-4): Finished running node model.github.stg_github_pull_request
2020-05-06 00:20:39.173834 (Thread-4): Began running node model.github.stg_github_issue_comment
2020-05-06 00:20:39.174000 (Thread-4): 17:20:39 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-06 00:20:39.174276 (Thread-1): 17:20:39 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.65s]
2020-05-06 00:20:39.174734 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:20:39.174873 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-06 00:20:39.174979 (Thread-4): Compiling model.github.stg_github_issue_comment
2020-05-06 00:20:39.181478 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-06 00:20:39.181646 (Thread-1): Began running node model.github.issue_close_stack
2020-05-06 00:20:39.181782 (Thread-1): 17:20:39 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-06 00:20:39.182040 (Thread-1): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:20:39.182128 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-06 00:20:39.182215 (Thread-1): Compiling model.github.issue_close_stack
2020-05-06 00:20:39.189244 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:20:39.192111 (Thread-1): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-06 00:20:39.192540 (Thread-4): finished collecting timing info
2020-05-06 00:20:39.196810 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:20:39.197014 (Thread-1): finished collecting timing info
2020-05-06 00:20:39.201981 (Thread-1): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-06 00:20:39.202482 (Thread-4): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-06 00:20:39.203221 (Thread-1): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-06 00:20:39.374541 (Thread-3): finished collecting timing info
2020-05-06 00:20:39.375571 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10590d610>]}
2020-05-06 00:20:39.375929 (Thread-3): 17:20:39 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.70s]
2020-05-06 00:20:39.376141 (Thread-3): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:20:39.376346 (Thread-3): Began running node model.github.issue_status_windows
2020-05-06 00:20:39.376551 (Thread-3): 17:20:39 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-06 00:20:39.376942 (Thread-3): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:20:39.377086 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-06 00:20:39.377230 (Thread-3): Compiling model.github.issue_status_windows
2020-05-06 00:20:39.387287 (Thread-3): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-06 00:20:39.388246 (Thread-3): finished collecting timing info
2020-05-06 00:20:39.393264 (Thread-3): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-06 00:20:39.393689 (Thread-3): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-06 00:20:39.661160 (Thread-2): finished collecting timing info
2020-05-06 00:20:39.662246 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043fd510>]}
2020-05-06 00:20:39.662612 (Thread-2): 17:20:39 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.59s]
2020-05-06 00:20:39.662817 (Thread-2): Finished running node model.github.stg_github_milestone
2020-05-06 00:20:39.663019 (Thread-2): Began running node model.github.issue_assignees
2020-05-06 00:20:39.663223 (Thread-2): 17:20:39 | 19 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-06 00:20:39.663659 (Thread-2): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:20:39.663791 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-06 00:20:39.663911 (Thread-2): Compiling model.github.issue_assignees
2020-05-06 00:20:39.673310 (Thread-2): Writing injected SQL for node "model.github.issue_assignees"
2020-05-06 00:20:39.673731 (Thread-2): finished collecting timing info
2020-05-06 00:20:39.678435 (Thread-2): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-06 00:20:39.679631 (Thread-2): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-06 00:20:39.878728 (Thread-1): finished collecting timing info
2020-05-06 00:20:39.879733 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058a4610>]}
2020-05-06 00:20:39.880090 (Thread-1): 17:20:39 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.70s]
2020-05-06 00:20:39.880291 (Thread-1): Finished running node model.github.issue_close_stack
2020-05-06 00:20:39.880497 (Thread-1): Began running node model.github.pull_request_reviewers
2020-05-06 00:20:39.880698 (Thread-1): 17:20:39 | 20 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-06 00:20:39.881050 (Thread-1): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:20:39.881255 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-06 00:20:39.881537 (Thread-1): Compiling model.github.pull_request_reviewers
2020-05-06 00:20:39.891047 (Thread-1): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:20:39.891502 (Thread-1): finished collecting timing info
2020-05-06 00:20:39.896207 (Thread-1): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:20:39.896610 (Thread-1): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-06 00:20:40.224383 (Thread-3): finished collecting timing info
2020-05-06 00:20:40.225640 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104389f90>]}
2020-05-06 00:20:40.226017 (Thread-3): 17:20:40 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.85s]
2020-05-06 00:20:40.226225 (Thread-3): Finished running node model.github.issue_status_windows
2020-05-06 00:20:40.226432 (Thread-3): Began running node model.github.issue_labels
2020-05-06 00:20:40.226648 (Thread-3): 17:20:40 | 21 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-06 00:20:40.226972 (Thread-3): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:20:40.227093 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-06 00:20:40.227211 (Thread-3): Compiling model.github.issue_labels
2020-05-06 00:20:40.235628 (Thread-3): Writing injected SQL for node "model.github.issue_labels"
2020-05-06 00:20:40.236068 (Thread-3): finished collecting timing info
2020-05-06 00:20:40.240956 (Thread-3): Writing runtime SQL for node "model.github.issue_labels"
2020-05-06 00:20:40.242806 (Thread-3): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-06 00:20:40.295555 (Thread-4): finished collecting timing info
2020-05-06 00:20:40.296602 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058be650>]}
2020-05-06 00:20:40.296966 (Thread-4): 17:20:40 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 1.12s]
2020-05-06 00:20:40.297178 (Thread-4): Finished running node model.github.stg_github_issue_comment
2020-05-06 00:20:40.297497 (Thread-4): Began running node model.github.issue_blocked_time
2020-05-06 00:20:40.297775 (Thread-4): 17:20:40 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-06 00:20:40.298129 (Thread-4): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:20:40.298246 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-06 00:20:40.298362 (Thread-4): Compiling model.github.issue_blocked_time
2020-05-06 00:20:40.307122 (Thread-4): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-06 00:20:40.307526 (Thread-4): finished collecting timing info
2020-05-06 00:20:40.312635 (Thread-4): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-06 00:20:40.314575 (Thread-4): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-06 00:20:40.444253 (Thread-2): finished collecting timing info
2020-05-06 00:20:40.445260 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059d5e90>]}
2020-05-06 00:20:40.445614 (Thread-2): 17:20:40 | 19 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.78s]
2020-05-06 00:20:40.445817 (Thread-2): Finished running node model.github.issue_assignees
2020-05-06 00:20:40.446023 (Thread-2): Began running node model.github.pull_request_times
2020-05-06 00:20:40.446224 (Thread-2): 17:20:40 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-06 00:20:40.446837 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:20:40.446974 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-06 00:20:40.447097 (Thread-2): Compiling model.github.pull_request_times
2020-05-06 00:20:40.460525 (Thread-2): Writing injected SQL for node "model.github.pull_request_times"
2020-05-06 00:20:40.460925 (Thread-2): finished collecting timing info
2020-05-06 00:20:40.466274 (Thread-2): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-06 00:20:40.466655 (Thread-2): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-06 00:20:40.563068 (Thread-1): finished collecting timing info
2020-05-06 00:20:40.564253 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b1f50>]}
2020-05-06 00:20:40.564670 (Thread-1): 17:20:40 | 20 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.68s]
2020-05-06 00:20:40.564896 (Thread-1): Finished running node model.github.pull_request_reviewers
2020-05-06 00:20:40.565115 (Thread-1): Began running node model.github.issue_open_length
2020-05-06 00:20:40.565309 (Thread-1): 17:20:40 | 24 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-06 00:20:40.565770 (Thread-1): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:20:40.565903 (Thread-1): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-06 00:20:40.566024 (Thread-1): Compiling model.github.issue_open_length
2020-05-06 00:20:40.609053 (Thread-1): Writing injected SQL for node "model.github.issue_open_length"
2020-05-06 00:20:40.610748 (Thread-1): finished collecting timing info
2020-05-06 00:20:40.616336 (Thread-1): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-06 00:20:40.619626 (Thread-1): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-06 00:20:40.928508 (Thread-3): finished collecting timing info
2020-05-06 00:20:40.932385 (Thread-4): finished collecting timing info
2020-05-06 00:20:40.933160 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a0cc50>]}
2020-05-06 00:20:40.933787 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a01890>]}
2020-05-06 00:20:40.934098 (Thread-3): 17:20:40 | 21 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.71s]
2020-05-06 00:20:40.934344 (Thread-4): 17:20:40 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.64s]
2020-05-06 00:20:40.934522 (Thread-3): Finished running node model.github.issue_labels
2020-05-06 00:20:40.934736 (Thread-4): Finished running node model.github.issue_blocked_time
2020-05-06 00:20:40.934967 (Thread-3): Began running node model.github.issue_inbox_time
2020-05-06 00:20:40.935271 (Thread-4): Began running node model.github.issue_projects
2020-05-06 00:20:40.935508 (Thread-3): 17:20:40 | 25 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-06 00:20:40.935657 (Thread-4): 17:20:40 | 26 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-06 00:20:40.935980 (Thread-3): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:20:40.936452 (Thread-4): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:20:40.936567 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-06 00:20:40.936665 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-06 00:20:40.936769 (Thread-3): Compiling model.github.issue_inbox_time
2020-05-06 00:20:40.936866 (Thread-4): Compiling model.github.issue_projects
2020-05-06 00:20:40.944776 (Thread-3): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-06 00:20:40.953351 (Thread-4): Writing injected SQL for node "model.github.issue_projects"
2020-05-06 00:20:40.955218 (Thread-3): finished collecting timing info
2020-05-06 00:20:40.960011 (Thread-3): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-06 00:20:40.960256 (Thread-4): finished collecting timing info
2020-05-06 00:20:40.964389 (Thread-4): Writing runtime SQL for node "model.github.issue_projects"
2020-05-06 00:20:40.964928 (Thread-3): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-06 00:20:40.965101 (Thread-4): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-06 00:20:41.291375 (Thread-1): finished collecting timing info
2020-05-06 00:20:41.293463 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a1e650>]}
2020-05-06 00:20:41.294354 (Thread-1): 17:20:41 | 24 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.73s]
2020-05-06 00:20:41.294543 (Thread-1): Finished running node model.github.issue_open_length
2020-05-06 00:20:41.363504 (Thread-2): finished collecting timing info
2020-05-06 00:20:41.364641 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a31410>]}
2020-05-06 00:20:41.365018 (Thread-2): 17:20:41 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.92s]
2020-05-06 00:20:41.365229 (Thread-2): Finished running node model.github.pull_request_times
2020-05-06 00:20:41.365667 (Thread-1): Began running node model.github.github_pull_requests
2020-05-06 00:20:41.365843 (Thread-1): 17:20:41 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-06 00:20:41.366173 (Thread-1): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:20:41.366287 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-06 00:20:41.366401 (Thread-1): Compiling model.github.github_pull_requests
2020-05-06 00:20:41.382832 (Thread-1): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-06 00:20:41.384578 (Thread-1): finished collecting timing info
2020-05-06 00:20:41.389446 (Thread-1): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-06 00:20:41.389833 (Thread-1): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-06 00:20:41.595525 (Thread-4): finished collecting timing info
2020-05-06 00:20:41.596545 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043a8490>]}
2020-05-06 00:20:41.596905 (Thread-4): 17:20:41 | 26 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.66s]
2020-05-06 00:20:41.597117 (Thread-4): Finished running node model.github.issue_projects
2020-05-06 00:20:41.630963 (Thread-3): finished collecting timing info
2020-05-06 00:20:41.632148 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a01890>]}
2020-05-06 00:20:41.632579 (Thread-3): 17:20:41 | 25 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.70s]
2020-05-06 00:20:41.632796 (Thread-3): Finished running node model.github.issue_inbox_time
2020-05-06 00:20:41.633221 (Thread-2): Began running node model.github.github_issues
2020-05-06 00:20:41.633439 (Thread-2): 17:20:41 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-06 00:20:41.633838 (Thread-2): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:20:41.633955 (Thread-2): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-06 00:20:41.634074 (Thread-2): Compiling model.github.github_issues
2020-05-06 00:20:41.652599 (Thread-2): Writing injected SQL for node "model.github.github_issues"
2020-05-06 00:20:41.652997 (Thread-2): finished collecting timing info
2020-05-06 00:20:41.657808 (Thread-2): Writing runtime SQL for node "model.github.github_issues"
2020-05-06 00:20:41.658190 (Thread-2): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-06 00:20:42.397164 (Thread-1): finished collecting timing info
2020-05-06 00:20:42.398218 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a1e650>]}
2020-05-06 00:20:42.398588 (Thread-1): 17:20:42 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 1.03s]
2020-05-06 00:20:42.398809 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-06 00:20:42.616816 (Thread-2): finished collecting timing info
2020-05-06 00:20:42.617584 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042ce850>]}
2020-05-06 00:20:42.617851 (Thread-2): 17:20:42 | 28 of 29 OK created view model dbt_erik.github_issues................ [CREATE VIEW in 0.98s]
2020-05-06 00:20:42.618014 (Thread-2): Finished running node model.github.github_issues
2020-05-06 00:20:42.618363 (Thread-3): Began running node model.github.issues_and_prs_per_month
2020-05-06 00:20:42.618550 (Thread-3): 17:20:42 | 29 of 29 START view model dbt_erik.issues_and_prs_per_month.......... [RUN]
2020-05-06 00:20:42.618855 (Thread-3): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:20:42.618953 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_inbox_time).
2020-05-06 00:20:42.619054 (Thread-3): Compiling model.github.issues_and_prs_per_month
2020-05-06 00:20:42.628245 (Thread-3): Writing injected SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:20:42.629436 (Thread-3): finished collecting timing info
2020-05-06 00:20:42.635364 (Thread-3): Writing runtime SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:20:42.635872 (Thread-3): On model.github.issues_and_prs_per_month: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month.month 
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month.month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-06 00:20:42.997539 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month.month 
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month.month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-06 00:20:42.997822 (Thread-3): 404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US

(job ID: 5bb40f30-b1fa-441a-ba6b-dbd78b49db50)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month.month 
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month.month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:20:42.998123 (Thread-3): finished collecting timing info
2020-05-06 00:20:42.998822 (Thread-3): Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US
  
  (job ID: 5bb40f30-b1fa-441a-ba6b-dbd78b49db50)
  
                                                              -----Query Job SQL Follows-----                                                             
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
     2:
     3:
     4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
     5:  OPTIONS()
     6:  as (
     7:    with github_issues as (
     8:
     9:    select *
    10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
    11:
    12:), pull_requests as (
    13:
    14:    select *
    15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
    16:
    17:), issues_opened_per_month as (
    18:
    19:   select 
    20:      date_trunc(date(created_at), month) as month, 
    21:      count(*) as number_issues_opened,
    22:      avg(days_issue_opened) as average_length_issue_open,
    23:      max(days_issue_opened) as longest_length_issue_open
    24:    from github_issues
    25:    group by 1
    26:
    27:), issues_closed_per_month as (
    28:
    29:   select 
    30:      date_trunc(date(closed_at), month) as month, 
    31:      count(*) as number_issues_closed
    32:    from github_issues
    33:    where closed_at is not null
    34:    group by 1
    35:
    36:), prs_opened_per_month as (
    37:
    38:   select 
    39:      date_trunc(date(created_at), month) as month, 
    40:      count(*) as number_prs_opened,
    41:      avg(days_issue_opened) as average_length_pr_open,
    42:      max(days_issue_opened) as longest_length_pr_open
    43:    from pull_requests
    44:    group by 1
    45:
    46:), prs_merged_per_month as (
    47:
    48:   select 
    49:      date_trunc(date(merged_at), month) as month, 
    50:      count(*) as number_prs_merged
    51:    from github_issues
    52:    group by 1
    53:
    54:), issues_per_month as (
    55:
    56:    select 
    57:      coalesce(issues_opened_per_month.month, 
    58:        issues_closed_per_month.month
    59:      ) as month,
    60:      number_issues_opened,
    61:      number_issues_closed,      
    62:      average_length_issue_open,
    63:      longest_length_issue_open
    64:    from issues_opened_per_month
    65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
    66:
    67:), prs_per_month as (
    68:
    69:    select 
    70:      coalesce(prs_opened_per_month.month, 
    71:        prs_merged_per_month.month
    72:      ) as month,
    73:      number_prs_opened,
    74:      number_prs_merged,
    75:      average_length_pr_open,
    76:      longest_length_pr_open
    77:    from prs_opened_per_month.month 
    78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    79:
    80:)
    81:
    82:select 
    83:  coalesce(issues_per_month.month, 
    84:    prs_per_month.month
    85:  ) as month,
    86:  coalesce(number_issues_opened, 0) as number_issues_opened,
    87:  coalesce(number_issues_closed, 0) as number_issues_closed,
    88:  average_length_issue_open,
    89:  longest_length_issue_open,
    90:  coalesce(number_prs_opened, 0) as number_prs_opened,
    91:  coalesce(number_prs_merged, 0) as number_prs_merged,
    92:  average_length_pr_open,
    93:  longest_length_pr_open
    94:from prs_opened_per_month.month 
    95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    96:  );
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US

(job ID: 5bb40f30-b1fa-441a-ba6b-dbd78b49db50)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month.month 
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month.month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US
  
  (job ID: 5bb40f30-b1fa-441a-ba6b-dbd78b49db50)
  
                                                              -----Query Job SQL Follows-----                                                             
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
     2:
     3:
     4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
     5:  OPTIONS()
     6:  as (
     7:    with github_issues as (
     8:
     9:    select *
    10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
    11:
    12:), pull_requests as (
    13:
    14:    select *
    15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
    16:
    17:), issues_opened_per_month as (
    18:
    19:   select 
    20:      date_trunc(date(created_at), month) as month, 
    21:      count(*) as number_issues_opened,
    22:      avg(days_issue_opened) as average_length_issue_open,
    23:      max(days_issue_opened) as longest_length_issue_open
    24:    from github_issues
    25:    group by 1
    26:
    27:), issues_closed_per_month as (
    28:
    29:   select 
    30:      date_trunc(date(closed_at), month) as month, 
    31:      count(*) as number_issues_closed
    32:    from github_issues
    33:    where closed_at is not null
    34:    group by 1
    35:
    36:), prs_opened_per_month as (
    37:
    38:   select 
    39:      date_trunc(date(created_at), month) as month, 
    40:      count(*) as number_prs_opened,
    41:      avg(days_issue_opened) as average_length_pr_open,
    42:      max(days_issue_opened) as longest_length_pr_open
    43:    from pull_requests
    44:    group by 1
    45:
    46:), prs_merged_per_month as (
    47:
    48:   select 
    49:      date_trunc(date(merged_at), month) as month, 
    50:      count(*) as number_prs_merged
    51:    from github_issues
    52:    group by 1
    53:
    54:), issues_per_month as (
    55:
    56:    select 
    57:      coalesce(issues_opened_per_month.month, 
    58:        issues_closed_per_month.month
    59:      ) as month,
    60:      number_issues_opened,
    61:      number_issues_closed,      
    62:      average_length_issue_open,
    63:      longest_length_issue_open
    64:    from issues_opened_per_month
    65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
    66:
    67:), prs_per_month as (
    68:
    69:    select 
    70:      coalesce(prs_opened_per_month.month, 
    71:        prs_merged_per_month.month
    72:      ) as month,
    73:      number_prs_opened,
    74:      number_prs_merged,
    75:      average_length_pr_open,
    76:      longest_length_pr_open
    77:    from prs_opened_per_month.month 
    78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    79:
    80:)
    81:
    82:select 
    83:  coalesce(issues_per_month.month, 
    84:    prs_per_month.month
    85:  ) as month,
    86:  coalesce(number_issues_opened, 0) as number_issues_opened,
    87:  coalesce(number_issues_closed, 0) as number_issues_closed,
    88:  average_length_issue_open,
    89:  longest_length_issue_open,
    90:  coalesce(number_prs_opened, 0) as number_prs_opened,
    91:  coalesce(number_prs_merged, 0) as number_prs_merged,
    92:  average_length_pr_open,
    93:  longest_length_pr_open
    94:from prs_opened_per_month.month 
    95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    96:  );
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:20:43.008711 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bff0c76f-4c33-4be2-a612-915bbedd12de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058b1f10>]}
2020-05-06 00:20:43.664174 (Thread-3): 17:20:43 | 29 of 29 ERROR creating view model dbt_erik.issues_and_prs_per_month. [ERROR in 0.39s]
2020-05-06 00:20:43.664459 (Thread-3): Finished running node model.github.issues_and_prs_per_month
2020-05-06 00:20:43.680910 (MainThread): 17:20:43 | 
2020-05-06 00:20:43.681381 (MainThread): 17:20:43 | Finished running 29 view models in 8.64s.
2020-05-06 00:20:43.681711 (MainThread): Connection 'master' was left open.
2020-05-06 00:20:43.681875 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-06 00:20:43.682029 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-06 00:20:43.682177 (MainThread): Connection 'model.github.issues_and_prs_per_month' was left open.
2020-05-06 00:20:43.682322 (MainThread): Connection 'model.github.issue_projects' was left open.
2020-05-06 00:20:43.752648 (MainThread): 
2020-05-06 00:20:43.752806 (MainThread): Completed with 1 error and 0 warnings:
2020-05-06 00:20:43.752980 (MainThread): 
2020-05-06 00:20:43.753121 (MainThread): Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
2020-05-06 00:20:43.753336 (MainThread):   404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US
2020-05-06 00:20:43.753483 (MainThread):   
2020-05-06 00:20:43.753641 (MainThread):   (job ID: 5bb40f30-b1fa-441a-ba6b-dbd78b49db50)
2020-05-06 00:20:43.753738 (MainThread):   
2020-05-06 00:20:43.753851 (MainThread):                                                               -----Query Job SQL Follows-----                                                             
2020-05-06 00:20:43.753933 (MainThread):   
2020-05-06 00:20:43.754052 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:20:43.754155 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
2020-05-06 00:20:43.754283 (MainThread):      2:
2020-05-06 00:20:43.754554 (MainThread):      3:
2020-05-06 00:20:43.754689 (MainThread):      4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
2020-05-06 00:20:43.754793 (MainThread):      5:  OPTIONS()
2020-05-06 00:20:43.754891 (MainThread):      6:  as (
2020-05-06 00:20:43.754970 (MainThread):      7:    with github_issues as (
2020-05-06 00:20:43.755047 (MainThread):      8:
2020-05-06 00:20:43.755123 (MainThread):      9:    select *
2020-05-06 00:20:43.755197 (MainThread):     10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
2020-05-06 00:20:43.755273 (MainThread):     11:
2020-05-06 00:20:43.755347 (MainThread):     12:), pull_requests as (
2020-05-06 00:20:43.755422 (MainThread):     13:
2020-05-06 00:20:43.755496 (MainThread):     14:    select *
2020-05-06 00:20:43.755571 (MainThread):     15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
2020-05-06 00:20:43.755728 (MainThread):     16:
2020-05-06 00:20:43.755881 (MainThread):     17:), issues_opened_per_month as (
2020-05-06 00:20:43.755989 (MainThread):     18:
2020-05-06 00:20:43.756072 (MainThread):     19:   select 
2020-05-06 00:20:43.756152 (MainThread):     20:      date_trunc(date(created_at), month) as month, 
2020-05-06 00:20:43.756229 (MainThread):     21:      count(*) as number_issues_opened,
2020-05-06 00:20:43.756306 (MainThread):     22:      avg(days_issue_opened) as average_length_issue_open,
2020-05-06 00:20:43.756383 (MainThread):     23:      max(days_issue_opened) as longest_length_issue_open
2020-05-06 00:20:43.756489 (MainThread):     24:    from github_issues
2020-05-06 00:20:43.756645 (MainThread):     25:    group by 1
2020-05-06 00:20:43.756768 (MainThread):     26:
2020-05-06 00:20:43.756883 (MainThread):     27:), issues_closed_per_month as (
2020-05-06 00:20:43.756982 (MainThread):     28:
2020-05-06 00:20:43.757065 (MainThread):     29:   select 
2020-05-06 00:20:43.757253 (MainThread):     30:      date_trunc(date(closed_at), month) as month, 
2020-05-06 00:20:43.757398 (MainThread):     31:      count(*) as number_issues_closed
2020-05-06 00:20:43.757495 (MainThread):     32:    from github_issues
2020-05-06 00:20:43.757581 (MainThread):     33:    where closed_at is not null
2020-05-06 00:20:43.757665 (MainThread):     34:    group by 1
2020-05-06 00:20:43.757745 (MainThread):     35:
2020-05-06 00:20:43.757824 (MainThread):     36:), prs_opened_per_month as (
2020-05-06 00:20:43.757906 (MainThread):     37:
2020-05-06 00:20:43.757984 (MainThread):     38:   select 
2020-05-06 00:20:43.758062 (MainThread):     39:      date_trunc(date(created_at), month) as month, 
2020-05-06 00:20:43.758141 (MainThread):     40:      count(*) as number_prs_opened,
2020-05-06 00:20:43.758218 (MainThread):     41:      avg(days_issue_opened) as average_length_pr_open,
2020-05-06 00:20:43.758296 (MainThread):     42:      max(days_issue_opened) as longest_length_pr_open
2020-05-06 00:20:43.758473 (MainThread):     43:    from pull_requests
2020-05-06 00:20:43.758557 (MainThread):     44:    group by 1
2020-05-06 00:20:43.758636 (MainThread):     45:
2020-05-06 00:20:43.758713 (MainThread):     46:), prs_merged_per_month as (
2020-05-06 00:20:43.758789 (MainThread):     47:
2020-05-06 00:20:43.758864 (MainThread):     48:   select 
2020-05-06 00:20:43.758939 (MainThread):     49:      date_trunc(date(merged_at), month) as month, 
2020-05-06 00:20:43.759015 (MainThread):     50:      count(*) as number_prs_merged
2020-05-06 00:20:43.759089 (MainThread):     51:    from github_issues
2020-05-06 00:20:43.759166 (MainThread):     52:    group by 1
2020-05-06 00:20:43.759241 (MainThread):     53:
2020-05-06 00:20:43.759315 (MainThread):     54:), issues_per_month as (
2020-05-06 00:20:43.759389 (MainThread):     55:
2020-05-06 00:20:43.759462 (MainThread):     56:    select 
2020-05-06 00:20:43.759536 (MainThread):     57:      coalesce(issues_opened_per_month.month, 
2020-05-06 00:20:43.759609 (MainThread):     58:        issues_closed_per_month.month
2020-05-06 00:20:43.759683 (MainThread):     59:      ) as month,
2020-05-06 00:20:43.759756 (MainThread):     60:      number_issues_opened,
2020-05-06 00:20:43.759829 (MainThread):     61:      number_issues_closed,      
2020-05-06 00:20:43.759903 (MainThread):     62:      average_length_issue_open,
2020-05-06 00:20:43.759976 (MainThread):     63:      longest_length_issue_open
2020-05-06 00:20:43.760049 (MainThread):     64:    from issues_opened_per_month
2020-05-06 00:20:43.760122 (MainThread):     65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
2020-05-06 00:20:43.760242 (MainThread):     66:
2020-05-06 00:20:43.760317 (MainThread):     67:), prs_per_month as (
2020-05-06 00:20:43.760390 (MainThread):     68:
2020-05-06 00:20:43.760463 (MainThread):     69:    select 
2020-05-06 00:20:43.760536 (MainThread):     70:      coalesce(prs_opened_per_month.month, 
2020-05-06 00:20:43.760609 (MainThread):     71:        prs_merged_per_month.month
2020-05-06 00:20:43.760682 (MainThread):     72:      ) as month,
2020-05-06 00:20:43.760755 (MainThread):     73:      number_prs_opened,
2020-05-06 00:20:43.760828 (MainThread):     74:      number_prs_merged,
2020-05-06 00:20:43.760900 (MainThread):     75:      average_length_pr_open,
2020-05-06 00:20:43.760973 (MainThread):     76:      longest_length_pr_open
2020-05-06 00:20:43.761046 (MainThread):     77:    from prs_opened_per_month.month 
2020-05-06 00:20:43.761119 (MainThread):     78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
2020-05-06 00:20:43.761193 (MainThread):     79:
2020-05-06 00:20:43.761266 (MainThread):     80:)
2020-05-06 00:20:43.761339 (MainThread):     81:
2020-05-06 00:20:43.761411 (MainThread):     82:select 
2020-05-06 00:20:43.761484 (MainThread):     83:  coalesce(issues_per_month.month, 
2020-05-06 00:20:43.761556 (MainThread):     84:    prs_per_month.month
2020-05-06 00:20:43.761629 (MainThread):     85:  ) as month,
2020-05-06 00:20:43.761702 (MainThread):     86:  coalesce(number_issues_opened, 0) as number_issues_opened,
2020-05-06 00:20:43.761776 (MainThread):     87:  coalesce(number_issues_closed, 0) as number_issues_closed,
2020-05-06 00:20:43.761848 (MainThread):     88:  average_length_issue_open,
2020-05-06 00:20:43.761921 (MainThread):     89:  longest_length_issue_open,
2020-05-06 00:20:43.761992 (MainThread):     90:  coalesce(number_prs_opened, 0) as number_prs_opened,
2020-05-06 00:20:43.762065 (MainThread):     91:  coalesce(number_prs_merged, 0) as number_prs_merged,
2020-05-06 00:20:43.762137 (MainThread):     92:  average_length_pr_open,
2020-05-06 00:20:43.762210 (MainThread):     93:  longest_length_pr_open
2020-05-06 00:20:43.762282 (MainThread):     94:from prs_opened_per_month.month 
2020-05-06 00:20:43.762355 (MainThread):     95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
2020-05-06 00:20:43.762428 (MainThread):     96:  );
2020-05-06 00:20:43.762501 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:20:43.762610 (MainThread): 
Done. PASS=28 WARN=0 ERROR=1 SKIP=0 TOTAL=29
2020-05-06 00:20:43.762771 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041ba1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105988690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10433b090>]}
2020-05-06 00:20:43.762946 (MainThread): Flushing usage events
2020-05-06 00:23:36.254332 (MainThread): Running with dbt=0.16.1
2020-05-06 00:23:36.444049 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-06 00:23:36.445804 (MainThread): Tracking: tracking
2020-05-06 00:23:36.454317 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106fd050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106fd910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101ca7d0>]}
2020-05-06 00:23:36.476521 (MainThread): Partial parsing not enabled
2020-05-06 00:23:36.478761 (MainThread): Parsing macros/core.sql
2020-05-06 00:23:36.483953 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-06 00:23:36.493221 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-06 00:23:36.495816 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-06 00:23:36.515531 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-06 00:23:36.552554 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-06 00:23:36.576575 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-06 00:23:36.579330 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-06 00:23:36.586898 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-06 00:23:36.600982 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-06 00:23:36.609160 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-06 00:23:36.616098 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-06 00:23:36.622555 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-06 00:23:36.624186 (MainThread): Parsing macros/etc/query.sql
2020-05-06 00:23:36.625896 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-06 00:23:36.628020 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-06 00:23:36.630520 (MainThread): Parsing macros/etc/datetime.sql
2020-05-06 00:23:36.641176 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-06 00:23:36.643570 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-06 00:23:36.644887 (MainThread): Parsing macros/adapters/common.sql
2020-05-06 00:23:36.690571 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-06 00:23:36.692040 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-06 00:23:36.693227 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-06 00:23:36.694529 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-06 00:23:36.697226 (MainThread): Parsing macros/etc.sql
2020-05-06 00:23:36.698156 (MainThread): Parsing macros/catalog.sql
2020-05-06 00:23:36.706049 (MainThread): Parsing macros/adapters.sql
2020-05-06 00:23:36.729740 (MainThread): Parsing macros/materializations/seed.sql
2020-05-06 00:23:36.732919 (MainThread): Parsing macros/materializations/view.sql
2020-05-06 00:23:36.735292 (MainThread): Parsing macros/materializations/table.sql
2020-05-06 00:23:36.747111 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-06 00:23:36.762629 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-06 00:23:36.784046 (MainThread): Partial parsing not enabled
2020-05-06 00:23:36.825577 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:23:36.825727 (MainThread): Opening a new connection, currently in state init
2020-05-06 00:23:36.849418 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:23:36.849548 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.857648 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:23:36.857787 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.873067 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:23:36.873210 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.881679 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:23:36.881846 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.889964 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:23:36.890088 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.897506 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:23:36.897644 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.904071 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:23:36.904206 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.912572 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:23:36.912713 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.920120 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:23:36.920257 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.927778 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:23:36.927919 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.936067 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:23:36.936236 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.945241 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:23:36.945407 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.956515 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:23:36.956656 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.963812 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:23:36.963951 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.970421 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:23:36.970654 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.978192 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:23:36.978361 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.986279 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:23:36.986424 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:36.993299 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:23:36.993441 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.000165 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:23:37.000302 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.007628 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:23:37.007773 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.013859 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:23:37.013975 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.020888 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:23:37.021053 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.028393 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:23:37.028531 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.034599 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:23:37.034702 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.041558 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:23:37.041690 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.048111 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:23:37.048234 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.054461 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:23:37.054603 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.061145 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:23:37.061283 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.201269 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-06 00:23:37.452616 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-06 00:23:37.470096 (MainThread): 
2020-05-06 00:23:37.470496 (MainThread): Acquiring new bigquery connection "master".
2020-05-06 00:23:37.470587 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:23:37.526796 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-06 00:23:37.527021 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-06 00:23:38.334775 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-06 00:23:38.335169 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-06 00:23:38.335489 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-06 00:23:38.515104 (MainThread): 17:23:38 | Concurrency: 4 threads (target='dev')
2020-05-06 00:23:38.515277 (MainThread): 17:23:38 | 
2020-05-06 00:23:38.518400 (Thread-1): Began running node model.github.stg_github_issue
2020-05-06 00:23:38.518614 (Thread-2): Began running node model.github.stg_github_card
2020-05-06 00:23:38.518761 (Thread-1): 17:23:38 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-06 00:23:38.518850 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-06 00:23:38.519141 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-06 00:23:38.519269 (Thread-2): 17:23:38 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-06 00:23:38.519573 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:23:38.519706 (Thread-3): 17:23:38 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-06 00:23:38.519857 (Thread-4): 17:23:38 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-06 00:23:38.520141 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:23:38.520243 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-06 00:23:38.520560 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:23:38.520823 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:23:38.520902 (Thread-2): Opening a new connection, currently in state init
2020-05-06 00:23:38.521032 (Thread-1): Compiling model.github.stg_github_issue
2020-05-06 00:23:38.521139 (Thread-3): Opening a new connection, currently in state init
2020-05-06 00:23:38.521242 (Thread-4): Opening a new connection, currently in state init
2020-05-06 00:23:38.521377 (Thread-2): Compiling model.github.stg_github_card
2020-05-06 00:23:38.532927 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-06 00:23:38.535597 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-06 00:23:38.535741 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-06 00:23:38.542546 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-06 00:23:38.548892 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:23:38.555815 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:23:38.556362 (Thread-1): finished collecting timing info
2020-05-06 00:23:38.568355 (Thread-2): finished collecting timing info
2020-05-06 00:23:38.598380 (Thread-3): finished collecting timing info
2020-05-06 00:23:38.610959 (Thread-4): finished collecting timing info
2020-05-06 00:23:39.028703 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-06 00:23:39.032767 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:23:39.041435 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-06 00:23:39.041994 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:23:39.043176 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-06 00:23:39.043851 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-06 00:23:39.044542 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-06 00:23:39.046822 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-06 00:23:39.741970 (Thread-1): finished collecting timing info
2020-05-06 00:23:39.742889 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dc7fd0>]}
2020-05-06 00:23:39.743200 (Thread-1): 17:23:39 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.22s]
2020-05-06 00:23:39.743374 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-06 00:23:39.743545 (Thread-1): Began running node model.github.stg_github_user
2020-05-06 00:23:39.743715 (Thread-1): 17:23:39 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-06 00:23:39.744044 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:23:39.744166 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-06 00:23:39.744289 (Thread-1): Compiling model.github.stg_github_user
2020-05-06 00:23:39.753056 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-06 00:23:39.753457 (Thread-1): finished collecting timing info
2020-05-06 00:23:39.758530 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-06 00:23:39.758952 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-06 00:23:39.847409 (Thread-4): finished collecting timing info
2020-05-06 00:23:39.848454 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109aa650>]}
2020-05-06 00:23:39.848827 (Thread-4): 17:23:39 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.33s]
2020-05-06 00:23:39.849034 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-06 00:23:39.849238 (Thread-4): Began running node model.github.stg_github_issue_assignee
2020-05-06 00:23:39.849444 (Thread-4): 17:23:39 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-06 00:23:39.849767 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:23:39.849887 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-06 00:23:39.850007 (Thread-4): Compiling model.github.stg_github_issue_assignee
2020-05-06 00:23:39.858688 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:23:39.862545 (Thread-2): finished collecting timing info
2020-05-06 00:23:39.863276 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109aa810>]}
2020-05-06 00:23:39.863511 (Thread-2): 17:23:39 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.34s]
2020-05-06 00:23:39.863658 (Thread-4): finished collecting timing info
2020-05-06 00:23:39.868508 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:23:39.868759 (Thread-2): Finished running node model.github.stg_github_card
2020-05-06 00:23:39.868917 (Thread-2): Began running node model.github.stg_github_issue_label
2020-05-06 00:23:39.869057 (Thread-2): 17:23:39 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-06 00:23:39.869353 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:23:39.869441 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-06 00:23:39.869526 (Thread-2): Compiling model.github.stg_github_issue_label
2020-05-06 00:23:39.877096 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:23:39.877572 (Thread-4): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-06 00:23:39.877952 (Thread-2): finished collecting timing info
2020-05-06 00:23:39.882103 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:23:39.883344 (Thread-2): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-06 00:23:39.891851 (Thread-3): finished collecting timing info
2020-05-06 00:23:39.892483 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11094b790>]}
2020-05-06 00:23:39.892705 (Thread-3): 17:23:39 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.37s]
2020-05-06 00:23:39.892832 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-06 00:23:39.892958 (Thread-3): Began running node model.github.stg_github_pull_request_review
2020-05-06 00:23:39.893267 (Thread-3): 17:23:39 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-06 00:23:39.893516 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:23:39.893602 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-06 00:23:39.893686 (Thread-3): Compiling model.github.stg_github_pull_request_review
2020-05-06 00:23:39.900289 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:23:39.900636 (Thread-3): finished collecting timing info
2020-05-06 00:23:39.905416 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:23:39.905848 (Thread-3): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-06 00:23:40.379880 (Thread-1): finished collecting timing info
2020-05-06 00:23:40.380915 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ee0090>]}
2020-05-06 00:23:40.381349 (Thread-1): 17:23:40 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.64s]
2020-05-06 00:23:40.381584 (Thread-1): Finished running node model.github.stg_github_user
2020-05-06 00:23:40.381755 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-06 00:23:40.381930 (Thread-1): 17:23:40 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-06 00:23:40.382260 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:23:40.382383 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-06 00:23:40.382503 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-06 00:23:40.390973 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:23:40.391388 (Thread-1): finished collecting timing info
2020-05-06 00:23:40.395934 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:23:40.396325 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-06 00:23:40.528481 (Thread-2): finished collecting timing info
2020-05-06 00:23:40.529331 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ddcf90>]}
2020-05-06 00:23:40.529641 (Thread-2): 17:23:40 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.66s]
2020-05-06 00:23:40.529817 (Thread-2): Finished running node model.github.stg_github_issue_label
2020-05-06 00:23:40.530049 (Thread-2): Began running node model.github.stg_github_issue_merged
2020-05-06 00:23:40.530385 (Thread-2): 17:23:40 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-06 00:23:40.530896 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:23:40.531030 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-06 00:23:40.531154 (Thread-2): Compiling model.github.stg_github_issue_merged
2020-05-06 00:23:40.540517 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:23:40.540943 (Thread-2): finished collecting timing info
2020-05-06 00:23:40.545465 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:23:40.545868 (Thread-2): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-06 00:23:40.838607 (Thread-3): finished collecting timing info
2020-05-06 00:23:40.839737 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111eaffd0>]}
2020-05-06 00:23:40.840130 (Thread-3): 17:23:40 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.95s]
2020-05-06 00:23:40.840341 (Thread-3): Finished running node model.github.stg_github_pull_request_review
2020-05-06 00:23:40.840541 (Thread-3): Began running node model.github.stg_github_project
2020-05-06 00:23:40.840713 (Thread-3): 17:23:40 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-06 00:23:40.841184 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:23:40.841459 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-06 00:23:40.841612 (Thread-3): Compiling model.github.stg_github_project
2020-05-06 00:23:40.850038 (Thread-3): Writing injected SQL for node "model.github.stg_github_project"
2020-05-06 00:23:40.850416 (Thread-3): finished collecting timing info
2020-05-06 00:23:40.855027 (Thread-3): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-06 00:23:40.856833 (Thread-3): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-06 00:23:40.933010 (Thread-4): finished collecting timing info
2020-05-06 00:23:40.934042 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11094b6d0>]}
2020-05-06 00:23:40.934414 (Thread-4): 17:23:40 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 1.08s]
2020-05-06 00:23:40.934624 (Thread-4): Finished running node model.github.stg_github_issue_assignee
2020-05-06 00:23:40.934833 (Thread-4): Began running node model.github.stg_github_pull_request
2020-05-06 00:23:40.935042 (Thread-4): 17:23:40 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-06 00:23:40.935454 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:23:40.935578 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-06 00:23:40.935699 (Thread-4): Compiling model.github.stg_github_pull_request
2020-05-06 00:23:40.944752 (Thread-4): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:23:40.945309 (Thread-4): finished collecting timing info
2020-05-06 00:23:40.949836 (Thread-4): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:23:40.950284 (Thread-4): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-06 00:23:40.985689 (Thread-1): finished collecting timing info
2020-05-06 00:23:40.986708 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110736950>]}
2020-05-06 00:23:40.987074 (Thread-1): 17:23:40 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.60s]
2020-05-06 00:23:40.987273 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-06 00:23:40.987442 (Thread-1): Began running node model.github.stg_github_repository
2020-05-06 00:23:40.987613 (Thread-1): 17:23:40 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-06 00:23:40.988083 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:23:40.988357 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-06 00:23:40.988511 (Thread-1): Compiling model.github.stg_github_repository
2020-05-06 00:23:40.996783 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-06 00:23:40.997164 (Thread-1): finished collecting timing info
2020-05-06 00:23:41.001718 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-06 00:23:41.002062 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-06 00:23:41.145119 (Thread-2): finished collecting timing info
2020-05-06 00:23:41.146153 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f5f9d0>]}
2020-05-06 00:23:41.146519 (Thread-2): 17:23:41 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.62s]
2020-05-06 00:23:41.146936 (Thread-2): Finished running node model.github.stg_github_issue_merged
2020-05-06 00:23:41.147179 (Thread-2): Began running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:23:41.147362 (Thread-2): 17:23:41 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-06 00:23:41.147702 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:23:41.147824 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-06 00:23:41.147945 (Thread-2): Compiling model.github.stg_github_requested_reviewer_history
2020-05-06 00:23:41.156769 (Thread-2): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:23:41.157169 (Thread-2): finished collecting timing info
2020-05-06 00:23:41.161733 (Thread-2): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:23:41.162103 (Thread-2): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-06 00:23:41.436911 (Thread-3): finished collecting timing info
2020-05-06 00:23:41.438612 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dd2bd0>]}
2020-05-06 00:23:41.439979 (Thread-3): 17:23:41 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.60s]
2020-05-06 00:23:41.440396 (Thread-3): Finished running node model.github.stg_github_project
2020-05-06 00:23:41.440769 (Thread-3): Began running node model.github.stg_github_milestone
2020-05-06 00:23:41.441404 (Thread-3): 17:23:41 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-06 00:23:41.441834 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:23:41.441967 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-06 00:23:41.442096 (Thread-3): Compiling model.github.stg_github_milestone
2020-05-06 00:23:41.451727 (Thread-3): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-06 00:23:41.452541 (Thread-3): finished collecting timing info
2020-05-06 00:23:41.457027 (Thread-3): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-06 00:23:41.457374 (Thread-3): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-06 00:23:41.515157 (Thread-4): finished collecting timing info
2020-05-06 00:23:41.516056 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ece190>]}
2020-05-06 00:23:41.516379 (Thread-4): 17:23:41 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.58s]
2020-05-06 00:23:41.516561 (Thread-4): Finished running node model.github.stg_github_pull_request
2020-05-06 00:23:41.516733 (Thread-4): Began running node model.github.stg_github_issue_comment
2020-05-06 00:23:41.516906 (Thread-4): 17:23:41 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-06 00:23:41.517234 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:23:41.517356 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-06 00:23:41.517476 (Thread-4): Compiling model.github.stg_github_issue_comment
2020-05-06 00:23:41.525509 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:23:41.525893 (Thread-4): finished collecting timing info
2020-05-06 00:23:41.530832 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:23:41.531431 (Thread-4): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-06 00:23:41.702568 (Thread-1): finished collecting timing info
2020-05-06 00:23:41.703597 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e0bf50>]}
2020-05-06 00:23:41.703970 (Thread-1): 17:23:41 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.72s]
2020-05-06 00:23:41.704176 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-06 00:23:41.704519 (Thread-1): Began running node model.github.issue_status_windows
2020-05-06 00:23:41.704892 (Thread-1): 17:23:41 | 17 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-06 00:23:41.705274 (Thread-1): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:23:41.705399 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-06 00:23:41.705521 (Thread-1): Compiling model.github.issue_status_windows
2020-05-06 00:23:41.715433 (Thread-1): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-06 00:23:41.719207 (Thread-2): finished collecting timing info
2020-05-06 00:23:41.719910 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111eaf8d0>]}
2020-05-06 00:23:41.720156 (Thread-2): 17:23:41 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.57s]
2020-05-06 00:23:41.720294 (Thread-2): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:23:41.720505 (Thread-2): Began running node model.github.issue_close_stack
2020-05-06 00:23:41.720667 (Thread-2): 17:23:41 | 18 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-06 00:23:41.721038 (Thread-2): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:23:41.721148 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-06 00:23:41.721248 (Thread-2): Compiling model.github.issue_close_stack
2020-05-06 00:23:41.729435 (Thread-2): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-06 00:23:41.729606 (Thread-1): finished collecting timing info
2020-05-06 00:23:41.734077 (Thread-1): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-06 00:23:41.734437 (Thread-1): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-06 00:23:41.734567 (Thread-2): finished collecting timing info
2020-05-06 00:23:41.740291 (Thread-2): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-06 00:23:41.740877 (Thread-2): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-06 00:23:42.202355 (Thread-4): finished collecting timing info
2020-05-06 00:23:42.203400 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f5f910>]}
2020-05-06 00:23:42.203764 (Thread-4): 17:23:42 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.69s]
2020-05-06 00:23:42.203970 (Thread-4): Finished running node model.github.stg_github_issue_comment
2020-05-06 00:23:42.204261 (Thread-4): Began running node model.github.issue_labels
2020-05-06 00:23:42.204640 (Thread-4): 17:23:42 | 19 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-06 00:23:42.204996 (Thread-4): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:23:42.205119 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-06 00:23:42.205245 (Thread-4): Compiling model.github.issue_labels
2020-05-06 00:23:42.213754 (Thread-4): Writing injected SQL for node "model.github.issue_labels"
2020-05-06 00:23:42.214235 (Thread-4): finished collecting timing info
2020-05-06 00:23:42.218917 (Thread-4): Writing runtime SQL for node "model.github.issue_labels"
2020-05-06 00:23:42.219301 (Thread-4): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-06 00:23:42.269780 (Thread-3): finished collecting timing info
2020-05-06 00:23:42.270811 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f0afd0>]}
2020-05-06 00:23:42.271178 (Thread-3): 17:23:42 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.83s]
2020-05-06 00:23:42.271386 (Thread-3): Finished running node model.github.stg_github_milestone
2020-05-06 00:23:42.271592 (Thread-3): Began running node model.github.pull_request_reviewers
2020-05-06 00:23:42.271798 (Thread-3): 17:23:42 | 20 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-06 00:23:42.272278 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:23:42.272430 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-06 00:23:42.272557 (Thread-3): Compiling model.github.pull_request_reviewers
2020-05-06 00:23:42.283551 (Thread-3): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:23:42.284010 (Thread-3): finished collecting timing info
2020-05-06 00:23:42.322597 (Thread-3): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:23:42.323171 (Thread-3): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-06 00:23:42.610867 (Thread-1): finished collecting timing info
2020-05-06 00:23:42.611902 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fa0d10>]}
2020-05-06 00:23:42.612264 (Thread-1): 17:23:42 | 17 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.91s]
2020-05-06 00:23:42.612470 (Thread-1): Finished running node model.github.issue_status_windows
2020-05-06 00:23:42.612679 (Thread-1): Began running node model.github.issue_assignees
2020-05-06 00:23:42.612892 (Thread-1): 17:23:42 | 21 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-06 00:23:42.613289 (Thread-1): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:23:42.613438 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-06 00:23:42.613584 (Thread-1): Compiling model.github.issue_assignees
2020-05-06 00:23:42.623200 (Thread-1): Writing injected SQL for node "model.github.issue_assignees"
2020-05-06 00:23:42.623660 (Thread-1): finished collecting timing info
2020-05-06 00:23:42.628209 (Thread-1): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-06 00:23:42.628591 (Thread-1): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-06 00:23:42.832990 (Thread-2): finished collecting timing info
2020-05-06 00:23:42.834284 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e0bc50>]}
2020-05-06 00:23:42.834651 (Thread-2): 17:23:42 | 18 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 1.11s]
2020-05-06 00:23:42.834859 (Thread-2): Finished running node model.github.issue_close_stack
2020-05-06 00:23:42.835071 (Thread-2): Began running node model.github.issue_blocked_time
2020-05-06 00:23:42.835280 (Thread-2): 17:23:42 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-06 00:23:42.835763 (Thread-2): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:23:42.836026 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-06 00:23:42.836180 (Thread-2): Compiling model.github.issue_blocked_time
2020-05-06 00:23:42.844322 (Thread-2): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-06 00:23:42.844750 (Thread-2): finished collecting timing info
2020-05-06 00:23:42.849383 (Thread-2): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-06 00:23:42.849792 (Thread-2): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-06 00:23:43.088566 (Thread-4): finished collecting timing info
2020-05-06 00:23:43.089596 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fa4d50>]}
2020-05-06 00:23:43.089959 (Thread-4): 17:23:43 | 19 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.88s]
2020-05-06 00:23:43.090169 (Thread-4): Finished running node model.github.issue_labels
2020-05-06 00:23:43.090381 (Thread-4): Began running node model.github.pull_request_times
2020-05-06 00:23:43.090606 (Thread-4): 17:23:43 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-06 00:23:43.091137 (Thread-4): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:23:43.091274 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-06 00:23:43.091399 (Thread-4): Compiling model.github.pull_request_times
2020-05-06 00:23:43.104109 (Thread-4): Writing injected SQL for node "model.github.pull_request_times"
2020-05-06 00:23:43.104502 (Thread-4): finished collecting timing info
2020-05-06 00:23:43.109792 (Thread-4): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-06 00:23:43.110214 (Thread-4): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-06 00:23:43.179696 (Thread-1): finished collecting timing info
2020-05-06 00:23:43.180770 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11092a510>]}
2020-05-06 00:23:43.181112 (Thread-1): 17:23:43 | 21 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.57s]
2020-05-06 00:23:43.181286 (Thread-1): Finished running node model.github.issue_assignees
2020-05-06 00:23:43.181460 (Thread-1): Began running node model.github.issue_inbox_time
2020-05-06 00:23:43.181635 (Thread-1): 17:23:43 | 24 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-06 00:23:43.181974 (Thread-1): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:23:43.182097 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-06 00:23:43.182218 (Thread-1): Compiling model.github.issue_inbox_time
2020-05-06 00:23:43.190416 (Thread-1): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-06 00:23:43.190811 (Thread-1): finished collecting timing info
2020-05-06 00:23:43.195359 (Thread-1): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-06 00:23:43.195736 (Thread-1): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-06 00:23:43.451414 (Thread-3): finished collecting timing info
2020-05-06 00:23:43.453429 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110645f90>]}
2020-05-06 00:23:43.454615 (Thread-3): 17:23:43 | 20 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 1.18s]
2020-05-06 00:23:43.454857 (Thread-3): Finished running node model.github.pull_request_reviewers
2020-05-06 00:23:43.455056 (Thread-3): Began running node model.github.issue_projects
2020-05-06 00:23:43.455239 (Thread-3): 17:23:43 | 25 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-06 00:23:43.455582 (Thread-3): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:23:43.455707 (Thread-3): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-06 00:23:43.455831 (Thread-3): Compiling model.github.issue_projects
2020-05-06 00:23:43.465090 (Thread-3): Writing injected SQL for node "model.github.issue_projects"
2020-05-06 00:23:43.468767 (Thread-2): finished collecting timing info
2020-05-06 00:23:43.469568 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fa8190>]}
2020-05-06 00:23:43.469836 (Thread-2): 17:23:43 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.63s]
2020-05-06 00:23:43.470201 (Thread-2): Finished running node model.github.issue_blocked_time
2020-05-06 00:23:43.470356 (Thread-2): Began running node model.github.issue_open_length
2020-05-06 00:23:43.470487 (Thread-2): 17:23:43 | 26 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-06 00:23:43.470661 (Thread-3): finished collecting timing info
2020-05-06 00:23:43.471284 (Thread-2): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:23:43.476019 (Thread-3): Writing runtime SQL for node "model.github.issue_projects"
2020-05-06 00:23:43.476223 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-06 00:23:43.476960 (Thread-2): Compiling model.github.issue_open_length
2020-05-06 00:23:43.483531 (Thread-2): Writing injected SQL for node "model.github.issue_open_length"
2020-05-06 00:23:43.483790 (Thread-3): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-06 00:23:43.484730 (Thread-2): finished collecting timing info
2020-05-06 00:23:43.489477 (Thread-2): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-06 00:23:43.490144 (Thread-2): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-06 00:23:43.859953 (Thread-1): finished collecting timing info
2020-05-06 00:23:43.861782 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e39cd0>]}
2020-05-06 00:23:43.862816 (Thread-1): 17:23:43 | 24 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.68s]
2020-05-06 00:23:43.863936 (Thread-1): Finished running node model.github.issue_inbox_time
2020-05-06 00:23:43.977961 (Thread-4): finished collecting timing info
2020-05-06 00:23:43.979001 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fdc7d0>]}
2020-05-06 00:23:43.979431 (Thread-4): 17:23:43 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.89s]
2020-05-06 00:23:43.979683 (Thread-4): Finished running node model.github.pull_request_times
2020-05-06 00:23:44.058036 (Thread-2): finished collecting timing info
2020-05-06 00:23:44.059060 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fc5e10>]}
2020-05-06 00:23:44.059425 (Thread-2): 17:23:44 | 26 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.59s]
2020-05-06 00:23:44.059629 (Thread-2): Finished running node model.github.issue_open_length
2020-05-06 00:23:44.060088 (Thread-1): Began running node model.github.github_pull_requests
2020-05-06 00:23:44.060343 (Thread-1): 17:23:44 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-06 00:23:44.060722 (Thread-1): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:23:44.060842 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_inbox_time).
2020-05-06 00:23:44.060963 (Thread-1): Compiling model.github.github_pull_requests
2020-05-06 00:23:44.078601 (Thread-1): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-06 00:23:44.079059 (Thread-1): finished collecting timing info
2020-05-06 00:23:44.083423 (Thread-1): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-06 00:23:44.083793 (Thread-1): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-06 00:23:44.211418 (Thread-3): finished collecting timing info
2020-05-06 00:23:44.212451 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109cb750>]}
2020-05-06 00:23:44.212824 (Thread-3): 17:23:44 | 25 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.76s]
2020-05-06 00:23:44.213035 (Thread-3): Finished running node model.github.issue_projects
2020-05-06 00:23:44.213426 (Thread-2): Began running node model.github.github_issues
2020-05-06 00:23:44.213609 (Thread-2): 17:23:44 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-06 00:23:44.213939 (Thread-2): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:23:44.214080 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-06 00:23:44.214298 (Thread-2): Compiling model.github.github_issues
2020-05-06 00:23:44.232510 (Thread-2): Writing injected SQL for node "model.github.github_issues"
2020-05-06 00:23:44.232896 (Thread-2): finished collecting timing info
2020-05-06 00:23:44.237556 (Thread-2): Writing runtime SQL for node "model.github.github_issues"
2020-05-06 00:23:44.237932 (Thread-2): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-06 00:23:45.222674 (Thread-1): finished collecting timing info
2020-05-06 00:23:45.223726 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108fa3d0>]}
2020-05-06 00:23:45.224099 (Thread-1): 17:23:45 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 1.16s]
2020-05-06 00:23:45.224307 (Thread-1): Finished running node model.github.github_pull_requests
2020-05-06 00:23:45.494084 (Thread-2): finished collecting timing info
2020-05-06 00:23:45.495211 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109ba2d0>]}
2020-05-06 00:23:45.495592 (Thread-2): 17:23:45 | 28 of 29 OK created view model dbt_erik.github_issues................ [CREATE VIEW in 1.28s]
2020-05-06 00:23:45.495801 (Thread-2): Finished running node model.github.github_issues
2020-05-06 00:23:45.496292 (Thread-3): Began running node model.github.issues_and_prs_per_month
2020-05-06 00:23:45.496517 (Thread-3): 17:23:45 | 29 of 29 START view model dbt_erik.issues_and_prs_per_month.......... [RUN]
2020-05-06 00:23:45.496857 (Thread-3): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:23:45.496977 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_projects).
2020-05-06 00:23:45.497096 (Thread-3): Compiling model.github.issues_and_prs_per_month
2020-05-06 00:23:45.507053 (Thread-3): Writing injected SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:23:45.507473 (Thread-3): finished collecting timing info
2020-05-06 00:23:45.512298 (Thread-3): Writing runtime SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:23:45.512686 (Thread-3): On model.github.issues_and_prs_per_month: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month.month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-06 00:23:45.708284 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month.month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-06 00:23:45.708587 (Thread-3): 404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US

(job ID: e1bf464d-81dd-4ce6-a68d-e2e7cd5fd775)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month.month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:23:45.708931 (Thread-3): finished collecting timing info
2020-05-06 00:23:45.709840 (Thread-3): Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US
  
  (job ID: e1bf464d-81dd-4ce6-a68d-e2e7cd5fd775)
  
                                                              -----Query Job SQL Follows-----                                                             
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
     2:
     3:
     4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
     5:  OPTIONS()
     6:  as (
     7:    with github_issues as (
     8:
     9:    select *
    10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
    11:
    12:), pull_requests as (
    13:
    14:    select *
    15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
    16:
    17:), issues_opened_per_month as (
    18:
    19:   select 
    20:      date_trunc(date(created_at), month) as month, 
    21:      count(*) as number_issues_opened,
    22:      avg(days_issue_opened) as average_length_issue_open,
    23:      max(days_issue_opened) as longest_length_issue_open
    24:    from github_issues
    25:    group by 1
    26:
    27:), issues_closed_per_month as (
    28:
    29:   select 
    30:      date_trunc(date(closed_at), month) as month, 
    31:      count(*) as number_issues_closed
    32:    from github_issues
    33:    where closed_at is not null
    34:    group by 1
    35:
    36:), prs_opened_per_month as (
    37:
    38:   select 
    39:      date_trunc(date(created_at), month) as month, 
    40:      count(*) as number_prs_opened,
    41:      avg(days_issue_opened) as average_length_pr_open,
    42:      max(days_issue_opened) as longest_length_pr_open
    43:    from pull_requests
    44:    group by 1
    45:
    46:), prs_merged_per_month as (
    47:
    48:   select 
    49:      date_trunc(date(merged_at), month) as month, 
    50:      count(*) as number_prs_merged
    51:    from github_issues
    52:    group by 1
    53:
    54:), issues_per_month as (
    55:
    56:    select 
    57:      coalesce(issues_opened_per_month.month, 
    58:        issues_closed_per_month.month
    59:      ) as month,
    60:      number_issues_opened,
    61:      number_issues_closed,      
    62:      average_length_issue_open,
    63:      longest_length_issue_open
    64:    from issues_opened_per_month
    65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
    66:
    67:), prs_per_month as (
    68:
    69:    select 
    70:      coalesce(prs_opened_per_month.month, 
    71:        prs_merged_per_month.month
    72:      ) as month,
    73:      number_prs_opened,
    74:      number_prs_merged,
    75:      average_length_pr_open,
    76:      longest_length_pr_open
    77:    from prs_opened_per_month
    78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    79:
    80:)
    81:
    82:select 
    83:  coalesce(issues_per_month.month, 
    84:    prs_per_month.month
    85:  ) as month,
    86:  coalesce(number_issues_opened, 0) as number_issues_opened,
    87:  coalesce(number_issues_closed, 0) as number_issues_closed,
    88:  average_length_issue_open,
    89:  longest_length_issue_open,
    90:  coalesce(number_prs_opened, 0) as number_prs_opened,
    91:  coalesce(number_prs_merged, 0) as number_prs_merged,
    92:  average_length_pr_open,
    93:  longest_length_pr_open
    94:from prs_opened_per_month.month 
    95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    96:  );
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US

(job ID: e1bf464d-81dd-4ce6-a68d-e2e7cd5fd775)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month.month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 98, in exception_handler
    raise RuntimeException(str(e))
dbt.exceptions.RuntimeException: Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US
  
  (job ID: e1bf464d-81dd-4ce6-a68d-e2e7cd5fd775)
  
                                                              -----Query Job SQL Follows-----                                                             
  
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
     1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
     2:
     3:
     4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
     5:  OPTIONS()
     6:  as (
     7:    with github_issues as (
     8:
     9:    select *
    10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
    11:
    12:), pull_requests as (
    13:
    14:    select *
    15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
    16:
    17:), issues_opened_per_month as (
    18:
    19:   select 
    20:      date_trunc(date(created_at), month) as month, 
    21:      count(*) as number_issues_opened,
    22:      avg(days_issue_opened) as average_length_issue_open,
    23:      max(days_issue_opened) as longest_length_issue_open
    24:    from github_issues
    25:    group by 1
    26:
    27:), issues_closed_per_month as (
    28:
    29:   select 
    30:      date_trunc(date(closed_at), month) as month, 
    31:      count(*) as number_issues_closed
    32:    from github_issues
    33:    where closed_at is not null
    34:    group by 1
    35:
    36:), prs_opened_per_month as (
    37:
    38:   select 
    39:      date_trunc(date(created_at), month) as month, 
    40:      count(*) as number_prs_opened,
    41:      avg(days_issue_opened) as average_length_pr_open,
    42:      max(days_issue_opened) as longest_length_pr_open
    43:    from pull_requests
    44:    group by 1
    45:
    46:), prs_merged_per_month as (
    47:
    48:   select 
    49:      date_trunc(date(merged_at), month) as month, 
    50:      count(*) as number_prs_merged
    51:    from github_issues
    52:    group by 1
    53:
    54:), issues_per_month as (
    55:
    56:    select 
    57:      coalesce(issues_opened_per_month.month, 
    58:        issues_closed_per_month.month
    59:      ) as month,
    60:      number_issues_opened,
    61:      number_issues_closed,      
    62:      average_length_issue_open,
    63:      longest_length_issue_open
    64:    from issues_opened_per_month
    65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
    66:
    67:), prs_per_month as (
    68:
    69:    select 
    70:      coalesce(prs_opened_per_month.month, 
    71:        prs_merged_per_month.month
    72:      ) as month,
    73:      number_prs_opened,
    74:      number_prs_merged,
    75:      average_length_pr_open,
    76:      longest_length_pr_open
    77:    from prs_opened_per_month
    78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    79:
    80:)
    81:
    82:select 
    83:  coalesce(issues_per_month.month, 
    84:    prs_per_month.month
    85:  ) as month,
    86:  coalesce(number_issues_opened, 0) as number_issues_opened,
    87:  coalesce(number_issues_closed, 0) as number_issues_closed,
    88:  average_length_issue_open,
    89:  longest_length_issue_open,
    90:  coalesce(number_prs_opened, 0) as number_prs_opened,
    91:  coalesce(number_prs_merged, 0) as number_prs_merged,
    92:  average_length_pr_open,
    93:  longest_length_pr_open
    94:from prs_opened_per_month.month 
    95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
    96:  );
      |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:23:45.723891 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2284aedf-dfdd-415c-b5d4-65ad6583b693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109e6c90>]}
2020-05-06 00:23:46.368595 (Thread-3): 17:23:46 | 29 of 29 ERROR creating view model dbt_erik.issues_and_prs_per_month. [ERROR in 0.23s]
2020-05-06 00:23:46.368962 (Thread-3): Finished running node model.github.issues_and_prs_per_month
2020-05-06 00:23:46.397010 (MainThread): 17:23:46 | 
2020-05-06 00:23:46.397514 (MainThread): 17:23:46 | Finished running 29 view models in 8.93s.
2020-05-06 00:23:46.397846 (MainThread): Connection 'master' was left open.
2020-05-06 00:23:46.398114 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-06 00:23:46.398274 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-06 00:23:46.398426 (MainThread): Connection 'model.github.issues_and_prs_per_month' was left open.
2020-05-06 00:23:46.398576 (MainThread): Connection 'model.github.pull_request_times' was left open.
2020-05-06 00:23:46.468683 (MainThread): 
2020-05-06 00:23:46.468840 (MainThread): Completed with 1 error and 0 warnings:
2020-05-06 00:23:46.469055 (MainThread): 
2020-05-06 00:23:46.469270 (MainThread): Runtime Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
2020-05-06 00:23:46.469483 (MainThread):   404 Not found: Dataset digital-arbor-400:prs_opened_per_month was not found in location US
2020-05-06 00:23:46.469616 (MainThread):   
2020-05-06 00:23:46.469766 (MainThread):   (job ID: e1bf464d-81dd-4ce6-a68d-e2e7cd5fd775)
2020-05-06 00:23:46.469880 (MainThread):   
2020-05-06 00:23:46.469977 (MainThread):                                                               -----Query Job SQL Follows-----                                                             
2020-05-06 00:23:46.470145 (MainThread):   
2020-05-06 00:23:46.470328 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:23:46.470580 (MainThread):      1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
2020-05-06 00:23:46.470844 (MainThread):      2:
2020-05-06 00:23:46.471006 (MainThread):      3:
2020-05-06 00:23:46.471162 (MainThread):      4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
2020-05-06 00:23:46.471351 (MainThread):      5:  OPTIONS()
2020-05-06 00:23:46.471598 (MainThread):      6:  as (
2020-05-06 00:23:46.471810 (MainThread):      7:    with github_issues as (
2020-05-06 00:23:46.471966 (MainThread):      8:
2020-05-06 00:23:46.472104 (MainThread):      9:    select *
2020-05-06 00:23:46.472255 (MainThread):     10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
2020-05-06 00:23:46.472600 (MainThread):     11:
2020-05-06 00:23:46.472904 (MainThread):     12:), pull_requests as (
2020-05-06 00:23:46.473038 (MainThread):     13:
2020-05-06 00:23:46.473163 (MainThread):     14:    select *
2020-05-06 00:23:46.473361 (MainThread):     15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
2020-05-06 00:23:46.473501 (MainThread):     16:
2020-05-06 00:23:46.473619 (MainThread):     17:), issues_opened_per_month as (
2020-05-06 00:23:46.473753 (MainThread):     18:
2020-05-06 00:23:46.473852 (MainThread):     19:   select 
2020-05-06 00:23:46.473933 (MainThread):     20:      date_trunc(date(created_at), month) as month, 
2020-05-06 00:23:46.474015 (MainThread):     21:      count(*) as number_issues_opened,
2020-05-06 00:23:46.474210 (MainThread):     22:      avg(days_issue_opened) as average_length_issue_open,
2020-05-06 00:23:46.474325 (MainThread):     23:      max(days_issue_opened) as longest_length_issue_open
2020-05-06 00:23:46.474426 (MainThread):     24:    from github_issues
2020-05-06 00:23:46.474527 (MainThread):     25:    group by 1
2020-05-06 00:23:46.474656 (MainThread):     26:
2020-05-06 00:23:46.474807 (MainThread):     27:), issues_closed_per_month as (
2020-05-06 00:23:46.474917 (MainThread):     28:
2020-05-06 00:23:46.475025 (MainThread):     29:   select 
2020-05-06 00:23:46.475132 (MainThread):     30:      date_trunc(date(closed_at), month) as month, 
2020-05-06 00:23:46.475211 (MainThread):     31:      count(*) as number_issues_closed
2020-05-06 00:23:46.475293 (MainThread):     32:    from github_issues
2020-05-06 00:23:46.475391 (MainThread):     33:    where closed_at is not null
2020-05-06 00:23:46.475492 (MainThread):     34:    group by 1
2020-05-06 00:23:46.475575 (MainThread):     35:
2020-05-06 00:23:46.475654 (MainThread):     36:), prs_opened_per_month as (
2020-05-06 00:23:46.475734 (MainThread):     37:
2020-05-06 00:23:46.475814 (MainThread):     38:   select 
2020-05-06 00:23:46.475892 (MainThread):     39:      date_trunc(date(created_at), month) as month, 
2020-05-06 00:23:46.475971 (MainThread):     40:      count(*) as number_prs_opened,
2020-05-06 00:23:46.476050 (MainThread):     41:      avg(days_issue_opened) as average_length_pr_open,
2020-05-06 00:23:46.476128 (MainThread):     42:      max(days_issue_opened) as longest_length_pr_open
2020-05-06 00:23:46.476207 (MainThread):     43:    from pull_requests
2020-05-06 00:23:46.476285 (MainThread):     44:    group by 1
2020-05-06 00:23:46.476363 (MainThread):     45:
2020-05-06 00:23:46.476440 (MainThread):     46:), prs_merged_per_month as (
2020-05-06 00:23:46.476518 (MainThread):     47:
2020-05-06 00:23:46.476596 (MainThread):     48:   select 
2020-05-06 00:23:46.476674 (MainThread):     49:      date_trunc(date(merged_at), month) as month, 
2020-05-06 00:23:46.476752 (MainThread):     50:      count(*) as number_prs_merged
2020-05-06 00:23:46.476830 (MainThread):     51:    from github_issues
2020-05-06 00:23:46.476908 (MainThread):     52:    group by 1
2020-05-06 00:23:46.476986 (MainThread):     53:
2020-05-06 00:23:46.477064 (MainThread):     54:), issues_per_month as (
2020-05-06 00:23:46.477143 (MainThread):     55:
2020-05-06 00:23:46.477221 (MainThread):     56:    select 
2020-05-06 00:23:46.477298 (MainThread):     57:      coalesce(issues_opened_per_month.month, 
2020-05-06 00:23:46.477376 (MainThread):     58:        issues_closed_per_month.month
2020-05-06 00:23:46.477455 (MainThread):     59:      ) as month,
2020-05-06 00:23:46.477533 (MainThread):     60:      number_issues_opened,
2020-05-06 00:23:46.477611 (MainThread):     61:      number_issues_closed,      
2020-05-06 00:23:46.477689 (MainThread):     62:      average_length_issue_open,
2020-05-06 00:23:46.477767 (MainThread):     63:      longest_length_issue_open
2020-05-06 00:23:46.477844 (MainThread):     64:    from issues_opened_per_month
2020-05-06 00:23:46.477922 (MainThread):     65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
2020-05-06 00:23:46.478002 (MainThread):     66:
2020-05-06 00:23:46.478080 (MainThread):     67:), prs_per_month as (
2020-05-06 00:23:46.478158 (MainThread):     68:
2020-05-06 00:23:46.478236 (MainThread):     69:    select 
2020-05-06 00:23:46.478317 (MainThread):     70:      coalesce(prs_opened_per_month.month, 
2020-05-06 00:23:46.478396 (MainThread):     71:        prs_merged_per_month.month
2020-05-06 00:23:46.478545 (MainThread):     72:      ) as month,
2020-05-06 00:23:46.478647 (MainThread):     73:      number_prs_opened,
2020-05-06 00:23:46.478738 (MainThread):     74:      number_prs_merged,
2020-05-06 00:23:46.478842 (MainThread):     75:      average_length_pr_open,
2020-05-06 00:23:46.478958 (MainThread):     76:      longest_length_pr_open
2020-05-06 00:23:46.479073 (MainThread):     77:    from prs_opened_per_month
2020-05-06 00:23:46.479186 (MainThread):     78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
2020-05-06 00:23:46.479280 (MainThread):     79:
2020-05-06 00:23:46.479379 (MainThread):     80:)
2020-05-06 00:23:46.479492 (MainThread):     81:
2020-05-06 00:23:46.479603 (MainThread):     82:select 
2020-05-06 00:23:46.479727 (MainThread):     83:  coalesce(issues_per_month.month, 
2020-05-06 00:23:46.479807 (MainThread):     84:    prs_per_month.month
2020-05-06 00:23:46.479889 (MainThread):     85:  ) as month,
2020-05-06 00:23:46.479969 (MainThread):     86:  coalesce(number_issues_opened, 0) as number_issues_opened,
2020-05-06 00:23:46.480050 (MainThread):     87:  coalesce(number_issues_closed, 0) as number_issues_closed,
2020-05-06 00:23:46.480131 (MainThread):     88:  average_length_issue_open,
2020-05-06 00:23:46.480212 (MainThread):     89:  longest_length_issue_open,
2020-05-06 00:23:46.480293 (MainThread):     90:  coalesce(number_prs_opened, 0) as number_prs_opened,
2020-05-06 00:23:46.480373 (MainThread):     91:  coalesce(number_prs_merged, 0) as number_prs_merged,
2020-05-06 00:23:46.480453 (MainThread):     92:  average_length_pr_open,
2020-05-06 00:23:46.480533 (MainThread):     93:  longest_length_pr_open
2020-05-06 00:23:46.480613 (MainThread):     94:from prs_opened_per_month.month 
2020-05-06 00:23:46.480693 (MainThread):     95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
2020-05-06 00:23:46.480773 (MainThread):     96:  );
2020-05-06 00:23:46.480853 (MainThread):       |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-05-06 00:23:46.480969 (MainThread): 
Done. PASS=28 WARN=0 ERROR=1 SKIP=0 TOTAL=29
2020-05-06 00:23:46.481137 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fa8f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ee0d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ea9dd0>]}
2020-05-06 00:23:46.481319 (MainThread): Flushing usage events
2020-05-06 00:24:35.350302 (MainThread): Running with dbt=0.16.1
2020-05-06 00:24:35.534711 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-06 00:24:35.535911 (MainThread): Tracking: tracking
2020-05-06 00:24:35.544080 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108463f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108497190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084a6750>]}
2020-05-06 00:24:35.566056 (MainThread): Partial parsing not enabled
2020-05-06 00:24:35.568646 (MainThread): Parsing macros/core.sql
2020-05-06 00:24:35.573758 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-06 00:24:35.582739 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-06 00:24:35.585246 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-06 00:24:35.604934 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-06 00:24:35.642731 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-06 00:24:35.667005 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-06 00:24:35.669897 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-06 00:24:35.677417 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-06 00:24:35.692724 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-06 00:24:35.700479 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-06 00:24:35.709416 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-06 00:24:35.715484 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-06 00:24:35.716850 (MainThread): Parsing macros/etc/query.sql
2020-05-06 00:24:35.718351 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-06 00:24:35.722102 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-06 00:24:35.727174 (MainThread): Parsing macros/etc/datetime.sql
2020-05-06 00:24:35.739617 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-06 00:24:35.742034 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-06 00:24:35.743646 (MainThread): Parsing macros/adapters/common.sql
2020-05-06 00:24:35.790261 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-06 00:24:35.791732 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-06 00:24:35.792986 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-06 00:24:35.794370 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-06 00:24:35.797174 (MainThread): Parsing macros/etc.sql
2020-05-06 00:24:35.798214 (MainThread): Parsing macros/catalog.sql
2020-05-06 00:24:35.806739 (MainThread): Parsing macros/adapters.sql
2020-05-06 00:24:35.830626 (MainThread): Parsing macros/materializations/seed.sql
2020-05-06 00:24:35.833646 (MainThread): Parsing macros/materializations/view.sql
2020-05-06 00:24:35.835369 (MainThread): Parsing macros/materializations/table.sql
2020-05-06 00:24:35.847237 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-06 00:24:35.862365 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-06 00:24:35.885230 (MainThread): Partial parsing not enabled
2020-05-06 00:24:35.921924 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:24:35.922077 (MainThread): Opening a new connection, currently in state init
2020-05-06 00:24:35.947088 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:24:35.947220 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:35.954867 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:24:35.954997 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:35.970711 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:24:35.970840 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:35.978145 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:24:35.978271 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:35.985304 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:24:35.985424 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:35.992104 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:24:35.992224 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:35.999092 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:24:35.999268 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.007388 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:24:36.007604 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.014478 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:24:36.014626 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.023045 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:24:36.023198 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.030700 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:24:36.030815 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.038431 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:24:36.038582 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.049916 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:24:36.050092 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.057052 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:24:36.057186 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.063725 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:24:36.063844 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.070477 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:24:36.070607 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.077914 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:24:36.078049 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.084672 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:24:36.084793 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.091033 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:24:36.091165 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.097656 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:24:36.097778 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.104714 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:24:36.104840 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.111262 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:24:36.111392 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.117587 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:24:36.117720 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.123806 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:24:36.123910 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.130278 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:24:36.130400 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.137236 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:24:36.137358 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.144557 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:24:36.144704 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.152070 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:24:36.152202 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.285847 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-06 00:24:36.543066 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-06 00:24:36.561607 (MainThread): 
2020-05-06 00:24:36.561949 (MainThread): Acquiring new bigquery connection "master".
2020-05-06 00:24:36.562051 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:24:36.618773 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-06 00:24:36.618973 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-06 00:24:37.415061 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-06 00:24:37.415460 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-06 00:24:37.415787 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-06 00:24:37.577505 (MainThread): 17:24:37 | Concurrency: 4 threads (target='dev')
2020-05-06 00:24:37.577738 (MainThread): 17:24:37 | 
2020-05-06 00:24:37.579866 (Thread-1): Began running node model.github.stg_github_issue
2020-05-06 00:24:37.580006 (Thread-2): Began running node model.github.stg_github_card
2020-05-06 00:24:37.580167 (Thread-1): 17:24:37 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-06 00:24:37.580304 (Thread-2): 17:24:37 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-06 00:24:37.580506 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-06 00:24:37.580652 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-06 00:24:37.580916 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:24:37.581163 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:24:37.581294 (Thread-3): 17:24:37 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-06 00:24:37.581442 (Thread-4): 17:24:37 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-06 00:24:37.581546 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-06 00:24:37.581643 (Thread-2): Opening a new connection, currently in state init
2020-05-06 00:24:37.581887 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:24:37.582150 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:24:37.582274 (Thread-1): Compiling model.github.stg_github_issue
2020-05-06 00:24:37.582378 (Thread-2): Compiling model.github.stg_github_card
2020-05-06 00:24:37.582468 (Thread-3): Opening a new connection, currently in state init
2020-05-06 00:24:37.582554 (Thread-4): Opening a new connection, currently in state init
2020-05-06 00:24:37.602974 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-06 00:24:37.604259 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-06 00:24:37.604434 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-06 00:24:37.604662 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-06 00:24:37.612092 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:24:37.619388 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:24:37.619582 (Thread-1): finished collecting timing info
2020-05-06 00:24:37.620128 (Thread-2): finished collecting timing info
2020-05-06 00:24:37.620463 (Thread-3): finished collecting timing info
2020-05-06 00:24:37.625849 (Thread-4): finished collecting timing info
2020-05-06 00:24:38.101632 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-06 00:24:38.102143 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-06 00:24:38.123107 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:24:38.134631 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:24:38.135086 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-06 00:24:38.136697 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-06 00:24:38.136888 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-06 00:24:38.137643 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-06 00:24:38.929455 (Thread-1): finished collecting timing info
2020-05-06 00:24:38.930402 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086a9550>]}
2020-05-06 00:24:38.930650 (Thread-1): 17:24:38 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.35s]
2020-05-06 00:24:38.930786 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-06 00:24:38.930915 (Thread-1): Began running node model.github.stg_github_user
2020-05-06 00:24:38.931197 (Thread-1): 17:24:38 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-06 00:24:38.931585 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:24:38.931724 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-06 00:24:38.931815 (Thread-1): Compiling model.github.stg_github_user
2020-05-06 00:24:38.938578 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-06 00:24:38.942093 (Thread-3): finished collecting timing info
2020-05-06 00:24:38.942770 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10871d210>]}
2020-05-06 00:24:38.943028 (Thread-3): 17:24:38 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.36s]
2020-05-06 00:24:38.943140 (Thread-1): finished collecting timing info
2020-05-06 00:24:38.943378 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-06 00:24:38.947828 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-06 00:24:38.948093 (Thread-3): Began running node model.github.stg_github_issue_assignee
2020-05-06 00:24:38.948642 (Thread-3): 17:24:38 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-06 00:24:38.948962 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:24:38.949094 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-06 00:24:38.949175 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-06 00:24:38.949580 (Thread-3): Compiling model.github.stg_github_issue_assignee
2020-05-06 00:24:38.956653 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:24:38.957061 (Thread-3): finished collecting timing info
2020-05-06 00:24:38.961549 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:24:38.962607 (Thread-3): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-06 00:24:39.072064 (Thread-2): finished collecting timing info
2020-05-06 00:24:39.073317 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086a9310>]}
2020-05-06 00:24:39.074351 (Thread-2): 17:24:39 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.49s]
2020-05-06 00:24:39.074538 (Thread-2): Finished running node model.github.stg_github_card
2020-05-06 00:24:39.074666 (Thread-2): Began running node model.github.stg_github_issue_label
2020-05-06 00:24:39.074870 (Thread-2): 17:24:39 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-06 00:24:39.075293 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:24:39.075588 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-06 00:24:39.075687 (Thread-2): Compiling model.github.stg_github_issue_label
2020-05-06 00:24:39.082484 (Thread-2): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:24:39.083120 (Thread-2): finished collecting timing info
2020-05-06 00:24:39.087467 (Thread-2): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:24:39.087855 (Thread-2): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-06 00:24:39.197366 (Thread-4): finished collecting timing info
2020-05-06 00:24:39.197980 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086bb510>]}
2020-05-06 00:24:39.198206 (Thread-4): 17:24:39 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.62s]
2020-05-06 00:24:39.198329 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-06 00:24:39.198513 (Thread-4): Began running node model.github.stg_github_pull_request_review
2020-05-06 00:24:39.198988 (Thread-4): 17:24:39 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-06 00:24:39.199417 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:24:39.199518 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-06 00:24:39.199612 (Thread-4): Compiling model.github.stg_github_pull_request_review
2020-05-06 00:24:39.206904 (Thread-4): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:24:39.207265 (Thread-4): finished collecting timing info
2020-05-06 00:24:39.211514 (Thread-4): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:24:39.211886 (Thread-4): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-06 00:24:39.581211 (Thread-1): finished collecting timing info
2020-05-06 00:24:39.581835 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051f98d0>]}
2020-05-06 00:24:39.582211 (Thread-1): 17:24:39 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.65s]
2020-05-06 00:24:39.582344 (Thread-1): Finished running node model.github.stg_github_user
2020-05-06 00:24:39.582480 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-06 00:24:39.582696 (Thread-1): 17:24:39 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-06 00:24:39.583055 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:24:39.583171 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-06 00:24:39.583267 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-06 00:24:39.589951 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:24:39.590304 (Thread-1): finished collecting timing info
2020-05-06 00:24:39.596171 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:24:39.596549 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-06 00:24:39.754597 (Thread-4): finished collecting timing info
2020-05-06 00:24:39.755218 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c1a0d0>]}
2020-05-06 00:24:39.755442 (Thread-4): 17:24:39 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.56s]
2020-05-06 00:24:39.755618 (Thread-4): Finished running node model.github.stg_github_pull_request_review
2020-05-06 00:24:39.755741 (Thread-4): Began running node model.github.stg_github_issue_merged
2020-05-06 00:24:39.756013 (Thread-4): 17:24:39 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-06 00:24:39.756516 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:24:39.756604 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-06 00:24:39.756688 (Thread-4): Compiling model.github.stg_github_issue_merged
2020-05-06 00:24:39.763182 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:24:39.766394 (Thread-3): finished collecting timing info
2020-05-06 00:24:39.767072 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bd6490>]}
2020-05-06 00:24:39.767230 (Thread-4): finished collecting timing info
2020-05-06 00:24:39.767523 (Thread-3): 17:24:39 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.82s]
2020-05-06 00:24:39.771784 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:24:39.771934 (Thread-3): Finished running node model.github.stg_github_issue_assignee
2020-05-06 00:24:39.772165 (Thread-3): Began running node model.github.stg_github_project
2020-05-06 00:24:39.772453 (Thread-3): 17:24:39 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-06 00:24:39.772806 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:24:39.772930 (Thread-4): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-06 00:24:39.773033 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-06 00:24:39.773447 (Thread-3): Compiling model.github.stg_github_project
2020-05-06 00:24:39.781088 (Thread-3): Writing injected SQL for node "model.github.stg_github_project"
2020-05-06 00:24:39.781633 (Thread-3): finished collecting timing info
2020-05-06 00:24:39.786443 (Thread-3): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-06 00:24:39.787333 (Thread-3): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-06 00:24:40.054442 (Thread-2): finished collecting timing info
2020-05-06 00:24:40.055166 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b628d0>]}
2020-05-06 00:24:40.055409 (Thread-2): 17:24:40 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.98s]
2020-05-06 00:24:40.055537 (Thread-2): Finished running node model.github.stg_github_issue_label
2020-05-06 00:24:40.055698 (Thread-2): Began running node model.github.stg_github_pull_request
2020-05-06 00:24:40.055912 (Thread-2): 17:24:40 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-06 00:24:40.056231 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:24:40.056317 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-06 00:24:40.056405 (Thread-2): Compiling model.github.stg_github_pull_request
2020-05-06 00:24:40.062986 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:24:40.064612 (Thread-2): finished collecting timing info
2020-05-06 00:24:40.069098 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:24:40.070759 (Thread-2): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-06 00:24:40.073857 (Thread-1): finished collecting timing info
2020-05-06 00:24:40.074508 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bc8b10>]}
2020-05-06 00:24:40.074908 (Thread-1): 17:24:40 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.49s]
2020-05-06 00:24:40.075230 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-06 00:24:40.075367 (Thread-1): Began running node model.github.stg_github_repository
2020-05-06 00:24:40.075868 (Thread-1): 17:24:40 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-06 00:24:40.076225 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:24:40.076311 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-06 00:24:40.076395 (Thread-1): Compiling model.github.stg_github_repository
2020-05-06 00:24:40.083829 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-06 00:24:40.085000 (Thread-1): finished collecting timing info
2020-05-06 00:24:40.089973 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-06 00:24:40.091083 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-06 00:24:40.343463 (Thread-4): finished collecting timing info
2020-05-06 00:24:40.344061 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086eda10>]}
2020-05-06 00:24:40.344279 (Thread-4): 17:24:40 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.59s]
2020-05-06 00:24:40.344398 (Thread-4): Finished running node model.github.stg_github_issue_merged
2020-05-06 00:24:40.344553 (Thread-4): Began running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:24:40.344801 (Thread-4): 17:24:40 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-06 00:24:40.345157 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:24:40.345257 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-06 00:24:40.345365 (Thread-4): Compiling model.github.stg_github_requested_reviewer_history
2020-05-06 00:24:40.352133 (Thread-4): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:24:40.352469 (Thread-4): finished collecting timing info
2020-05-06 00:24:40.357621 (Thread-4): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:24:40.357965 (Thread-4): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-06 00:24:40.362056 (Thread-3): finished collecting timing info
2020-05-06 00:24:40.363271 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d05690>]}
2020-05-06 00:24:40.363929 (Thread-3): 17:24:40 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.59s]
2020-05-06 00:24:40.364336 (Thread-3): Finished running node model.github.stg_github_project
2020-05-06 00:24:40.364865 (Thread-3): Began running node model.github.stg_github_milestone
2020-05-06 00:24:40.365030 (Thread-3): 17:24:40 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-06 00:24:40.365680 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:24:40.365815 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-06 00:24:40.365971 (Thread-3): Compiling model.github.stg_github_milestone
2020-05-06 00:24:40.372757 (Thread-3): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-06 00:24:40.373114 (Thread-3): finished collecting timing info
2020-05-06 00:24:40.377480 (Thread-3): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-06 00:24:40.377892 (Thread-3): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-06 00:24:40.718884 (Thread-1): finished collecting timing info
2020-05-06 00:24:40.719612 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086bb910>]}
2020-05-06 00:24:40.719864 (Thread-1): 17:24:40 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.64s]
2020-05-06 00:24:40.719995 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-06 00:24:40.720124 (Thread-1): Began running node model.github.stg_github_issue_comment
2020-05-06 00:24:40.720349 (Thread-1): 17:24:40 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-06 00:24:40.720630 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:24:40.720716 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-06 00:24:40.720804 (Thread-1): Compiling model.github.stg_github_issue_comment
2020-05-06 00:24:40.729016 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:24:40.729459 (Thread-1): finished collecting timing info
2020-05-06 00:24:40.734102 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:24:40.734488 (Thread-1): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-06 00:24:40.855496 (Thread-2): finished collecting timing info
2020-05-06 00:24:40.856112 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b8ed90>]}
2020-05-06 00:24:40.856336 (Thread-2): 17:24:40 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.80s]
2020-05-06 00:24:40.856460 (Thread-2): Finished running node model.github.stg_github_pull_request
2020-05-06 00:24:40.856583 (Thread-2): Began running node model.github.issue_close_stack
2020-05-06 00:24:40.856715 (Thread-2): 17:24:40 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-06 00:24:40.857050 (Thread-2): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:24:40.857152 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-06 00:24:40.857250 (Thread-2): Compiling model.github.issue_close_stack
2020-05-06 00:24:40.864862 (Thread-2): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-06 00:24:40.865232 (Thread-2): finished collecting timing info
2020-05-06 00:24:40.869594 (Thread-2): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-06 00:24:40.869984 (Thread-2): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-06 00:24:40.908897 (Thread-3): finished collecting timing info
2020-05-06 00:24:40.909745 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cea9d0>]}
2020-05-06 00:24:40.910012 (Thread-3): 17:24:40 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.54s]
2020-05-06 00:24:40.910168 (Thread-3): Finished running node model.github.stg_github_milestone
2020-05-06 00:24:40.910389 (Thread-3): Began running node model.github.issue_status_windows
2020-05-06 00:24:40.910680 (Thread-3): 17:24:40 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-06 00:24:40.910928 (Thread-3): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:24:40.911014 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-06 00:24:40.911099 (Thread-3): Compiling model.github.issue_status_windows
2020-05-06 00:24:40.919244 (Thread-3): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-06 00:24:40.919636 (Thread-3): finished collecting timing info
2020-05-06 00:24:40.924069 (Thread-3): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-06 00:24:40.924642 (Thread-3): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-06 00:24:40.940546 (Thread-4): finished collecting timing info
2020-05-06 00:24:40.941166 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d12ad0>]}
2020-05-06 00:24:40.941397 (Thread-4): 17:24:40 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.60s]
2020-05-06 00:24:40.941519 (Thread-4): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:24:40.941644 (Thread-4): Began running node model.github.pull_request_reviewers
2020-05-06 00:24:40.941847 (Thread-4): 17:24:40 | 19 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-06 00:24:40.942159 (Thread-4): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:24:40.942244 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-06 00:24:40.942326 (Thread-4): Compiling model.github.pull_request_reviewers
2020-05-06 00:24:40.950445 (Thread-4): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:24:40.950815 (Thread-4): finished collecting timing info
2020-05-06 00:24:40.956023 (Thread-4): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:24:40.956453 (Thread-4): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-06 00:24:41.379289 (Thread-2): finished collecting timing info
2020-05-06 00:24:41.380352 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086edd10>]}
2020-05-06 00:24:41.380726 (Thread-2): 17:24:41 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.52s]
2020-05-06 00:24:41.380937 (Thread-2): Finished running node model.github.issue_close_stack
2020-05-06 00:24:41.381160 (Thread-2): Began running node model.github.issue_assignees
2020-05-06 00:24:41.381338 (Thread-2): 17:24:41 | 20 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-06 00:24:41.381672 (Thread-2): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:24:41.381795 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-06 00:24:41.381922 (Thread-2): Compiling model.github.issue_assignees
2020-05-06 00:24:41.426816 (Thread-2): Writing injected SQL for node "model.github.issue_assignees"
2020-05-06 00:24:41.430479 (Thread-2): finished collecting timing info
2020-05-06 00:24:41.435990 (Thread-2): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-06 00:24:41.438278 (Thread-2): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-06 00:24:41.551982 (Thread-1): finished collecting timing info
2020-05-06 00:24:41.555982 (Thread-4): finished collecting timing info
2020-05-06 00:24:41.556776 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108639090>]}
2020-05-06 00:24:41.557413 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d44b10>]}
2020-05-06 00:24:41.557730 (Thread-1): 17:24:41 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.84s]
2020-05-06 00:24:41.557987 (Thread-4): 17:24:41 | 19 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.62s]
2020-05-06 00:24:41.558173 (Thread-1): Finished running node model.github.stg_github_issue_comment
2020-05-06 00:24:41.558343 (Thread-4): Finished running node model.github.pull_request_reviewers
2020-05-06 00:24:41.558519 (Thread-1): Began running node model.github.issue_labels
2020-05-06 00:24:41.558807 (Thread-4): Began running node model.github.issue_blocked_time
2020-05-06 00:24:41.559086 (Thread-1): 17:24:41 | 21 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-06 00:24:41.559275 (Thread-4): 17:24:41 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-06 00:24:41.559642 (Thread-1): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:24:41.559919 (Thread-4): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:24:41.560041 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-06 00:24:41.560143 (Thread-4): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-06 00:24:41.560254 (Thread-1): Compiling model.github.issue_labels
2020-05-06 00:24:41.560356 (Thread-4): Compiling model.github.issue_blocked_time
2020-05-06 00:24:41.567775 (Thread-1): Writing injected SQL for node "model.github.issue_labels"
2020-05-06 00:24:41.573859 (Thread-4): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-06 00:24:41.574316 (Thread-4): finished collecting timing info
2020-05-06 00:24:41.578475 (Thread-4): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-06 00:24:41.578689 (Thread-1): finished collecting timing info
2020-05-06 00:24:41.582761 (Thread-1): Writing runtime SQL for node "model.github.issue_labels"
2020-05-06 00:24:41.583098 (Thread-4): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-06 00:24:41.583988 (Thread-1): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-06 00:24:41.734485 (Thread-3): finished collecting timing info
2020-05-06 00:24:41.736506 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108befb50>]}
2020-05-06 00:24:41.737412 (Thread-3): 17:24:41 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.83s]
2020-05-06 00:24:41.738369 (Thread-3): Finished running node model.github.issue_status_windows
2020-05-06 00:24:41.738577 (Thread-3): Began running node model.github.pull_request_times
2020-05-06 00:24:41.738766 (Thread-3): 17:24:41 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-06 00:24:41.739129 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:24:41.739257 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-06 00:24:41.739384 (Thread-3): Compiling model.github.pull_request_times
2020-05-06 00:24:41.754248 (Thread-3): Writing injected SQL for node "model.github.pull_request_times"
2020-05-06 00:24:41.755086 (Thread-3): finished collecting timing info
2020-05-06 00:24:41.759785 (Thread-3): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-06 00:24:41.760197 (Thread-3): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-06 00:24:41.990658 (Thread-2): finished collecting timing info
2020-05-06 00:24:41.991441 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086ede50>]}
2020-05-06 00:24:41.991713 (Thread-2): 17:24:41 | 20 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.61s]
2020-05-06 00:24:41.991871 (Thread-2): Finished running node model.github.issue_assignees
2020-05-06 00:24:41.992090 (Thread-2): Began running node model.github.issue_open_length
2020-05-06 00:24:41.992348 (Thread-2): 17:24:41 | 24 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-06 00:24:41.992670 (Thread-2): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:24:41.992778 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-06 00:24:41.992887 (Thread-2): Compiling model.github.issue_open_length
2020-05-06 00:24:42.000986 (Thread-2): Writing injected SQL for node "model.github.issue_open_length"
2020-05-06 00:24:42.001441 (Thread-2): finished collecting timing info
2020-05-06 00:24:42.006677 (Thread-2): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-06 00:24:42.007132 (Thread-2): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-06 00:24:42.169107 (Thread-1): finished collecting timing info
2020-05-06 00:24:42.170190 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ce3dd0>]}
2020-05-06 00:24:42.170565 (Thread-1): 17:24:42 | 21 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.61s]
2020-05-06 00:24:42.170777 (Thread-1): Finished running node model.github.issue_labels
2020-05-06 00:24:42.171012 (Thread-1): Began running node model.github.issue_inbox_time
2020-05-06 00:24:42.171299 (Thread-1): 17:24:42 | 25 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-06 00:24:42.171666 (Thread-1): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:24:42.171793 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-06 00:24:42.171916 (Thread-1): Compiling model.github.issue_inbox_time
2020-05-06 00:24:42.180101 (Thread-1): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-06 00:24:42.180566 (Thread-1): finished collecting timing info
2020-05-06 00:24:42.184920 (Thread-1): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-06 00:24:42.185255 (Thread-1): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-06 00:24:42.299305 (Thread-4): finished collecting timing info
2020-05-06 00:24:42.300515 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108639090>]}
2020-05-06 00:24:42.300931 (Thread-4): 17:24:42 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.74s]
2020-05-06 00:24:42.301154 (Thread-4): Finished running node model.github.issue_blocked_time
2020-05-06 00:24:42.301375 (Thread-4): Began running node model.github.issue_projects
2020-05-06 00:24:42.301723 (Thread-4): 17:24:42 | 26 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-06 00:24:42.302093 (Thread-4): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:24:42.302219 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-06 00:24:42.302343 (Thread-4): Compiling model.github.issue_projects
2020-05-06 00:24:42.311641 (Thread-4): Writing injected SQL for node "model.github.issue_projects"
2020-05-06 00:24:42.312029 (Thread-4): finished collecting timing info
2020-05-06 00:24:42.316595 (Thread-4): Writing runtime SQL for node "model.github.issue_projects"
2020-05-06 00:24:42.316993 (Thread-4): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-06 00:24:42.377730 (Thread-3): finished collecting timing info
2020-05-06 00:24:42.378815 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c3b690>]}
2020-05-06 00:24:42.379202 (Thread-3): 17:24:42 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.64s]
2020-05-06 00:24:42.379382 (Thread-3): Finished running node model.github.pull_request_times
2020-05-06 00:24:42.660423 (Thread-2): finished collecting timing info
2020-05-06 00:24:42.661618 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108711550>]}
2020-05-06 00:24:42.663068 (Thread-2): 17:24:42 | 24 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.67s]
2020-05-06 00:24:42.664637 (Thread-2): Finished running node model.github.issue_open_length
2020-05-06 00:24:42.665248 (Thread-3): Began running node model.github.github_pull_requests
2020-05-06 00:24:42.665524 (Thread-3): 17:24:42 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-06 00:24:42.666297 (Thread-3): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:24:42.666480 (Thread-3): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-06 00:24:42.666681 (Thread-3): Compiling model.github.github_pull_requests
2020-05-06 00:24:42.683963 (Thread-3): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-06 00:24:42.684817 (Thread-3): finished collecting timing info
2020-05-06 00:24:42.689164 (Thread-3): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-06 00:24:42.689515 (Thread-3): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-06 00:24:43.049307 (Thread-1): finished collecting timing info
2020-05-06 00:24:43.050447 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108702990>]}
2020-05-06 00:24:43.050826 (Thread-1): 17:24:43 | 25 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.88s]
2020-05-06 00:24:43.051003 (Thread-1): Finished running node model.github.issue_inbox_time
2020-05-06 00:24:43.175861 (Thread-4): finished collecting timing info
2020-05-06 00:24:43.176891 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10850c610>]}
2020-05-06 00:24:43.177262 (Thread-4): 17:24:43 | 26 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.87s]
2020-05-06 00:24:43.177474 (Thread-4): Finished running node model.github.issue_projects
2020-05-06 00:24:43.178038 (Thread-2): Began running node model.github.github_issues
2020-05-06 00:24:43.178243 (Thread-2): 17:24:43 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-06 00:24:43.178602 (Thread-2): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:24:43.178729 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-06 00:24:43.178856 (Thread-2): Compiling model.github.github_issues
2020-05-06 00:24:43.197093 (Thread-2): Writing injected SQL for node "model.github.github_issues"
2020-05-06 00:24:43.197467 (Thread-2): finished collecting timing info
2020-05-06 00:24:43.202658 (Thread-2): Writing runtime SQL for node "model.github.github_issues"
2020-05-06 00:24:43.203065 (Thread-2): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-06 00:24:43.642493 (Thread-3): finished collecting timing info
2020-05-06 00:24:43.643535 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10846cbd0>]}
2020-05-06 00:24:43.643905 (Thread-3): 17:24:43 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 0.98s]
2020-05-06 00:24:43.644117 (Thread-3): Finished running node model.github.github_pull_requests
2020-05-06 00:24:44.378695 (Thread-2): finished collecting timing info
2020-05-06 00:24:44.379739 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10867dd10>]}
2020-05-06 00:24:44.380112 (Thread-2): 17:24:44 | 28 of 29 OK created view model dbt_erik.github_issues................ [CREATE VIEW in 1.20s]
2020-05-06 00:24:44.380327 (Thread-2): Finished running node model.github.github_issues
2020-05-06 00:24:44.380815 (Thread-4): Began running node model.github.issues_and_prs_per_month
2020-05-06 00:24:44.381028 (Thread-4): 17:24:44 | 29 of 29 START view model dbt_erik.issues_and_prs_per_month.......... [RUN]
2020-05-06 00:24:44.381367 (Thread-4): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:24:44.381489 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_projects).
2020-05-06 00:24:44.381611 (Thread-4): Compiling model.github.issues_and_prs_per_month
2020-05-06 00:24:44.391203 (Thread-4): Writing injected SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:24:44.391618 (Thread-4): finished collecting timing info
2020-05-06 00:24:44.396127 (Thread-4): Writing runtime SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:24:44.396524 (Thread-4): On model.github.issues_and_prs_per_month: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from github_issues
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-06 00:24:45.382416 (Thread-4): finished collecting timing info
2020-05-06 00:24:45.383837 (Thread-4): Database Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  Unrecognized name: merged_at at [49:23]
  compiled SQL at target/run/github/issues_and_prs_per_month.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/63c12e72-10bb-482e-9b50-d3fc75d9f9a2?maxResults=0&location=US: Unrecognized name: merged_at at [49:23]

(job ID: 63c12e72-10bb-482e-9b50-d3fc75d9f9a2)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from github_issues
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  Unrecognized name: merged_at at [49:23]
  compiled SQL at target/run/github/issues_and_prs_per_month.sql
2020-05-06 00:24:45.402130 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07e05d3c-5d99-4b03-a738-2c44196569bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bef2d0>]}
2020-05-06 00:24:46.011957 (Thread-4): 17:24:46 | 29 of 29 ERROR creating view model dbt_erik.issues_and_prs_per_month. [ERROR in 1.02s]
2020-05-06 00:24:46.012275 (Thread-4): Finished running node model.github.issues_and_prs_per_month
2020-05-06 00:24:46.047163 (MainThread): 17:24:46 | 
2020-05-06 00:24:46.048066 (MainThread): 17:24:46 | Finished running 29 view models in 9.48s.
2020-05-06 00:24:46.048412 (MainThread): Connection 'master' was left open.
2020-05-06 00:24:46.048611 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-06 00:24:46.048781 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-06 00:24:46.048943 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-06 00:24:46.049099 (MainThread): Connection 'model.github.issues_and_prs_per_month' was left open.
2020-05-06 00:24:46.119773 (MainThread): 
2020-05-06 00:24:46.119969 (MainThread): Completed with 1 error and 0 warnings:
2020-05-06 00:24:46.120133 (MainThread): 
2020-05-06 00:24:46.120232 (MainThread): Database Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
2020-05-06 00:24:46.120321 (MainThread):   Unrecognized name: merged_at at [49:23]
2020-05-06 00:24:46.120404 (MainThread):   compiled SQL at target/run/github/issues_and_prs_per_month.sql
2020-05-06 00:24:46.120554 (MainThread): 
Done. PASS=28 WARN=0 ERROR=1 SKIP=0 TOTAL=29
2020-05-06 00:24:46.120748 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086c38d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b55050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086818d0>]}
2020-05-06 00:24:46.120919 (MainThread): Flushing usage events
2020-05-06 00:25:23.493331 (MainThread): Running with dbt=0.16.1
2020-05-06 00:25:23.634388 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-06 00:25:23.635384 (MainThread): Tracking: tracking
2020-05-06 00:25:23.642234 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10950a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109519cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ea950>]}
2020-05-06 00:25:23.666301 (MainThread): Partial parsing not enabled
2020-05-06 00:25:23.668491 (MainThread): Parsing macros/core.sql
2020-05-06 00:25:23.673040 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-06 00:25:23.682825 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-06 00:25:23.685594 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-06 00:25:23.704901 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-06 00:25:23.742475 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-06 00:25:23.766750 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-06 00:25:23.769559 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-06 00:25:23.776580 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-06 00:25:23.791054 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-06 00:25:23.798595 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-06 00:25:23.806361 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-06 00:25:23.811625 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-06 00:25:23.812716 (MainThread): Parsing macros/etc/query.sql
2020-05-06 00:25:23.813991 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-06 00:25:23.815905 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-06 00:25:23.818112 (MainThread): Parsing macros/etc/datetime.sql
2020-05-06 00:25:23.827778 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-06 00:25:23.829882 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-06 00:25:23.830990 (MainThread): Parsing macros/adapters/common.sql
2020-05-06 00:25:23.874522 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-06 00:25:23.875763 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-06 00:25:23.876778 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-06 00:25:23.877942 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-06 00:25:23.880676 (MainThread): Parsing macros/etc.sql
2020-05-06 00:25:23.881374 (MainThread): Parsing macros/catalog.sql
2020-05-06 00:25:23.889097 (MainThread): Parsing macros/adapters.sql
2020-05-06 00:25:23.911338 (MainThread): Parsing macros/materializations/seed.sql
2020-05-06 00:25:23.913494 (MainThread): Parsing macros/materializations/view.sql
2020-05-06 00:25:23.915010 (MainThread): Parsing macros/materializations/table.sql
2020-05-06 00:25:23.925990 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-06 00:25:23.940081 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-06 00:25:23.959496 (MainThread): Partial parsing not enabled
2020-05-06 00:25:23.992905 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:25:23.993040 (MainThread): Opening a new connection, currently in state init
2020-05-06 00:25:24.016606 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:25:24.016735 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.023590 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:25:24.023704 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.038827 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:25:24.038961 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.045606 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:25:24.045724 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.052700 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:25:24.052819 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.058980 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:25:24.059103 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.065390 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:25:24.065518 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.072240 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:25:24.072358 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.077972 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:25:24.078079 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.084729 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:25:24.084839 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.091795 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:25:24.092012 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.099267 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:25:24.099473 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.109231 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:25:24.109366 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.115242 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:25:24.115360 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.120894 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:25:24.120999 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.126820 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:25:24.126932 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.133873 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:25:24.133998 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.140100 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:25:24.140219 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.146200 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:25:24.146387 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.152385 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:25:24.152492 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.158324 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:25:24.158440 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.164877 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:25:24.165003 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.170948 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:25:24.171058 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.176803 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:25:24.176966 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.183103 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:25:24.183223 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.189081 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:25:24.189199 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.194956 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:25:24.195143 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.202054 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:25:24.202178 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.334688 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-06 00:25:24.581802 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-06 00:25:24.599839 (MainThread): 
2020-05-06 00:25:24.600177 (MainThread): Acquiring new bigquery connection "master".
2020-05-06 00:25:24.600270 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:25:24.654368 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-06 00:25:24.654648 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-06 00:25:25.430388 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-06 00:25:25.430789 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-06 00:25:25.431127 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-06 00:25:25.616000 (MainThread): 17:25:25 | Concurrency: 4 threads (target='dev')
2020-05-06 00:25:25.616166 (MainThread): 17:25:25 | 
2020-05-06 00:25:25.618276 (Thread-1): Began running node model.github.stg_github_issue
2020-05-06 00:25:25.618454 (Thread-1): 17:25:25 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-06 00:25:25.618672 (Thread-2): Began running node model.github.stg_github_card
2020-05-06 00:25:25.618877 (Thread-2): 17:25:25 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-06 00:25:25.619383 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:25:25.619523 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-06 00:25:25.619904 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:25:25.620073 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-06 00:25:25.620162 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-06 00:25:25.620303 (Thread-3): 17:25:25 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-06 00:25:25.620478 (Thread-2): Opening a new connection, currently in state init
2020-05-06 00:25:25.620702 (Thread-4): 17:25:25 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-06 00:25:25.620843 (Thread-1): Compiling model.github.stg_github_issue
2020-05-06 00:25:25.621132 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:25:25.621218 (Thread-2): Compiling model.github.stg_github_card
2020-05-06 00:25:25.621491 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:25:25.634288 (Thread-3): Opening a new connection, currently in state init
2020-05-06 00:25:25.636079 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-06 00:25:25.645287 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-06 00:25:25.645501 (Thread-4): Opening a new connection, currently in state init
2020-05-06 00:25:25.645709 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-06 00:25:25.646082 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-06 00:25:25.659629 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:25:25.661467 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:25:25.661618 (Thread-1): finished collecting timing info
2020-05-06 00:25:25.661982 (Thread-2): finished collecting timing info
2020-05-06 00:25:25.681849 (Thread-3): finished collecting timing info
2020-05-06 00:25:25.682214 (Thread-4): finished collecting timing info
2020-05-06 00:25:26.099424 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:25:26.132354 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-06 00:25:26.132907 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-06 00:25:26.141913 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:25:26.142773 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-06 00:25:26.143401 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-06 00:25:26.144632 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-06 00:25:26.145717 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-06 00:25:26.734017 (Thread-1): finished collecting timing info
2020-05-06 00:25:26.736153 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ea950>]}
2020-05-06 00:25:26.736776 (Thread-1): 17:25:26 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.12s]
2020-05-06 00:25:26.736943 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-06 00:25:26.737095 (Thread-1): Began running node model.github.stg_github_user
2020-05-06 00:25:26.737244 (Thread-1): 17:25:26 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-06 00:25:26.737651 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:25:26.737769 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-06 00:25:26.737937 (Thread-1): Compiling model.github.stg_github_user
2020-05-06 00:25:26.745766 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-06 00:25:26.746145 (Thread-1): finished collecting timing info
2020-05-06 00:25:26.750546 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-06 00:25:26.750895 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-06 00:25:26.856084 (Thread-3): finished collecting timing info
2020-05-06 00:25:26.857136 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096ca890>]}
2020-05-06 00:25:26.857504 (Thread-3): 17:25:26 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.24s]
2020-05-06 00:25:26.857711 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-06 00:25:26.857922 (Thread-3): Began running node model.github.stg_github_issue_assignee
2020-05-06 00:25:26.858150 (Thread-3): 17:25:26 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-06 00:25:26.858588 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:25:26.858943 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-06 00:25:26.859089 (Thread-3): Compiling model.github.stg_github_issue_assignee
2020-05-06 00:25:26.867866 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:25:26.868340 (Thread-3): finished collecting timing info
2020-05-06 00:25:26.872812 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:25:26.875907 (Thread-4): finished collecting timing info
2020-05-06 00:25:26.876468 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097e8990>]}
2020-05-06 00:25:26.876757 (Thread-4): 17:25:26 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.25s]
2020-05-06 00:25:26.877037 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-06 00:25:26.877241 (Thread-4): Began running node model.github.stg_github_issue_label
2020-05-06 00:25:26.877579 (Thread-4): 17:25:26 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-06 00:25:26.877843 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:25:26.877929 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-06 00:25:26.878013 (Thread-4): Compiling model.github.stg_github_issue_label
2020-05-06 00:25:26.884187 (Thread-3): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-06 00:25:26.885627 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:25:26.886830 (Thread-4): finished collecting timing info
2020-05-06 00:25:26.891624 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:25:26.892871 (Thread-4): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-06 00:25:26.975179 (Thread-2): finished collecting timing info
2020-05-06 00:25:26.976312 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097e8c90>]}
2020-05-06 00:25:26.976696 (Thread-2): 17:25:26 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.36s]
2020-05-06 00:25:26.976919 (Thread-2): Finished running node model.github.stg_github_card
2020-05-06 00:25:26.977131 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-06 00:25:26.977347 (Thread-2): 17:25:26 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-06 00:25:26.977741 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:25:26.977890 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-06 00:25:26.978038 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-06 00:25:26.986867 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:25:26.987294 (Thread-2): finished collecting timing info
2020-05-06 00:25:26.992055 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:25:26.992431 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-06 00:25:27.372025 (Thread-4): finished collecting timing info
2020-05-06 00:25:27.372887 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109772110>]}
2020-05-06 00:25:27.373184 (Thread-4): 17:25:27 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.49s]
2020-05-06 00:25:27.373351 (Thread-4): Finished running node model.github.stg_github_issue_label
2020-05-06 00:25:27.373521 (Thread-4): Began running node model.github.stg_github_issue_label_history
2020-05-06 00:25:27.373694 (Thread-4): 17:25:27 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-06 00:25:27.374010 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:25:27.374131 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-06 00:25:27.374254 (Thread-4): Compiling model.github.stg_github_issue_label_history
2020-05-06 00:25:27.383633 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:25:27.386602 (Thread-1): finished collecting timing info
2020-05-06 00:25:27.387212 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086fe090>]}
2020-05-06 00:25:27.387458 (Thread-1): 17:25:27 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.65s]
2020-05-06 00:25:27.387631 (Thread-4): finished collecting timing info
2020-05-06 00:25:27.393056 (Thread-1): Finished running node model.github.stg_github_user
2020-05-06 00:25:27.393233 (Thread-1): Began running node model.github.stg_github_issue_merged
2020-05-06 00:25:27.393370 (Thread-1): 17:25:27 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-06 00:25:27.394122 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:25:27.394669 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:25:27.394788 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-06 00:25:27.394878 (Thread-1): Compiling model.github.stg_github_issue_merged
2020-05-06 00:25:27.401939 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:25:27.402319 (Thread-4): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-06 00:25:27.403210 (Thread-1): finished collecting timing info
2020-05-06 00:25:27.407421 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:25:27.407896 (Thread-1): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-06 00:25:27.417439 (Thread-3): finished collecting timing info
2020-05-06 00:25:27.418198 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad4efd0>]}
2020-05-06 00:25:27.418428 (Thread-3): 17:25:27 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.56s]
2020-05-06 00:25:27.418546 (Thread-3): Finished running node model.github.stg_github_issue_assignee
2020-05-06 00:25:27.418665 (Thread-3): Began running node model.github.stg_github_project
2020-05-06 00:25:27.418783 (Thread-3): 17:25:27 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-06 00:25:27.419020 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:25:27.419105 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-06 00:25:27.419189 (Thread-3): Compiling model.github.stg_github_project
2020-05-06 00:25:27.425980 (Thread-3): Writing injected SQL for node "model.github.stg_github_project"
2020-05-06 00:25:27.426342 (Thread-3): finished collecting timing info
2020-05-06 00:25:27.430825 (Thread-3): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-06 00:25:27.431458 (Thread-3): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-06 00:25:27.763159 (Thread-2): finished collecting timing info
2020-05-06 00:25:27.764062 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad34650>]}
2020-05-06 00:25:27.764366 (Thread-2): 17:25:27 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.79s]
2020-05-06 00:25:27.764537 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-06 00:25:27.764708 (Thread-2): Began running node model.github.stg_github_pull_request
2020-05-06 00:25:27.764882 (Thread-2): 17:25:27 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-06 00:25:27.765209 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:25:27.765331 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-06 00:25:27.765452 (Thread-2): Compiling model.github.stg_github_pull_request
2020-05-06 00:25:27.773609 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:25:27.774043 (Thread-2): finished collecting timing info
2020-05-06 00:25:27.778820 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:25:27.779192 (Thread-2): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-06 00:25:27.973176 (Thread-3): finished collecting timing info
2020-05-06 00:25:27.974048 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096aeb90>]}
2020-05-06 00:25:27.974352 (Thread-3): 17:25:27 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.55s]
2020-05-06 00:25:27.974522 (Thread-3): Finished running node model.github.stg_github_project
2020-05-06 00:25:27.974698 (Thread-3): Began running node model.github.stg_github_repository
2020-05-06 00:25:27.974874 (Thread-3): 17:25:27 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-06 00:25:27.975202 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:25:27.975489 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-06 00:25:27.975614 (Thread-3): Compiling model.github.stg_github_repository
2020-05-06 00:25:27.983371 (Thread-3): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-06 00:25:27.983778 (Thread-3): finished collecting timing info
2020-05-06 00:25:27.988366 (Thread-3): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-06 00:25:27.988750 (Thread-3): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-06 00:25:28.110470 (Thread-1): finished collecting timing info
2020-05-06 00:25:28.111378 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad44d90>]}
2020-05-06 00:25:28.111687 (Thread-1): 17:25:28 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 0.72s]
2020-05-06 00:25:28.111857 (Thread-1): Finished running node model.github.stg_github_issue_merged
2020-05-06 00:25:28.112032 (Thread-1): Began running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:25:28.112205 (Thread-1): 17:25:28 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-06 00:25:28.112528 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:25:28.112649 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-06 00:25:28.112777 (Thread-1): Compiling model.github.stg_github_requested_reviewer_history
2020-05-06 00:25:28.121014 (Thread-1): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:25:28.121433 (Thread-1): finished collecting timing info
2020-05-06 00:25:28.127156 (Thread-1): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:25:28.127567 (Thread-1): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-06 00:25:28.327418 (Thread-2): finished collecting timing info
2020-05-06 00:25:28.328382 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acb4b90>]}
2020-05-06 00:25:28.328716 (Thread-2): 17:25:28 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.56s]
2020-05-06 00:25:28.328976 (Thread-2): Finished running node model.github.stg_github_pull_request
2020-05-06 00:25:28.329165 (Thread-2): Began running node model.github.stg_github_milestone
2020-05-06 00:25:28.329348 (Thread-2): 17:25:28 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-06 00:25:28.329702 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:25:28.329931 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-06 00:25:28.330099 (Thread-2): Compiling model.github.stg_github_milestone
2020-05-06 00:25:28.337800 (Thread-2): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-06 00:25:28.338275 (Thread-2): finished collecting timing info
2020-05-06 00:25:28.342787 (Thread-2): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-06 00:25:28.343151 (Thread-2): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-06 00:25:28.447529 (Thread-4): finished collecting timing info
2020-05-06 00:25:28.448797 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad6ea50>]}
2020-05-06 00:25:28.450066 (Thread-4): 17:25:28 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 1.07s]
2020-05-06 00:25:28.450437 (Thread-4): Finished running node model.github.stg_github_issue_label_history
2020-05-06 00:25:28.450635 (Thread-4): Began running node model.github.stg_github_issue_comment
2020-05-06 00:25:28.450820 (Thread-4): 17:25:28 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-06 00:25:28.451169 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:25:28.451948 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-06 00:25:28.452837 (Thread-4): Compiling model.github.stg_github_issue_comment
2020-05-06 00:25:28.461387 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:25:28.462420 (Thread-4): finished collecting timing info
2020-05-06 00:25:28.467142 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:25:28.467530 (Thread-4): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-06 00:25:28.659309 (Thread-3): finished collecting timing info
2020-05-06 00:25:28.660512 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad1b390>]}
2020-05-06 00:25:28.660899 (Thread-3): 17:25:28 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.68s]
2020-05-06 00:25:28.661110 (Thread-3): Finished running node model.github.stg_github_repository
2020-05-06 00:25:28.661327 (Thread-3): Began running node model.github.issue_close_stack
2020-05-06 00:25:28.661838 (Thread-3): 17:25:28 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-06 00:25:28.662235 (Thread-3): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:25:28.662360 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-06 00:25:28.662480 (Thread-3): Compiling model.github.issue_close_stack
2020-05-06 00:25:28.672012 (Thread-3): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-06 00:25:28.672402 (Thread-3): finished collecting timing info
2020-05-06 00:25:28.676876 (Thread-3): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-06 00:25:28.677278 (Thread-3): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-06 00:25:28.701107 (Thread-1): finished collecting timing info
2020-05-06 00:25:28.701865 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972ea50>]}
2020-05-06 00:25:28.702128 (Thread-1): 17:25:28 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.59s]
2020-05-06 00:25:28.702274 (Thread-1): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:25:28.702418 (Thread-1): Began running node model.github.issue_status_windows
2020-05-06 00:25:28.702562 (Thread-1): 17:25:28 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-06 00:25:28.702963 (Thread-1): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:25:28.703081 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-06 00:25:28.703189 (Thread-1): Compiling model.github.issue_status_windows
2020-05-06 00:25:28.711398 (Thread-1): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-06 00:25:28.711780 (Thread-1): finished collecting timing info
2020-05-06 00:25:28.716052 (Thread-1): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-06 00:25:28.716368 (Thread-1): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-06 00:25:28.858243 (Thread-2): finished collecting timing info
2020-05-06 00:25:28.859282 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad1b5d0>]}
2020-05-06 00:25:28.859647 (Thread-2): 17:25:28 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.53s]
2020-05-06 00:25:28.859856 (Thread-2): Finished running node model.github.stg_github_milestone
2020-05-06 00:25:28.860093 (Thread-2): Began running node model.github.issue_labels
2020-05-06 00:25:28.860434 (Thread-2): 17:25:28 | 19 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-06 00:25:28.860980 (Thread-2): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:25:28.861127 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-06 00:25:28.861254 (Thread-2): Compiling model.github.issue_labels
2020-05-06 00:25:28.869245 (Thread-2): Writing injected SQL for node "model.github.issue_labels"
2020-05-06 00:25:28.869653 (Thread-2): finished collecting timing info
2020-05-06 00:25:28.875375 (Thread-2): Writing runtime SQL for node "model.github.issue_labels"
2020-05-06 00:25:28.875831 (Thread-2): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-06 00:25:29.065117 (Thread-4): finished collecting timing info
2020-05-06 00:25:29.066005 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acaed50>]}
2020-05-06 00:25:29.066313 (Thread-4): 17:25:29 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.61s]
2020-05-06 00:25:29.066483 (Thread-4): Finished running node model.github.stg_github_issue_comment
2020-05-06 00:25:29.066660 (Thread-4): Began running node model.github.issue_assignees
2020-05-06 00:25:29.066833 (Thread-4): 17:25:29 | 20 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-06 00:25:29.067156 (Thread-4): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:25:29.067277 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-06 00:25:29.067399 (Thread-4): Compiling model.github.issue_assignees
2020-05-06 00:25:29.109157 (Thread-4): Writing injected SQL for node "model.github.issue_assignees"
2020-05-06 00:25:29.109669 (Thread-4): finished collecting timing info
2020-05-06 00:25:29.115124 (Thread-4): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-06 00:25:29.115552 (Thread-4): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-06 00:25:29.247299 (Thread-1): finished collecting timing info
2020-05-06 00:25:29.248337 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acba490>]}
2020-05-06 00:25:29.248706 (Thread-1): 17:25:29 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.55s]
2020-05-06 00:25:29.248912 (Thread-1): Finished running node model.github.issue_status_windows
2020-05-06 00:25:29.249121 (Thread-1): Began running node model.github.pull_request_reviewers
2020-05-06 00:25:29.249333 (Thread-1): 17:25:29 | 21 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-06 00:25:29.249727 (Thread-1): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:25:29.250148 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-06 00:25:29.250340 (Thread-1): Compiling model.github.pull_request_reviewers
2020-05-06 00:25:29.259974 (Thread-1): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:25:29.260435 (Thread-1): finished collecting timing info
2020-05-06 00:25:29.265210 (Thread-1): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:25:29.265659 (Thread-1): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-06 00:25:29.381232 (Thread-3): finished collecting timing info
2020-05-06 00:25:29.382257 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac80450>]}
2020-05-06 00:25:29.382615 (Thread-3): 17:25:29 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.72s]
2020-05-06 00:25:29.382826 (Thread-3): Finished running node model.github.issue_close_stack
2020-05-06 00:25:29.382998 (Thread-3): Began running node model.github.issue_blocked_time
2020-05-06 00:25:29.383393 (Thread-3): 17:25:29 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-06 00:25:29.383772 (Thread-3): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:25:29.383902 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-06 00:25:29.384029 (Thread-3): Compiling model.github.issue_blocked_time
2020-05-06 00:25:29.392154 (Thread-3): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-06 00:25:29.392559 (Thread-3): finished collecting timing info
2020-05-06 00:25:29.397307 (Thread-3): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-06 00:25:29.397740 (Thread-3): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-06 00:25:29.471314 (Thread-2): finished collecting timing info
2020-05-06 00:25:29.472174 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096aed10>]}
2020-05-06 00:25:29.472476 (Thread-2): 17:25:29 | 19 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.61s]
2020-05-06 00:25:29.472647 (Thread-2): Finished running node model.github.issue_labels
2020-05-06 00:25:29.472816 (Thread-2): Began running node model.github.pull_request_times
2020-05-06 00:25:29.472989 (Thread-2): 17:25:29 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-06 00:25:29.473313 (Thread-2): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:25:29.473435 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-06 00:25:29.473557 (Thread-2): Compiling model.github.pull_request_times
2020-05-06 00:25:29.486708 (Thread-2): Writing injected SQL for node "model.github.pull_request_times"
2020-05-06 00:25:29.487080 (Thread-2): finished collecting timing info
2020-05-06 00:25:29.491595 (Thread-2): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-06 00:25:29.492168 (Thread-2): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-06 00:25:29.793626 (Thread-1): finished collecting timing info
2020-05-06 00:25:29.794684 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acea390>]}
2020-05-06 00:25:29.795166 (Thread-1): 17:25:29 | 21 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.54s]
2020-05-06 00:25:29.795408 (Thread-1): Finished running node model.github.pull_request_reviewers
2020-05-06 00:25:29.795627 (Thread-1): Began running node model.github.issue_inbox_time
2020-05-06 00:25:29.795849 (Thread-1): 17:25:29 | 24 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-06 00:25:29.796215 (Thread-1): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:25:29.796339 (Thread-1): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-06 00:25:29.796462 (Thread-1): Compiling model.github.issue_inbox_time
2020-05-06 00:25:29.804932 (Thread-1): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-06 00:25:29.805380 (Thread-1): finished collecting timing info
2020-05-06 00:25:29.810302 (Thread-1): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-06 00:25:29.812186 (Thread-1): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-06 00:25:29.822076 (Thread-4): finished collecting timing info
2020-05-06 00:25:29.822727 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acf7a90>]}
2020-05-06 00:25:29.822956 (Thread-4): 17:25:29 | 20 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.76s]
2020-05-06 00:25:29.823082 (Thread-4): Finished running node model.github.issue_assignees
2020-05-06 00:25:29.823207 (Thread-4): Began running node model.github.issue_projects
2020-05-06 00:25:29.823336 (Thread-4): 17:25:29 | 25 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-06 00:25:29.823664 (Thread-4): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:25:29.823765 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-06 00:25:29.823856 (Thread-4): Compiling model.github.issue_projects
2020-05-06 00:25:29.831967 (Thread-4): Writing injected SQL for node "model.github.issue_projects"
2020-05-06 00:25:29.832346 (Thread-4): finished collecting timing info
2020-05-06 00:25:29.836927 (Thread-4): Writing runtime SQL for node "model.github.issue_projects"
2020-05-06 00:25:29.838812 (Thread-4): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-06 00:25:30.081492 (Thread-2): finished collecting timing info
2020-05-06 00:25:30.082524 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac6ec50>]}
2020-05-06 00:25:30.082887 (Thread-2): 17:25:30 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.61s]
2020-05-06 00:25:30.083092 (Thread-2): Finished running node model.github.pull_request_times
2020-05-06 00:25:30.083342 (Thread-2): Began running node model.github.issue_open_length
2020-05-06 00:25:30.083560 (Thread-2): 17:25:30 | 26 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-06 00:25:30.083932 (Thread-2): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:25:30.084054 (Thread-2): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-06 00:25:30.084175 (Thread-2): Compiling model.github.issue_open_length
2020-05-06 00:25:30.092563 (Thread-2): Writing injected SQL for node "model.github.issue_open_length"
2020-05-06 00:25:30.092993 (Thread-2): finished collecting timing info
2020-05-06 00:25:30.097826 (Thread-2): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-06 00:25:30.098296 (Thread-2): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-06 00:25:30.104087 (Thread-3): finished collecting timing info
2020-05-06 00:25:30.104729 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acbfa10>]}
2020-05-06 00:25:30.105007 (Thread-3): 17:25:30 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.72s]
2020-05-06 00:25:30.105224 (Thread-3): Finished running node model.github.issue_blocked_time
2020-05-06 00:25:30.295993 (Thread-1): finished collecting timing info
2020-05-06 00:25:30.297069 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098b9fd0>]}
2020-05-06 00:25:30.297440 (Thread-1): 17:25:30 | 24 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.50s]
2020-05-06 00:25:30.297646 (Thread-1): Finished running node model.github.issue_inbox_time
2020-05-06 00:25:30.623002 (Thread-2): finished collecting timing info
2020-05-06 00:25:30.624078 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac915d0>]}
2020-05-06 00:25:30.624449 (Thread-2): 17:25:30 | 26 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.54s]
2020-05-06 00:25:30.624654 (Thread-2): Finished running node model.github.issue_open_length
2020-05-06 00:25:30.625124 (Thread-3): Began running node model.github.github_pull_requests
2020-05-06 00:25:30.625346 (Thread-3): 17:25:30 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-06 00:25:30.625690 (Thread-3): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:25:30.625812 (Thread-3): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-06 00:25:30.625933 (Thread-3): Compiling model.github.github_pull_requests
2020-05-06 00:25:30.643818 (Thread-3): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-06 00:25:30.644227 (Thread-3): finished collecting timing info
2020-05-06 00:25:30.648327 (Thread-3): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-06 00:25:30.648686 (Thread-3): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-06 00:25:30.994937 (Thread-4): finished collecting timing info
2020-05-06 00:25:30.996151 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10977e110>]}
2020-05-06 00:25:30.996522 (Thread-4): 17:25:30 | 25 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 1.17s]
2020-05-06 00:25:30.996736 (Thread-4): Finished running node model.github.issue_projects
2020-05-06 00:25:30.997242 (Thread-2): Began running node model.github.github_issues
2020-05-06 00:25:30.997452 (Thread-2): 17:25:30 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-06 00:25:30.997792 (Thread-2): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:25:30.997912 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-06 00:25:30.998032 (Thread-2): Compiling model.github.github_issues
2020-05-06 00:25:31.016203 (Thread-2): Writing injected SQL for node "model.github.github_issues"
2020-05-06 00:25:31.016612 (Thread-2): finished collecting timing info
2020-05-06 00:25:31.020942 (Thread-2): Writing runtime SQL for node "model.github.github_issues"
2020-05-06 00:25:31.021283 (Thread-2): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-06 00:25:31.602087 (Thread-3): finished collecting timing info
2020-05-06 00:25:31.603198 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10951f650>]}
2020-05-06 00:25:31.603533 (Thread-3): 17:25:31 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 0.98s]
2020-05-06 00:25:31.603703 (Thread-3): Finished running node model.github.github_pull_requests
2020-05-06 00:25:31.989019 (Thread-2): finished collecting timing info
2020-05-06 00:25:31.990082 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097a1710>]}
2020-05-06 00:25:31.990449 (Thread-2): 17:25:31 | 28 of 29 OK created view model dbt_erik.github_issues................ [CREATE VIEW in 0.99s]
2020-05-06 00:25:31.990657 (Thread-2): Finished running node model.github.github_issues
2020-05-06 00:25:31.991139 (Thread-4): Began running node model.github.issues_and_prs_per_month
2020-05-06 00:25:31.991409 (Thread-4): 17:25:31 | 29 of 29 START view model dbt_erik.issues_and_prs_per_month.......... [RUN]
2020-05-06 00:25:31.991739 (Thread-4): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:25:31.991859 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_projects).
2020-05-06 00:25:31.991978 (Thread-4): Compiling model.github.issues_and_prs_per_month
2020-05-06 00:25:32.001999 (Thread-4): Writing injected SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:25:32.002434 (Thread-4): finished collecting timing info
2020-05-06 00:25:32.006941 (Thread-4): Writing runtime SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:25:32.007399 (Thread-4): On model.github.issues_and_prs_per_month: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from pull_requests
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from prs_opened_per_month 
full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  );

2020-05-06 00:25:33.201690 (Thread-4): finished collecting timing info
2020-05-06 00:25:33.202681 (Thread-4): Database Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  Unrecognized name: issues_per_month at [83:12]
  compiled SQL at target/run/github/issues_and_prs_per_month.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 80, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 212, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 339, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3098, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3085, in done
    timeout=timeout,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1287, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 556, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/digital-arbor-400/queries/95a019b1-7037-4fb8-a00a-8a48e41e977d?maxResults=0&location=US: Unrecognized name: issues_per_month at [83:12]

(job ID: 95a019b1-7037-4fb8-a00a-8a48e41e977d)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */
   2:
   3:
   4:  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
   5:  OPTIONS()
   6:  as (
   7:    with github_issues as (
   8:
   9:    select *
  10:    from `digital-arbor-400`.`dbt_erik`.`github_issues`
  11:
  12:), pull_requests as (
  13:
  14:    select *
  15:    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  16:
  17:), issues_opened_per_month as (
  18:
  19:   select 
  20:      date_trunc(date(created_at), month) as month, 
  21:      count(*) as number_issues_opened,
  22:      avg(days_issue_opened) as average_length_issue_open,
  23:      max(days_issue_opened) as longest_length_issue_open
  24:    from github_issues
  25:    group by 1
  26:
  27:), issues_closed_per_month as (
  28:
  29:   select 
  30:      date_trunc(date(closed_at), month) as month, 
  31:      count(*) as number_issues_closed
  32:    from github_issues
  33:    where closed_at is not null
  34:    group by 1
  35:
  36:), prs_opened_per_month as (
  37:
  38:   select 
  39:      date_trunc(date(created_at), month) as month, 
  40:      count(*) as number_prs_opened,
  41:      avg(days_issue_opened) as average_length_pr_open,
  42:      max(days_issue_opened) as longest_length_pr_open
  43:    from pull_requests
  44:    group by 1
  45:
  46:), prs_merged_per_month as (
  47:
  48:   select 
  49:      date_trunc(date(merged_at), month) as month, 
  50:      count(*) as number_prs_merged
  51:    from pull_requests
  52:    group by 1
  53:
  54:), issues_per_month as (
  55:
  56:    select 
  57:      coalesce(issues_opened_per_month.month, 
  58:        issues_closed_per_month.month
  59:      ) as month,
  60:      number_issues_opened,
  61:      number_issues_closed,      
  62:      average_length_issue_open,
  63:      longest_length_issue_open
  64:    from issues_opened_per_month
  65:    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month
  66:
  67:), prs_per_month as (
  68:
  69:    select 
  70:      coalesce(prs_opened_per_month.month, 
  71:        prs_merged_per_month.month
  72:      ) as month,
  73:      number_prs_opened,
  74:      number_prs_merged,
  75:      average_length_pr_open,
  76:      longest_length_pr_open
  77:    from prs_opened_per_month
  78:    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  79:
  80:)
  81:
  82:select 
  83:  coalesce(issues_per_month.month, 
  84:    prs_per_month.month
  85:  ) as month,
  86:  coalesce(number_issues_opened, 0) as number_issues_opened,
  87:  coalesce(number_issues_closed, 0) as number_issues_closed,
  88:  average_length_issue_open,
  89:  longest_length_issue_open,
  90:  coalesce(number_prs_opened, 0) as number_prs_opened,
  91:  coalesce(number_prs_merged, 0) as number_prs_merged,
  92:  average_length_pr_open,
  93:  longest_length_pr_open
  94:from prs_opened_per_month 
  95:full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month
  96:  );
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 99, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/clients/jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 220, in execute
    fetch=fetch
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 221, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 214, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 350, in _retry_and_handle
    deadline=None)
  File "/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 84, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.16.1_1/libexec/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 72, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
  Unrecognized name: issues_per_month at [83:12]
  compiled SQL at target/run/github/issues_and_prs_per_month.sql
2020-05-06 00:25:33.207389 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c331e3-01a6-4540-8925-01bd649b8c83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097a78d0>]}
2020-05-06 00:25:33.897914 (Thread-4): 17:25:33 | 29 of 29 ERROR creating view model dbt_erik.issues_and_prs_per_month. [ERROR in 1.22s]
2020-05-06 00:25:33.898293 (Thread-4): Finished running node model.github.issues_and_prs_per_month
2020-05-06 00:25:33.966283 (MainThread): 17:25:33 | 
2020-05-06 00:25:33.966626 (MainThread): 17:25:33 | Finished running 29 view models in 9.37s.
2020-05-06 00:25:33.966941 (MainThread): Connection 'master' was left open.
2020-05-06 00:25:33.967084 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-06 00:25:33.967210 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-06 00:25:33.967330 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-06 00:25:33.967447 (MainThread): Connection 'model.github.issues_and_prs_per_month' was left open.
2020-05-06 00:25:34.037273 (MainThread): 
2020-05-06 00:25:34.037436 (MainThread): Completed with 1 error and 0 warnings:
2020-05-06 00:25:34.037570 (MainThread): 
2020-05-06 00:25:34.037684 (MainThread): Database Error in model issues_and_prs_per_month (models/issues_and_prs_per_month.sql)
2020-05-06 00:25:34.037773 (MainThread):   Unrecognized name: issues_per_month at [83:12]
2020-05-06 00:25:34.037875 (MainThread):   compiled SQL at target/run/github/issues_and_prs_per_month.sql
2020-05-06 00:25:34.038033 (MainThread): 
Done. PASS=28 WARN=0 ERROR=1 SKIP=0 TOTAL=29
2020-05-06 00:25:34.038226 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097cec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10985ee90>]}
2020-05-06 00:25:34.038403 (MainThread): Flushing usage events
2020-05-06 00:26:25.764306 (MainThread): Running with dbt=0.16.1
2020-05-06 00:26:25.907870 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/erikm/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-05-06 00:26:25.908988 (MainThread): Tracking: tracking
2020-05-06 00:26:25.916050 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7a1150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7b2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7b2610>]}
2020-05-06 00:26:25.938202 (MainThread): Partial parsing not enabled
2020-05-06 00:26:25.940178 (MainThread): Parsing macros/core.sql
2020-05-06 00:26:25.944636 (MainThread): Parsing macros/materializations/helpers.sql
2020-05-06 00:26:25.953395 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-05-06 00:26:25.955412 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-05-06 00:26:25.974891 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-05-06 00:26:26.011605 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-05-06 00:26:26.035419 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-05-06 00:26:26.037459 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-05-06 00:26:26.044799 (MainThread): Parsing macros/materializations/common/merge.sql
2020-05-06 00:26:26.059812 (MainThread): Parsing macros/materializations/table/table.sql
2020-05-06 00:26:26.067338 (MainThread): Parsing macros/materializations/view/view.sql
2020-05-06 00:26:26.074132 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-05-06 00:26:26.079534 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-05-06 00:26:26.080536 (MainThread): Parsing macros/etc/query.sql
2020-05-06 00:26:26.081657 (MainThread): Parsing macros/etc/is_incremental.sql
2020-05-06 00:26:26.083392 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-05-06 00:26:26.086037 (MainThread): Parsing macros/etc/datetime.sql
2020-05-06 00:26:26.096426 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-05-06 00:26:26.098609 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-05-06 00:26:26.099753 (MainThread): Parsing macros/adapters/common.sql
2020-05-06 00:26:26.145249 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-05-06 00:26:26.146528 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-05-06 00:26:26.147507 (MainThread): Parsing macros/schema_tests/unique.sql
2020-05-06 00:26:26.149032 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-05-06 00:26:26.151654 (MainThread): Parsing macros/etc.sql
2020-05-06 00:26:26.152356 (MainThread): Parsing macros/catalog.sql
2020-05-06 00:26:26.160710 (MainThread): Parsing macros/adapters.sql
2020-05-06 00:26:26.183693 (MainThread): Parsing macros/materializations/seed.sql
2020-05-06 00:26:26.185889 (MainThread): Parsing macros/materializations/view.sql
2020-05-06 00:26:26.187453 (MainThread): Parsing macros/materializations/table.sql
2020-05-06 00:26:26.199135 (MainThread): Parsing macros/materializations/incremental.sql
2020-05-06 00:26:26.213686 (MainThread): Parsing macros/materializations/snapshot.sql
2020-05-06 00:26:26.233903 (MainThread): Partial parsing not enabled
2020-05-06 00:26:26.268736 (MainThread): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:26:26.268898 (MainThread): Opening a new connection, currently in state init
2020-05-06 00:26:26.293353 (MainThread): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:26:26.293484 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.300708 (MainThread): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:26:26.300830 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.315100 (MainThread): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:26:26.315222 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.322400 (MainThread): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:26:26.322530 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.330102 (MainThread): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:26:26.330239 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.336502 (MainThread): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:26:26.336613 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.342593 (MainThread): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:26:26.342712 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.349278 (MainThread): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:26:26.349385 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.355073 (MainThread): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:26:26.355182 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.363332 (MainThread): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:26:26.363459 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.370205 (MainThread): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:26:26.370314 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.376253 (MainThread): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:26:26.376371 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.386202 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:26:26.386331 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.392953 (MainThread): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:26:26.393084 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.398895 (MainThread): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:26:26.399005 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.405051 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:26:26.405169 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.411282 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:26:26.411388 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.417393 (MainThread): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:26:26.417514 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.423195 (MainThread): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:26:26.423382 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.429775 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:26:26.429902 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.435379 (MainThread): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:26:26.435484 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.441503 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:26:26.441622 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.447675 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:26:26.447798 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.453445 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:26:26.453549 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.459839 (MainThread): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:26:26.459968 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.465725 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:26:26.465829 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.471521 (MainThread): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:26:26.471632 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.477256 (MainThread): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:26:26.477444 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.611420 (MainThread): WARNING: Found documentation for resource "pull_request" which was not found or is disabled
2020-05-06 00:26:26.864601 (MainThread): Found 29 models, 0 tests, 0 snapshots, 0 analyses, 141 macros, 0 operations, 0 seed files, 16 sources
2020-05-06 00:26:26.882784 (MainThread): 
2020-05-06 00:26:26.883122 (MainThread): Acquiring new bigquery connection "master".
2020-05-06 00:26:26.883213 (MainThread): Opening a new connection, currently in state closed
2020-05-06 00:26:26.937585 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_digital-arbor-400".
2020-05-06 00:26:26.937984 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-05-06 00:26:27.937306 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_digital-arbor-400_dbt_erik".
2020-05-06 00:26:27.937697 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_digital-arbor-400).
2020-05-06 00:26:27.938017 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-05-06 00:26:28.137784 (MainThread): 17:26:28 | Concurrency: 4 threads (target='dev')
2020-05-06 00:26:28.137959 (MainThread): 17:26:28 | 
2020-05-06 00:26:28.139881 (Thread-1): Began running node model.github.stg_github_issue
2020-05-06 00:26:28.140052 (Thread-1): 17:26:28 | 1 of 29 START view model dbt_erik.stg_github_issue................... [RUN]
2020-05-06 00:26:28.140311 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue".
2020-05-06 00:26:28.140399 (Thread-1): Re-using an available connection from the pool (formerly list_digital-arbor-400_dbt_erik).
2020-05-06 00:26:28.140628 (Thread-2): Began running node model.github.stg_github_card
2020-05-06 00:26:28.140747 (Thread-1): Compiling model.github.stg_github_issue
2020-05-06 00:26:28.140825 (Thread-3): Began running node model.github.stg_github_issue_closed_history
2020-05-06 00:26:28.140973 (Thread-4): Began running node model.github.stg_github_issue_project_history
2020-05-06 00:26:28.141090 (Thread-2): 17:26:28 | 2 of 29 START view model dbt_erik.stg_github_card.................... [RUN]
2020-05-06 00:26:28.146926 (Thread-3): 17:26:28 | 3 of 29 START view model dbt_erik.stg_github_issue_closed_history.... [RUN]
2020-05-06 00:26:28.155794 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue"
2020-05-06 00:26:28.155969 (Thread-4): 17:26:28 | 4 of 29 START view model dbt_erik.stg_github_issue_project_history... [RUN]
2020-05-06 00:26:28.156254 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_card".
2020-05-06 00:26:28.156705 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_closed_history".
2020-05-06 00:26:28.157300 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_project_history".
2020-05-06 00:26:28.157689 (Thread-2): Opening a new connection, currently in state init
2020-05-06 00:26:28.157851 (Thread-3): Opening a new connection, currently in state init
2020-05-06 00:26:28.158013 (Thread-4): Opening a new connection, currently in state init
2020-05-06 00:26:28.158105 (Thread-1): finished collecting timing info
2020-05-06 00:26:28.158375 (Thread-2): Compiling model.github.stg_github_card
2020-05-06 00:26:28.158469 (Thread-3): Compiling model.github.stg_github_issue_closed_history
2020-05-06 00:26:28.158555 (Thread-4): Compiling model.github.stg_github_issue_project_history
2020-05-06 00:26:28.183049 (Thread-2): Writing injected SQL for node "model.github.stg_github_card"
2020-05-06 00:26:28.201095 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:26:28.213113 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:26:28.238703 (Thread-2): finished collecting timing info
2020-05-06 00:26:28.268170 (Thread-3): finished collecting timing info
2020-05-06 00:26:28.305235 (Thread-4): finished collecting timing info
2020-05-06 00:26:28.425945 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue"
2020-05-06 00:26:28.490289 (Thread-2): Writing runtime SQL for node "model.github.stg_github_card"
2020-05-06 00:26:28.510645 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_closed_history"
2020-05-06 00:26:28.519903 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_project_history"
2020-05-06 00:26:28.520220 (Thread-1): On model.github.stg_github_issue: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked,
      milestone_id,
      number,
      pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
  );

2020-05-06 00:26:28.522936 (Thread-2): On model.github.stg_github_card: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_card"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  OPTIONS()
  as (
    with card as (

    select *
    from `digital-arbor-400`.`github`.`card`

), fields as (

    select 
      id,
      archived,
      updated_at,
      is_deleted
    from card
)

select *
from fields
  );

2020-05-06 00:26:28.523148 (Thread-3): On model.github.stg_github_issue_closed_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_closed_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  OPTIONS()
  as (
    with issue_closed_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed
    from issue_closed_history
)

select *
from fields
  );

2020-05-06 00:26:28.525708 (Thread-4): On model.github.stg_github_issue_project_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_project_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_project_history`

), fields as (

    select 
      issue_id,
      project_id,
      column_name,
      removed,
      updated_at,
      card_id
    from issue_project_history
)

select *
from fields
  );

2020-05-06 00:26:29.258553 (Thread-1): finished collecting timing info
2020-05-06 00:26:29.259645 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9c7810>]}
2020-05-06 00:26:29.260031 (Thread-1): 17:26:29 | 1 of 29 OK created view model dbt_erik.stg_github_issue.............. [CREATE VIEW in 1.12s]
2020-05-06 00:26:29.260252 (Thread-1): Finished running node model.github.stg_github_issue
2020-05-06 00:26:29.260465 (Thread-1): Began running node model.github.stg_github_user
2020-05-06 00:26:29.260814 (Thread-1): 17:26:29 | 5 of 29 START view model dbt_erik.stg_github_user.................... [RUN]
2020-05-06 00:26:29.261168 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_user".
2020-05-06 00:26:29.261291 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue).
2020-05-06 00:26:29.261411 (Thread-1): Compiling model.github.stg_github_user
2020-05-06 00:26:29.269910 (Thread-1): Writing injected SQL for node "model.github.stg_github_user"
2020-05-06 00:26:29.270354 (Thread-1): finished collecting timing info
2020-05-06 00:26:29.274968 (Thread-1): Writing runtime SQL for node "model.github.stg_github_user"
2020-05-06 00:26:29.275355 (Thread-1): On model.github.stg_github_user: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_user"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_user`
  OPTIONS()
  as (
    with user as (

    select *
    from `digital-arbor-400`.`github`.`user`

), fields as (

    select
      id,
      login
    from user
)

select *
from fields
  );

2020-05-06 00:26:29.404348 (Thread-4): finished collecting timing info
2020-05-06 00:26:29.405408 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae80a90>]}
2020-05-06 00:26:29.405784 (Thread-4): 17:26:29 | 4 of 29 OK created view model dbt_erik.stg_github_issue_project_history [CREATE VIEW in 1.25s]
2020-05-06 00:26:29.405997 (Thread-4): Finished running node model.github.stg_github_issue_project_history
2020-05-06 00:26:29.406236 (Thread-4): Began running node model.github.stg_github_issue_assignee
2020-05-06 00:26:29.406546 (Thread-4): 17:26:29 | 6 of 29 START view model dbt_erik.stg_github_issue_assignee.......... [RUN]
2020-05-06 00:26:29.406907 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_assignee".
2020-05-06 00:26:29.407033 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_project_history).
2020-05-06 00:26:29.407154 (Thread-4): Compiling model.github.stg_github_issue_assignee
2020-05-06 00:26:29.415480 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:26:29.415942 (Thread-4): finished collecting timing info
2020-05-06 00:26:29.420864 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_assignee"
2020-05-06 00:26:29.422744 (Thread-4): On model.github.stg_github_issue_assignee: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_assignee"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
  );

2020-05-06 00:26:29.544945 (Thread-3): finished collecting timing info
2020-05-06 00:26:29.545978 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a97f7d0>]}
2020-05-06 00:26:29.546351 (Thread-3): 17:26:29 | 3 of 29 OK created view model dbt_erik.stg_github_issue_closed_history [CREATE VIEW in 1.39s]
2020-05-06 00:26:29.546562 (Thread-3): Finished running node model.github.stg_github_issue_closed_history
2020-05-06 00:26:29.546783 (Thread-3): Began running node model.github.stg_github_issue_label
2020-05-06 00:26:29.547181 (Thread-3): 17:26:29 | 7 of 29 START view model dbt_erik.stg_github_issue_label............. [RUN]
2020-05-06 00:26:29.547793 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_issue_label".
2020-05-06 00:26:29.547958 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_closed_history).
2020-05-06 00:26:29.548108 (Thread-3): Compiling model.github.stg_github_issue_label
2020-05-06 00:26:29.558201 (Thread-3): Writing injected SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:26:29.558655 (Thread-3): finished collecting timing info
2020-05-06 00:26:29.564050 (Thread-3): Writing runtime SQL for node "model.github.stg_github_issue_label"
2020-05-06 00:26:29.564474 (Thread-3): On model.github.stg_github_issue_label: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
  );

2020-05-06 00:26:29.598563 (Thread-2): finished collecting timing info
2020-05-06 00:26:29.600455 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a947690>]}
2020-05-06 00:26:29.601987 (Thread-2): 17:26:29 | 2 of 29 OK created view model dbt_erik.stg_github_card............... [CREATE VIEW in 1.44s]
2020-05-06 00:26:29.602371 (Thread-2): Finished running node model.github.stg_github_card
2020-05-06 00:26:29.602582 (Thread-2): Began running node model.github.stg_github_pull_request_review
2020-05-06 00:26:29.603167 (Thread-2): 17:26:29 | 8 of 29 START view model dbt_erik.stg_github_pull_request_review..... [RUN]
2020-05-06 00:26:29.603700 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_pull_request_review".
2020-05-06 00:26:29.603837 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_card).
2020-05-06 00:26:29.603966 (Thread-2): Compiling model.github.stg_github_pull_request_review
2020-05-06 00:26:29.612174 (Thread-2): Writing injected SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:26:29.612933 (Thread-2): finished collecting timing info
2020-05-06 00:26:29.617498 (Thread-2): Writing runtime SQL for node "model.github.stg_github_pull_request_review"
2020-05-06 00:26:29.617892 (Thread-2): On model.github.stg_github_pull_request_review: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request_review"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
  );

2020-05-06 00:26:29.908565 (Thread-1): finished collecting timing info
2020-05-06 00:26:29.909650 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9e8990>]}
2020-05-06 00:26:29.910023 (Thread-1): 17:26:29 | 5 of 29 OK created view model dbt_erik.stg_github_user............... [CREATE VIEW in 0.65s]
2020-05-06 00:26:29.910235 (Thread-1): Finished running node model.github.stg_github_user
2020-05-06 00:26:29.910447 (Thread-1): Began running node model.github.stg_github_issue_label_history
2020-05-06 00:26:29.910659 (Thread-1): 17:26:29 | 9 of 29 START view model dbt_erik.stg_github_issue_label_history..... [RUN]
2020-05-06 00:26:29.911019 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_issue_label_history".
2020-05-06 00:26:29.911140 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_user).
2020-05-06 00:26:29.911263 (Thread-1): Compiling model.github.stg_github_issue_label_history
2020-05-06 00:26:29.920609 (Thread-1): Writing injected SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:26:29.922129 (Thread-1): finished collecting timing info
2020-05-06 00:26:29.927217 (Thread-1): Writing runtime SQL for node "model.github.stg_github_issue_label_history"
2020-05-06 00:26:29.928436 (Thread-1): On model.github.stg_github_issue_label_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_label_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`github`.`issue_label_history`

), fields as (

    select 
      issue_id,
      updated_at,
      label,
      labeled
    from issue_label_history
)

select *
from fields
  );

2020-05-06 00:26:30.211091 (Thread-4): finished collecting timing info
2020-05-06 00:26:30.212735 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9c8c50>]}
2020-05-06 00:26:30.213805 (Thread-4): 17:26:30 | 6 of 29 OK created view model dbt_erik.stg_github_issue_assignee..... [CREATE VIEW in 0.81s]
2020-05-06 00:26:30.215006 (Thread-4): Finished running node model.github.stg_github_issue_assignee
2020-05-06 00:26:30.215385 (Thread-4): Began running node model.github.stg_github_issue_merged
2020-05-06 00:26:30.215877 (Thread-4): 17:26:30 | 10 of 29 START view model dbt_erik.stg_github_issue_merged........... [RUN]
2020-05-06 00:26:30.216460 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_merged".
2020-05-06 00:26:30.217167 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_assignee).
2020-05-06 00:26:30.217303 (Thread-4): Compiling model.github.stg_github_issue_merged
2020-05-06 00:26:30.225945 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:26:30.226438 (Thread-4): finished collecting timing info
2020-05-06 00:26:30.231122 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_merged"
2020-05-06 00:26:30.231514 (Thread-4): On model.github.stg_github_issue_merged: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_merged"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
  OPTIONS()
  as (
    with issue_merged as (

    select *
    from `digital-arbor-400`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
  );

2020-05-06 00:26:30.344906 (Thread-2): finished collecting timing info
2020-05-06 00:26:30.345771 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af72a90>]}
2020-05-06 00:26:30.346080 (Thread-2): 17:26:30 | 8 of 29 OK created view model dbt_erik.stg_github_pull_request_review [CREATE VIEW in 0.74s]
2020-05-06 00:26:30.346261 (Thread-2): Finished running node model.github.stg_github_pull_request_review
2020-05-06 00:26:30.346436 (Thread-2): Began running node model.github.stg_github_project
2020-05-06 00:26:30.346611 (Thread-2): 17:26:30 | 11 of 29 START view model dbt_erik.stg_github_project................ [RUN]
2020-05-06 00:26:30.347117 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_project".
2020-05-06 00:26:30.347612 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request_review).
2020-05-06 00:26:30.347972 (Thread-2): Compiling model.github.stg_github_project
2020-05-06 00:26:30.356059 (Thread-2): Writing injected SQL for node "model.github.stg_github_project"
2020-05-06 00:26:30.356570 (Thread-2): finished collecting timing info
2020-05-06 00:26:30.361170 (Thread-2): Writing runtime SQL for node "model.github.stg_github_project"
2020-05-06 00:26:30.361536 (Thread-2): On model.github.stg_github_project: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_project"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  OPTIONS()
  as (
    with project as (

    select *
    from `digital-arbor-400`.`github`.`project`

), fields as (

    select
      id,
      name
    from project
)

select *
from fields
  );

2020-05-06 00:26:30.474574 (Thread-3): finished collecting timing info
2020-05-06 00:26:30.475619 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa6e450>]}
2020-05-06 00:26:30.475999 (Thread-3): 17:26:30 | 7 of 29 OK created view model dbt_erik.stg_github_issue_label........ [CREATE VIEW in 0.93s]
2020-05-06 00:26:30.476211 (Thread-3): Finished running node model.github.stg_github_issue_label
2020-05-06 00:26:30.476423 (Thread-3): Began running node model.github.stg_github_pull_request
2020-05-06 00:26:30.476635 (Thread-3): 17:26:30 | 12 of 29 START view model dbt_erik.stg_github_pull_request........... [RUN]
2020-05-06 00:26:30.477011 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_pull_request".
2020-05-06 00:26:30.477132 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label).
2020-05-06 00:26:30.477254 (Thread-3): Compiling model.github.stg_github_pull_request
2020-05-06 00:26:30.486016 (Thread-3): Writing injected SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:26:30.486569 (Thread-3): finished collecting timing info
2020-05-06 00:26:30.493041 (Thread-3): Writing runtime SQL for node "model.github.stg_github_pull_request"
2020-05-06 00:26:30.493476 (Thread-3): On model.github.stg_github_pull_request: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_pull_request"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`
  OPTIONS()
  as (
    with pull_request as (

    select *
    from `digital-arbor-400`.`github`.`pull_request`

), fields as (

    select 
      issue_id,
      id,
      base_repo_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
  );

2020-05-06 00:26:30.728988 (Thread-1): finished collecting timing info
2020-05-06 00:26:30.730008 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aefdc90>]}
2020-05-06 00:26:30.730369 (Thread-1): 17:26:30 | 9 of 29 OK created view model dbt_erik.stg_github_issue_label_history [CREATE VIEW in 0.82s]
2020-05-06 00:26:30.730579 (Thread-1): Finished running node model.github.stg_github_issue_label_history
2020-05-06 00:26:30.730794 (Thread-1): Began running node model.github.stg_github_repository
2020-05-06 00:26:30.730982 (Thread-1): 17:26:30 | 13 of 29 START view model dbt_erik.stg_github_repository............. [RUN]
2020-05-06 00:26:30.731308 (Thread-1): Acquiring new bigquery connection "model.github.stg_github_repository".
2020-05-06 00:26:30.731432 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_issue_label_history).
2020-05-06 00:26:30.731555 (Thread-1): Compiling model.github.stg_github_repository
2020-05-06 00:26:30.740219 (Thread-1): Writing injected SQL for node "model.github.stg_github_repository"
2020-05-06 00:26:30.740777 (Thread-1): finished collecting timing info
2020-05-06 00:26:30.745496 (Thread-1): Writing runtime SQL for node "model.github.stg_github_repository"
2020-05-06 00:26:30.745914 (Thread-1): On model.github.stg_github_repository: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_repository"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_repository`
  OPTIONS()
  as (
    with repository as (

    select *
    from `digital-arbor-400`.`github`.`repository`

), fields as (

    select 
      id,
      full_name
    from repository
)

select *
from fields
  );

2020-05-06 00:26:30.902939 (Thread-2): finished collecting timing info
2020-05-06 00:26:30.903977 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9fed10>]}
2020-05-06 00:26:30.904347 (Thread-2): 17:26:30 | 11 of 29 OK created view model dbt_erik.stg_github_project........... [CREATE VIEW in 0.56s]
2020-05-06 00:26:30.904561 (Thread-2): Finished running node model.github.stg_github_project
2020-05-06 00:26:30.904772 (Thread-2): Began running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:26:30.904984 (Thread-2): 17:26:30 | 14 of 29 START view model dbt_erik.stg_github_requested_reviewer_history [RUN]
2020-05-06 00:26:30.905382 (Thread-2): Acquiring new bigquery connection "model.github.stg_github_requested_reviewer_history".
2020-05-06 00:26:30.905534 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_project).
2020-05-06 00:26:30.905657 (Thread-2): Compiling model.github.stg_github_requested_reviewer_history
2020-05-06 00:26:30.914560 (Thread-2): Writing injected SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:26:30.915038 (Thread-2): finished collecting timing info
2020-05-06 00:26:30.919717 (Thread-2): Writing runtime SQL for node "model.github.stg_github_requested_reviewer_history"
2020-05-06 00:26:30.920114 (Thread-2): On model.github.stg_github_requested_reviewer_history: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_requested_reviewer_history"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`
  OPTIONS()
  as (
    with requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id
    from requested_reviewer_history
)

select *
from fields
  );

2020-05-06 00:26:31.252848 (Thread-3): finished collecting timing info
2020-05-06 00:26:31.255508 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aae0510>]}
2020-05-06 00:26:31.256111 (Thread-3): 17:26:31 | 12 of 29 OK created view model dbt_erik.stg_github_pull_request...... [CREATE VIEW in 0.78s]
2020-05-06 00:26:31.261070 (Thread-4): finished collecting timing info
2020-05-06 00:26:31.261440 (Thread-3): Finished running node model.github.stg_github_pull_request
2020-05-06 00:26:31.262180 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae63f90>]}
2020-05-06 00:26:31.263433 (Thread-3): Began running node model.github.stg_github_milestone
2020-05-06 00:26:31.265186 (Thread-3): 17:26:31 | 15 of 29 START view model dbt_erik.stg_github_milestone.............. [RUN]
2020-05-06 00:26:31.265430 (Thread-4): 17:26:31 | 10 of 29 OK created view model dbt_erik.stg_github_issue_merged...... [CREATE VIEW in 1.05s]
2020-05-06 00:26:31.265725 (Thread-3): Acquiring new bigquery connection "model.github.stg_github_milestone".
2020-05-06 00:26:31.266204 (Thread-4): Finished running node model.github.stg_github_issue_merged
2020-05-06 00:26:31.266628 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_pull_request).
2020-05-06 00:26:31.267074 (Thread-4): Began running node model.github.stg_github_issue_comment
2020-05-06 00:26:31.267474 (Thread-3): Compiling model.github.stg_github_milestone
2020-05-06 00:26:31.267626 (Thread-4): 17:26:31 | 16 of 29 START view model dbt_erik.stg_github_issue_comment.......... [RUN]
2020-05-06 00:26:31.275155 (Thread-3): Writing injected SQL for node "model.github.stg_github_milestone"
2020-05-06 00:26:31.275426 (Thread-4): Acquiring new bigquery connection "model.github.stg_github_issue_comment".
2020-05-06 00:26:31.275642 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_merged).
2020-05-06 00:26:31.275748 (Thread-4): Compiling model.github.stg_github_issue_comment
2020-05-06 00:26:31.282461 (Thread-4): Writing injected SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:26:31.282899 (Thread-3): finished collecting timing info
2020-05-06 00:26:31.287662 (Thread-3): Writing runtime SQL for node "model.github.stg_github_milestone"
2020-05-06 00:26:31.287855 (Thread-4): finished collecting timing info
2020-05-06 00:26:31.293271 (Thread-4): Writing runtime SQL for node "model.github.stg_github_issue_comment"
2020-05-06 00:26:31.293723 (Thread-4): On model.github.stg_github_issue_comment: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_issue_comment"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_issue_comment`
  OPTIONS()
  as (
    with issue_comment as (

    select *
    from `digital-arbor-400`.`github`.`issue_comment`

), fields as (

    select 
      issue_id,
      user_id
    from issue_comment
)

select *
from fields
  );

2020-05-06 00:26:31.294169 (Thread-3): On model.github.stg_github_milestone: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.stg_github_milestone"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`
  OPTIONS()
  as (
    with milestone as (

    select *
    from `digital-arbor-400`.`github`.`milestone`

), fields as (

    select 
      id,
      title,
      due_on, 
      repository_id
    from milestone
)

select *
from fields
  );

2020-05-06 00:26:31.412617 (Thread-1): finished collecting timing info
2020-05-06 00:26:31.415002 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af28750>]}
2020-05-06 00:26:31.415449 (Thread-1): 17:26:31 | 13 of 29 OK created view model dbt_erik.stg_github_repository........ [CREATE VIEW in 0.68s]
2020-05-06 00:26:31.415645 (Thread-1): Finished running node model.github.stg_github_repository
2020-05-06 00:26:31.415830 (Thread-1): Began running node model.github.issue_close_stack
2020-05-06 00:26:31.416007 (Thread-1): 17:26:31 | 17 of 29 START view model dbt_erik.issue_close_stack................. [RUN]
2020-05-06 00:26:31.416344 (Thread-1): Acquiring new bigquery connection "model.github.issue_close_stack".
2020-05-06 00:26:31.416468 (Thread-1): Re-using an available connection from the pool (formerly model.github.stg_github_repository).
2020-05-06 00:26:31.416591 (Thread-1): Compiling model.github.issue_close_stack
2020-05-06 00:26:31.427476 (Thread-1): Writing injected SQL for node "model.github.issue_close_stack"
2020-05-06 00:26:31.428435 (Thread-1): finished collecting timing info
2020-05-06 00:26:31.433012 (Thread-1): Writing runtime SQL for node "model.github.issue_close_stack"
2020-05-06 00:26:31.433403 (Thread-1): On model.github.issue_close_stack: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_close_stack"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  OPTIONS()
  as (
    with issue as (
    
    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_closed_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_closed_history`
  
), close_events_stacked as (
    select
      issue_id,
      created_at as updated_at,
      FALSE as closed
    from issue
    union all
    select
      issue_id,
      updated_at,
      closed
    from issue_closed_history
    union all
    select
      issue_id,
      closed_at as updated_at,
      TRUE as closed
    from issue
    where closed_at is not null

), close_events_stacked_ordered as (
    select
      *,
      row_number() over (partition by issue_id order by updated_at) as issue_event_order /* to avoid ordering issues when updated_at value is present twice */
    from close_events_stacked
)

select
  issue_id,
  updated_at as valid_starting,
  coalesce(lead(updated_at) over (partition by issue_id order by issue_event_order), timestamp_sub(timestamp_add(timestamp(current_date()), interval 1 day), interval 1 millisecond)) as valid_until,
  closed as is_closed
from close_events_stacked_ordered
  );

2020-05-06 00:26:31.645766 (Thread-2): finished collecting timing info
2020-05-06 00:26:31.646927 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af44210>]}
2020-05-06 00:26:31.647546 (Thread-2): 17:26:31 | 14 of 29 OK created view model dbt_erik.stg_github_requested_reviewer_history [CREATE VIEW in 0.74s]
2020-05-06 00:26:31.648149 (Thread-2): Finished running node model.github.stg_github_requested_reviewer_history
2020-05-06 00:26:31.648390 (Thread-2): Began running node model.github.issue_status_windows
2020-05-06 00:26:31.648580 (Thread-2): 17:26:31 | 18 of 29 START view model dbt_erik.issue_status_windows.............. [RUN]
2020-05-06 00:26:31.648933 (Thread-2): Acquiring new bigquery connection "model.github.issue_status_windows".
2020-05-06 00:26:31.649370 (Thread-2): Re-using an available connection from the pool (formerly model.github.stg_github_requested_reviewer_history).
2020-05-06 00:26:31.649639 (Thread-2): Compiling model.github.issue_status_windows
2020-05-06 00:26:31.659248 (Thread-2): Writing injected SQL for node "model.github.issue_status_windows"
2020-05-06 00:26:31.659735 (Thread-2): finished collecting timing info
2020-05-06 00:26:31.664278 (Thread-2): Writing runtime SQL for node "model.github.issue_status_windows"
2020-05-06 00:26:31.664631 (Thread-2): On model.github.issue_status_windows: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_status_windows"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  OPTIONS()
  as (
    with issue_project_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_project_history`
  
), card as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_card`
  
)

select
  issue_project_history.issue_id,
  issue_project_history.project_id,
  issue_project_history.column_name,
  issue_project_history.removed,
  issue_project_history.updated_at as valid_starting,
  coalesce(lead(issue_project_history.updated_at) over (partition by issue_project_history.issue_id, issue_project_history.project_id order by issue_project_history.updated_at),
    if(card.archived, card.updated_at, null),
    current_timestamp()) as valid_until
from issue_project_history
join card on issue_project_history.card_id = card.id
  and not coalesce(card.is_deleted, false)
  );

2020-05-06 00:26:31.914670 (Thread-4): finished collecting timing info
2020-05-06 00:26:31.915812 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9fec50>]}
2020-05-06 00:26:31.916137 (Thread-4): 17:26:31 | 16 of 29 OK created view model dbt_erik.stg_github_issue_comment..... [CREATE VIEW in 0.64s]
2020-05-06 00:26:31.916312 (Thread-4): Finished running node model.github.stg_github_issue_comment
2020-05-06 00:26:31.916485 (Thread-4): Began running node model.github.issue_assignees
2020-05-06 00:26:31.916654 (Thread-4): 17:26:31 | 19 of 29 START view model dbt_erik.issue_assignees................... [RUN]
2020-05-06 00:26:31.916983 (Thread-4): Acquiring new bigquery connection "model.github.issue_assignees".
2020-05-06 00:26:31.917106 (Thread-4): Re-using an available connection from the pool (formerly model.github.stg_github_issue_comment).
2020-05-06 00:26:31.917228 (Thread-4): Compiling model.github.issue_assignees
2020-05-06 00:26:31.927234 (Thread-4): Writing injected SQL for node "model.github.issue_assignees"
2020-05-06 00:26:31.927693 (Thread-4): finished collecting timing info
2020-05-06 00:26:31.932567 (Thread-4): Writing runtime SQL for node "model.github.issue_assignees"
2020-05-06 00:26:31.932983 (Thread-4): On model.github.issue_assignees: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_assignees"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_assignees`
  OPTIONS()
  as (
    with issue_assignee as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_assignee`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue_id,
  string_agg(login, ', ') as assignees
from issue_assignee
left join user on issue_assignee.user_id = user.id
group by 1
  );

2020-05-06 00:26:32.006490 (Thread-3): finished collecting timing info
2020-05-06 00:26:32.007541 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af90510>]}
2020-05-06 00:26:32.007914 (Thread-3): 17:26:32 | 15 of 29 OK created view model dbt_erik.stg_github_milestone......... [CREATE VIEW in 0.74s]
2020-05-06 00:26:32.008130 (Thread-3): Finished running node model.github.stg_github_milestone
2020-05-06 00:26:32.008343 (Thread-3): Began running node model.github.pull_request_reviewers
2020-05-06 00:26:32.008554 (Thread-3): 17:26:32 | 20 of 29 START view model dbt_erik.pull_request_reviewers............ [RUN]
2020-05-06 00:26:32.008967 (Thread-3): Acquiring new bigquery connection "model.github.pull_request_reviewers".
2020-05-06 00:26:32.009089 (Thread-3): Re-using an available connection from the pool (formerly model.github.stg_github_milestone).
2020-05-06 00:26:32.009210 (Thread-3): Compiling model.github.pull_request_reviewers
2020-05-06 00:26:32.019271 (Thread-3): Writing injected SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:26:32.019678 (Thread-3): finished collecting timing info
2020-05-06 00:26:32.024689 (Thread-3): Writing runtime SQL for node "model.github.pull_request_reviewers"
2020-05-06 00:26:32.025120 (Thread-3): On model.github.pull_request_reviewers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_reviewers"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_reviewers`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), user as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  pull_request_id,
  string_agg(login, ', ') as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join user on pull_request_review.user_id = user.id
group by 1
  );

2020-05-06 00:26:32.300534 (Thread-2): finished collecting timing info
2020-05-06 00:26:32.301521 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9e8c50>]}
2020-05-06 00:26:32.302776 (Thread-2): 17:26:32 | 18 of 29 OK created view model dbt_erik.issue_status_windows......... [CREATE VIEW in 0.65s]
2020-05-06 00:26:32.303387 (Thread-2): Finished running node model.github.issue_status_windows
2020-05-06 00:26:32.306360 (Thread-1): finished collecting timing info
2020-05-06 00:26:32.307037 (Thread-2): Began running node model.github.issue_labels
2020-05-06 00:26:32.308445 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b030490>]}
2020-05-06 00:26:32.308754 (Thread-2): 17:26:32 | 21 of 29 START view model dbt_erik.issue_labels...................... [RUN]
2020-05-06 00:26:32.309102 (Thread-1): 17:26:32 | 17 of 29 OK created view model dbt_erik.issue_close_stack............ [CREATE VIEW in 0.89s]
2020-05-06 00:26:32.309399 (Thread-2): Acquiring new bigquery connection "model.github.issue_labels".
2020-05-06 00:26:32.309549 (Thread-1): Finished running node model.github.issue_close_stack
2020-05-06 00:26:32.309673 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_status_windows).
2020-05-06 00:26:32.309811 (Thread-1): Began running node model.github.issue_blocked_time
2020-05-06 00:26:32.310008 (Thread-2): Compiling model.github.issue_labels
2020-05-06 00:26:32.310201 (Thread-1): 17:26:32 | 22 of 29 START view model dbt_erik.issue_blocked_time................ [RUN]
2020-05-06 00:26:32.317354 (Thread-2): Writing injected SQL for node "model.github.issue_labels"
2020-05-06 00:26:32.317625 (Thread-1): Acquiring new bigquery connection "model.github.issue_blocked_time".
2020-05-06 00:26:32.317840 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_close_stack).
2020-05-06 00:26:32.317949 (Thread-1): Compiling model.github.issue_blocked_time
2020-05-06 00:26:32.324813 (Thread-1): Writing injected SQL for node "model.github.issue_blocked_time"
2020-05-06 00:26:32.325127 (Thread-2): finished collecting timing info
2020-05-06 00:26:32.330824 (Thread-1): finished collecting timing info
2020-05-06 00:26:32.331663 (Thread-2): Writing runtime SQL for node "model.github.issue_labels"
2020-05-06 00:26:32.367795 (Thread-1): Writing runtime SQL for node "model.github.issue_blocked_time"
2020-05-06 00:26:32.368345 (Thread-2): On model.github.issue_labels: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_labels"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_labels`
  OPTIONS()
  as (
    with issue_label as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label`
  
)

select
  issue_id,
  string_agg(label, ', ' order by label) as labels
from issue_label
group by issue_id
  );

2020-05-06 00:26:32.368556 (Thread-1): On model.github.issue_blocked_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_blocked_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`
  OPTIONS()
  as (
    with issue_label_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_label_history`
  
), issue_label_times as (

    select
      issue_id,
      label,
      updated_at as valid_starting,
      lead(issue_label_history.updated_at) over (partition by issue_label_history.issue_id, label order by issue_label_history.updated_at) as valid_until,
      labeled
    from issue_label_history
    order by updated_at

)

select
  issue_id,
  sum(timestamp_diff(coalesce(valid_until, current_timestamp()), valid_starting, second)/86400) as days_blocked
from issue_label_times
where labeled
  and lower(label) like '%blocked%'
group by 1
  );

2020-05-06 00:26:32.547101 (Thread-4): finished collecting timing info
2020-05-06 00:26:32.548123 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b03d410>]}
2020-05-06 00:26:32.548567 (Thread-4): 17:26:32 | 19 of 29 OK created view model dbt_erik.issue_assignees.............. [CREATE VIEW in 0.63s]
2020-05-06 00:26:32.548832 (Thread-4): Finished running node model.github.issue_assignees
2020-05-06 00:26:32.549055 (Thread-4): Began running node model.github.pull_request_times
2020-05-06 00:26:32.549274 (Thread-4): 17:26:32 | 23 of 29 START view model dbt_erik.pull_request_times................ [RUN]
2020-05-06 00:26:32.549698 (Thread-4): Acquiring new bigquery connection "model.github.pull_request_times".
2020-05-06 00:26:32.549823 (Thread-4): Re-using an available connection from the pool (formerly model.github.issue_assignees).
2020-05-06 00:26:32.549947 (Thread-4): Compiling model.github.pull_request_times
2020-05-06 00:26:32.563515 (Thread-4): Writing injected SQL for node "model.github.pull_request_times"
2020-05-06 00:26:32.563922 (Thread-4): finished collecting timing info
2020-05-06 00:26:32.568370 (Thread-4): Writing runtime SQL for node "model.github.pull_request_times"
2020-05-06 00:26:32.568704 (Thread-4): On model.github.pull_request_times: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.pull_request_times"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`pull_request_times`
  OPTIONS()
  as (
    with pull_request_review as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request_review`
  
), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

), requested_reviewer_history as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_requested_reviewer_history`

), issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from `digital-arbor-400`.`dbt_erik`.`stg_github_issue_merged`
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.id,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(if(
            requested_reviewer_history.requested_id = pull_request_review.user_id
            and upper(pull_request_review.state) in ('COMMENTED', 'APPROVED', 'CHANGES_REQUESTED'),
            pull_request_review.submitted_at,
            NULL)) as time_of_first_requested_reviewer_review
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  merged_at,
  timestamp_diff(coalesce(time_of_first_review_post_request, current_timestamp()),time_of_first_request, second)/3600 as hours_first_review_post_request,
  --Finds time between first request for review and the review action, uses current_timestamp is no action yet
  timestamp_diff(
    least(
    coalesce(time_of_first_requested_reviewer_review, current_timestamp()),
    coalesce(issue.closed_at, current_timestamp())
  ),
  time_of_first_request,
  second)/3600 as hours_first_action_post_request,
  timestamp_diff(merged_at, time_of_first_request, second)/3600 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
  );

2020-05-06 00:26:32.693743 (Thread-3): finished collecting timing info
2020-05-06 00:26:32.694808 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0599d0>]}
2020-05-06 00:26:32.695181 (Thread-3): 17:26:32 | 20 of 29 OK created view model dbt_erik.pull_request_reviewers....... [CREATE VIEW in 0.69s]
2020-05-06 00:26:32.695396 (Thread-3): Finished running node model.github.pull_request_reviewers
2020-05-06 00:26:32.695610 (Thread-3): Began running node model.github.issue_inbox_time
2020-05-06 00:26:32.695824 (Thread-3): 17:26:32 | 24 of 29 START view model dbt_erik.issue_inbox_time.................. [RUN]
2020-05-06 00:26:32.696221 (Thread-3): Acquiring new bigquery connection "model.github.issue_inbox_time".
2020-05-06 00:26:32.696374 (Thread-3): Re-using an available connection from the pool (formerly model.github.pull_request_reviewers).
2020-05-06 00:26:32.696524 (Thread-3): Compiling model.github.issue_inbox_time
2020-05-06 00:26:32.705133 (Thread-3): Writing injected SQL for node "model.github.issue_inbox_time"
2020-05-06 00:26:32.705575 (Thread-3): finished collecting timing info
2020-05-06 00:26:32.710228 (Thread-3): Writing runtime SQL for node "model.github.issue_inbox_time"
2020-05-06 00:26:32.710610 (Thread-3): On model.github.issue_inbox_time: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_inbox_time"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
)

select
  issue_id,
  sum(timestamp_diff(valid_until, valid_starting, second)/86400) as inbox_days
from issue_status_windows
where upper(column_name) like '%INBOX%'
  and not removed
group by 1
  );

2020-05-06 00:26:33.019570 (Thread-2): finished collecting timing info
2020-05-06 00:26:33.020628 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b048f50>]}
2020-05-06 00:26:33.021002 (Thread-2): 17:26:33 | 21 of 29 OK created view model dbt_erik.issue_labels................. [CREATE VIEW in 0.71s]
2020-05-06 00:26:33.021214 (Thread-2): Finished running node model.github.issue_labels
2020-05-06 00:26:33.021429 (Thread-2): Began running node model.github.issue_projects
2020-05-06 00:26:33.021766 (Thread-2): 17:26:33 | 25 of 29 START view model dbt_erik.issue_projects.................... [RUN]
2020-05-06 00:26:33.022108 (Thread-2): Acquiring new bigquery connection "model.github.issue_projects".
2020-05-06 00:26:33.022236 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_labels).
2020-05-06 00:26:33.022361 (Thread-2): Compiling model.github.issue_projects
2020-05-06 00:26:33.032171 (Thread-2): Writing injected SQL for node "model.github.issue_projects"
2020-05-06 00:26:33.032576 (Thread-2): finished collecting timing info
2020-05-06 00:26:33.037777 (Thread-2): Writing runtime SQL for node "model.github.issue_projects"
2020-05-06 00:26:33.038147 (Thread-2): On model.github.issue_projects: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_projects"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_projects`
  OPTIONS()
  as (
    with issue_status_windows as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_status_windows`
  
), project as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_project`
  
), current_status as (

    select
      issue_id,
      project_id,
      array_agg(removed order by valid_until desc)[safe_offset(0)] as most_recent_removed_status
    from issue_status_windows
    group by 1, 2

), current_project_issues_with_ids as (

    select
      issue_id,
      array_agg(distinct project_id) as projects_array
    from issue_status_windows
    where concat(issue_id, '-', project_id) not in ( --projects where the issue has not been removed
      select
        concat(issue_id, '-', project_id) as issue_project
      from current_status
      where most_recent_removed_status = true
    )
    group by 1

)
select
  issue_id,
  string_agg(project.name, ', ') as projects
from current_project_issues_with_ids, unnest(projects_array) as project_id
join project on project_id = project.id
group by 1
  );

2020-05-06 00:26:33.123238 (Thread-1): finished collecting timing info
2020-05-06 00:26:33.124822 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae99d50>]}
2020-05-06 00:26:33.125504 (Thread-1): 17:26:33 | 22 of 29 OK created view model dbt_erik.issue_blocked_time........... [CREATE VIEW in 0.81s]
2020-05-06 00:26:33.126073 (Thread-1): Finished running node model.github.issue_blocked_time
2020-05-06 00:26:33.126304 (Thread-1): Began running node model.github.issue_open_length
2020-05-06 00:26:33.126586 (Thread-1): 17:26:33 | 26 of 29 START view model dbt_erik.issue_open_length................. [RUN]
2020-05-06 00:26:33.127180 (Thread-1): Acquiring new bigquery connection "model.github.issue_open_length".
2020-05-06 00:26:33.127313 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_blocked_time).
2020-05-06 00:26:33.127441 (Thread-1): Compiling model.github.issue_open_length
2020-05-06 00:26:33.136687 (Thread-1): Writing injected SQL for node "model.github.issue_open_length"
2020-05-06 00:26:33.138110 (Thread-1): finished collecting timing info
2020-05-06 00:26:33.142985 (Thread-1): Writing runtime SQL for node "model.github.issue_open_length"
2020-05-06 00:26:33.143952 (Thread-1): On model.github.issue_open_length: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issue_open_length"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issue_open_length`
  OPTIONS()
  as (
    with issue_close_stack as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_close_stack`
  
)

select
  issue_id,
  sum(timestamp_diff(least(valid_until, current_timestamp()), valid_starting, second)/86400) as days_issue_opened
from issue_close_stack
  where not is_closed
group by issue_id
  );

2020-05-06 00:26:33.346830 (Thread-4): finished collecting timing info
2020-05-06 00:26:33.347859 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b03d410>]}
2020-05-06 00:26:33.348228 (Thread-4): 17:26:33 | 23 of 29 OK created view model dbt_erik.pull_request_times........... [CREATE VIEW in 0.80s]
2020-05-06 00:26:33.348570 (Thread-4): Finished running node model.github.pull_request_times
2020-05-06 00:26:33.512637 (Thread-3): finished collecting timing info
2020-05-06 00:26:33.513676 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9688d0>]}
2020-05-06 00:26:33.514048 (Thread-3): 17:26:33 | 24 of 29 OK created view model dbt_erik.issue_inbox_time............. [CREATE VIEW in 0.82s]
2020-05-06 00:26:33.514253 (Thread-3): Finished running node model.github.issue_inbox_time
2020-05-06 00:26:33.873930 (Thread-1): finished collecting timing info
2020-05-06 00:26:33.874976 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae99410>]}
2020-05-06 00:26:33.875346 (Thread-1): 17:26:33 | 26 of 29 OK created view model dbt_erik.issue_open_length............ [CREATE VIEW in 0.75s]
2020-05-06 00:26:33.875557 (Thread-1): Finished running node model.github.issue_open_length
2020-05-06 00:26:33.876064 (Thread-4): Began running node model.github.github_pull_requests
2020-05-06 00:26:33.876315 (Thread-4): 17:26:33 | 27 of 29 START view model dbt_erik.github_pull_requests.............. [RUN]
2020-05-06 00:26:33.876657 (Thread-4): Acquiring new bigquery connection "model.github.github_pull_requests".
2020-05-06 00:26:33.876780 (Thread-4): Re-using an available connection from the pool (formerly model.github.pull_request_times).
2020-05-06 00:26:33.876902 (Thread-4): Compiling model.github.github_pull_requests
2020-05-06 00:26:33.893335 (Thread-4): Writing injected SQL for node "model.github.github_pull_requests"
2020-05-06 00:26:33.896446 (Thread-2): finished collecting timing info
2020-05-06 00:26:33.897020 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b07d310>]}
2020-05-06 00:26:33.897233 (Thread-2): 17:26:33 | 25 of 29 OK created view model dbt_erik.issue_projects............... [CREATE VIEW in 0.87s]
2020-05-06 00:26:33.897354 (Thread-2): Finished running node model.github.issue_projects
2020-05-06 00:26:33.897780 (Thread-4): finished collecting timing info
2020-05-06 00:26:33.902130 (Thread-4): Writing runtime SQL for node "model.github.github_pull_requests"
2020-05-06 00:26:33.902423 (Thread-1): Began running node model.github.github_issues
2020-05-06 00:26:33.902572 (Thread-1): 17:26:33 | 28 of 29 START view model dbt_erik.github_issues..................... [RUN]
2020-05-06 00:26:33.902929 (Thread-1): Acquiring new bigquery connection "model.github.github_issues".
2020-05-06 00:26:33.903222 (Thread-1): Re-using an available connection from the pool (formerly model.github.issue_open_length).
2020-05-06 00:26:33.903373 (Thread-1): Compiling model.github.github_issues
2020-05-06 00:26:33.908839 (Thread-4): On model.github.github_pull_requests: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_pull_requests"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_pull_requests`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

), pull_request_times as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`pull_request_times`

), pull_request as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_pull_request`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login as created_by,
  hours_first_review_post_request,
  hours_first_action_post_request,
  hours_request_review_to_merge,
  merged_at
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join repository
  on issue.repository_id = repository.id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join creator 
  on issue.user_id = creator.id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
where issue.pull_request
  );

2020-05-06 00:26:33.921118 (Thread-1): Writing injected SQL for node "model.github.github_issues"
2020-05-06 00:26:33.922670 (Thread-1): finished collecting timing info
2020-05-06 00:26:33.927521 (Thread-1): Writing runtime SQL for node "model.github.github_issues"
2020-05-06 00:26:33.928844 (Thread-1): On model.github.github_issues: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.github_issues"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`github_issues`
  OPTIONS()
  as (
    with issue as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_issue`
  
), issue_labels as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_labels`

), issue_projects as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_projects`

), repository as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_repository`

), milestone as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_milestone`

), issue_assignees as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_assignees`

), issue_open_length as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_open_length`

), issue_blocked_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_blocked_time`

), issue_inbox_time as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`issue_inbox_time`

), creator as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`stg_github_user`

)

select
  issue.issue_id,
  issue.body,
  issue.closed_at,
  issue.created_at,
  issue.locked,
  issue.milestone_id,
  issue.number,
  issue.repository_id,
  issue.state,
  issue.title,
  issue.updated_at,
  issue.user_id,
  concat('https://github.com/', repository.full_name, '/issues/', cast(issue.number as string)) as url_link,
  issue_open_length.days_issue_opened,
  labels.labels,
  issue_projects.projects,
  repository.full_name as repository,
  milestone.title as milestone,
  milestone.due_on as milestone_due_on,
  issue_assignees.assignees,
  issue_blocked_time.days_blocked,
  issue_inbox_time.inbox_days,
  creator.login as created_by
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
left join issue_projects
  on issue.issue_id = issue_projects.issue_id
left join repository
  on issue.repository_id = repository.id
left join milestone
  on issue.milestone_id = milestone.id and issue.repository_id = milestone.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_blocked_time
  on issue.issue_id = issue_blocked_time.issue_id
left join issue_inbox_time
  on issue.issue_id = issue_inbox_time.issue_id
left join creator on issue.user_id = creator.id
where not issue.pull_request
  );

2020-05-06 00:26:34.657992 (Thread-1): finished collecting timing info
2020-05-06 00:26:34.658877 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9fb590>]}
2020-05-06 00:26:34.659190 (Thread-1): 17:26:34 | 28 of 29 OK created view model dbt_erik.github_issues................ [CREATE VIEW in 0.76s]
2020-05-06 00:26:34.659367 (Thread-1): Finished running node model.github.github_issues
2020-05-06 00:26:35.196936 (Thread-4): finished collecting timing info
2020-05-06 00:26:35.197983 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae99410>]}
2020-05-06 00:26:35.198335 (Thread-4): 17:26:35 | 27 of 29 OK created view model dbt_erik.github_pull_requests......... [CREATE VIEW in 1.32s]
2020-05-06 00:26:35.198513 (Thread-4): Finished running node model.github.github_pull_requests
2020-05-06 00:26:35.198870 (Thread-2): Began running node model.github.issues_and_prs_per_month
2020-05-06 00:26:35.199053 (Thread-2): 17:26:35 | 29 of 29 START view model dbt_erik.issues_and_prs_per_month.......... [RUN]
2020-05-06 00:26:35.199387 (Thread-2): Acquiring new bigquery connection "model.github.issues_and_prs_per_month".
2020-05-06 00:26:35.199509 (Thread-2): Re-using an available connection from the pool (formerly model.github.issue_projects).
2020-05-06 00:26:35.199630 (Thread-2): Compiling model.github.issues_and_prs_per_month
2020-05-06 00:26:35.210296 (Thread-2): Writing injected SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:26:35.210734 (Thread-2): finished collecting timing info
2020-05-06 00:26:35.215445 (Thread-2): Writing runtime SQL for node "model.github.issues_and_prs_per_month"
2020-05-06 00:26:35.215857 (Thread-2): On model.github.issues_and_prs_per_month: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "fivetran", "target_name": "dev", "node_id": "model.github.issues_and_prs_per_month"} */


  create or replace view `digital-arbor-400`.`dbt_erik`.`issues_and_prs_per_month`
  OPTIONS()
  as (
    with github_issues as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_issues`

), pull_requests as (

    select *
    from `digital-arbor-400`.`dbt_erik`.`github_pull_requests`

), issues_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_issues_opened,
      avg(days_issue_opened) as average_length_issue_open,
      max(days_issue_opened) as longest_length_issue_open
    from github_issues
    group by 1

), issues_closed_per_month as (

   select 
      date_trunc(date(closed_at), month) as month, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_month as (

   select 
      date_trunc(date(created_at), month) as month, 
      count(*) as number_prs_opened,
      avg(days_issue_opened) as average_length_pr_open,
      max(days_issue_opened) as longest_length_pr_open
    from pull_requests
    group by 1

), prs_merged_per_month as (

   select 
      date_trunc(date(merged_at), month) as month, 
      count(*) as number_prs_merged
    from pull_requests
    group by 1

), issues_per_month as (

    select 
      coalesce(issues_opened_per_month.month, 
        issues_closed_per_month.month
      ) as month,
      number_issues_opened,
      number_issues_closed,      
      average_length_issue_open,
      longest_length_issue_open
    from issues_opened_per_month
    full outer join issues_closed_per_month on issues_opened_per_month.month = issues_closed_per_month.month

), prs_per_month as (

    select 
      coalesce(prs_opened_per_month.month, 
        prs_merged_per_month.month
      ) as month,
      number_prs_opened,
      number_prs_merged,
      average_length_pr_open,
      longest_length_pr_open
    from prs_opened_per_month
    full outer join prs_merged_per_month on prs_opened_per_month.month = prs_merged_per_month.month

)

select 
  coalesce(issues_per_month.month, 
    prs_per_month.month
  ) as month,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  average_length_issue_open,
  longest_length_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  average_length_pr_open,
  longest_length_pr_open
from issues_per_month 
full outer join prs_per_month on issues_per_month.month = prs_per_month.month
  );

2020-05-06 00:26:36.628530 (Thread-2): finished collecting timing info
2020-05-06 00:26:36.629575 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95d64719-a9dd-4f99-84d9-7fe5e1980682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7dcb10>]}
2020-05-06 00:26:37.308267 (Thread-2): 17:26:37 | 29 of 29 OK created view model dbt_erik.issues_and_prs_per_month..... [CREATE VIEW in 1.43s]
2020-05-06 00:26:37.308636 (Thread-2): Finished running node model.github.issues_and_prs_per_month
2020-05-06 00:26:37.392825 (MainThread): 17:26:37 | 
2020-05-06 00:26:37.393177 (MainThread): 17:26:37 | Finished running 29 view models in 10.51s.
2020-05-06 00:26:37.393416 (MainThread): Connection 'master' was left open.
2020-05-06 00:26:37.393590 (MainThread): Connection 'model.github.github_issues' was left open.
2020-05-06 00:26:37.393750 (MainThread): Connection 'model.github.issues_and_prs_per_month' was left open.
2020-05-06 00:26:37.393907 (MainThread): Connection 'model.github.issue_inbox_time' was left open.
2020-05-06 00:26:37.394060 (MainThread): Connection 'model.github.github_pull_requests' was left open.
2020-05-06 00:26:37.464824 (MainThread): 
2020-05-06 00:26:37.464981 (MainThread): Completed successfully
2020-05-06 00:26:37.465205 (MainThread): 
Done. PASS=29 WARN=0 ERROR=0 SKIP=0 TOTAL=29
2020-05-06 00:26:37.465430 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a8b390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a958dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa0fe90>]}
2020-05-06 00:26:37.465839 (MainThread): Flushing usage events
